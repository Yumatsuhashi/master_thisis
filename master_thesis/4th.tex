\chapter{時系列補間型学習データを用いた無線チャネル予測機構}{}
\label{chap:4th}

\section{はじめに}
本章では，第2章で指摘した予測スロットにおいて推定値が得られずモデルの重みを更新できないという問題に対して
補間を用いた新たなモデル重み更新機構を提案する．その際に用いる補間手法は第3章で比較検証した中で最も有効な手法を採用する.



\section{時系列補間型学習データを用いたチャネル予測機構によるモデル重み更新}
本研究では，参照信号削減のため予測スロットでは参照信号を送信せず，当該スロットのCSI推定値が得られない状況を前提とする．このとき，予測スロットでは教師信号，すなわち正解ラベルが欠損するため，既存の重み更新手法をそのまま適用できない．そこで，予測を継続しながらも時系列CSI予測モデルを更新できる枠組みを提案する．
本枠組みの要点は，欠損した正解ラベルを直ちに用意して逐次更新するのではなく，後続スロットで観測されるCSI推定値に基づき予測スロットの補間値を事後的に算出し，推定値と補間値で構成されるCSI系列を一定量蓄積した後に，その系列から更新用の学習サンプル群を構成してモデルを更新する点にある．
提案機構の概要を図\ref{fig:explonation}に示す．

以下，時刻\(t\)をスロット時刻とし，参照信号から得るCSI推定値を\(\bm{H}_t\)，予測モデルが出力するCSI予測値を\(\widehat{\bm{H}}_t\)とする．
補間により得られる予測スロットの補間値を\(\widetilde{\bm{H}}_t\)とする．
説明のため，直近3スロットを入力として1スロット先を予測する3入力1出力の予測モデルを例にとる．このとき，学習済み予測モデル\(f_{\theta}\)により
\begin{equation}
  \widehat{\bm{H}}_{t+3}=f_{\theta}(\bm{H}_t,\bm{H}_{t+1},\bm{H}_{t+2})
\end{equation}
を得る．しかし，参照信号削減の運用では予測スロット\(t+3\)において参照信号を送信しないため，\(\bm{H}_{t+3}\)は観測できず，\(\widehat{\bm{H}}_{t+3}\)に対する教師信号が欠落する．

そこで本研究では，予測スロットより後に得られる推定値を用い，欠損した\(\bm{H}_{t+3}\)を事後的に推定する．
具体的には，次スロット以降で参照信号が送信されて\(\bm{H}_{t+4},\bm{H}_{t+5},\dots\)が得られたら，欠損時刻の前後に存在する推定値を用いて補間し，予測スロットに対応する補間値
\begin{equation}
  \widetilde{\bm{H}}_{t+3}
\end{equation}
を算出する．この\(\widetilde{\bm{H}}_{t+3}\)は，予測スロットで本来得られるべき\(\bm{H}_{t+3}\)の近似として扱うことで，教師あり学習に必要な正解ラベルを補間により近似する役割を担う．

補間値は後続スロットの推定値が得られてはじめて定まるため，欠損が生じるたびに即時に学習サンプルを確定させて逐次更新する運用とはならない．本研究では，推定値と補間値で構成されるCSI系列を蓄積し，所定の長さの時系列が揃った時点で，その系列から更新用の学習サンプル群を構成してモデルを微調整する．
例えば，3入力1出力の設定では，入力を\(\widetilde{\bm{H}}_{t+3},\bm{H}_{t+4},\bm{H}_{t+5}\)，出力を\(\bm{H}_{t+6}\)として学習サンプルを作成し，複数サンプルをまとめて更新に用いる．
ここで，3入力の並びは一例であり，入力の3時刻のうち予測スロットに対応する1点を\(\widetilde{\bm{H}}\)で置き換え，残りを後続スロットで得られる推定値で構成すればよい．
すなわち，
\begin{equation}
  \bm{H}_{t+6}\approx f_{\theta}(\widetilde{\bm{H}}_{t+3},\bm{H}_{t+4},\bm{H}_{t+5})
\end{equation}
となるように損失を計算し，勾配法によりモデルを微調整する．

以上の手順を繰り返すことで，参照信号削減下でも予測スロットにおける欠損ラベルを補間により補ったCSI系列を蓄積し，蓄積した系列から学習サンプル群を構成して更新を反復できる．
これにより，環境変化に伴う分布の変化に追従したモデル更新を実現する．




\begin{figure}[H]
  \centering
  \includegraphics[width=120mm]{../picture/4nd/explonation_pdf15.pdf}
  \caption{提案機構の概要}
  \label{fig:explonation}
\end{figure}




\section{シミュレーション}
\label{sec:simulation}

\subsection{シミュレーション条件}

本節では，提案機構の有効性を検証するためのシミュレーション条件について述べる．
本実験で用いるCSI系列は，\autoref{subsec:terrain_raytracing}で述べたとおり，Sionnaによるレイトレーシングで生成したものである．
以下，本実験で用いる学習データの構成および実験手順を説明する．

\subsubsection{ベースラインモデルおよび補間モデルの学習}
本実験では，事前学習用データセットとして事前学習データを用いる．
事前学習データは，池袋，渋谷，新宿の3地域から取得したCSI系列で構成される．
この事前学習データから，時系列CSI予測を担うベースラインモデルと，欠損時刻のCSIを推定する補間モデルの両方を学習する．

ベースラインモデルの学習では，事前学習データを学習用，検証用，テスト用の3つに分割する．
分割比率はTrain:Val:Test = 7:2:1とし，学習用データでモデルを訓練し，検証用データで過学習の監視および最良モデルの選択を行い，テスト用データで汎化性能を評価する．

補間モデルの学習も同一の事前学習データを用いる．
ニューラルネットワーク補間を用いる場合は，補間モデル専用のデータ分割を行う．
補間モデルの学習ではTrain:Val = 8:2の比率で分割し，学習用データで補間モデルを訓練し，検証用データで性能を監視する．
スプライン補間や多項式近似など事前学習を要しない補間手法では，このステップは不要である．

以上により，事前学習データからベースラインモデルと補間モデルの両方を得る．
ベースラインモデルは以降のファインチューニングにおける初期値として用い，補間モデルはファインチューニング用データセット生成時の補間値算出に用いる．

\subsubsection{検証用データの5分割}
検証用データは，錦糸町で取得したCSI系列で構成される．
この検証用データを用いて，ベースラインモデルを新環境に適応させるファインチューニングを実施する．

評価の信頼性を高めるため，検証用データを5分割し，交差検証により評価する．
具体的には，検証用データを5つの互いに重複しない部分集合に分割する．
各分割において，5つの部分集合のうち4つをファインチューニング用として用い，残りの1つを評価用として用いる．
すなわち，ファインチューニング用と評価用の比率は4:1である．

この分割を5回繰り返し，各回で異なる部分集合を評価用に割り当てることで，すべてのデータが1度は評価用として用いられる．
5分割交差検証により，特定のデータ分割に依存した偏りを排除し，データセットの難易度による評価結果の変動を均一化する．

\subsubsection{ファインチューニング用データセットの生成}
各分割において，ファインチューニング用として割り当てられた4/5の検証用データから，学習サンプルを生成する．
ファインチューニング用データセットの生成には，補間手法を用いる．

具体的には，連続するCSIフレームからスライディングウィンドウ方式でサンプルを抽出する．
抽出したウィンドウの中心時刻に対応するフレームを欠損フレームとみなし，周囲のフレームを用いて補間値を算出する．
補間値の算出には，3次スプライン補間，ニューラルネットワーク補間，多項式近似などの手法を適用する．
算出した補間値を入力系列に含め，後続時刻の真値を出力とする学習サンプルを構成する．

この手順により，欠損時刻を補間値で補ったファインチューニング用学習サンプル群が得られる．
補間手法ごとに異なるファインチューニング用データセットを生成し，手法間の性能比較に用いる．

\subsubsection{ファインチューニングの実施}
生成したファインチューニング用データセットを用いて，ベースラインモデルを更新する．
ベースラインモデルの重みを初期値として読み込み，ファインチューニング用データセットで追加学習を行う．
学習後のモデルを適応後モデルとして保存する．

この操作を補間手法ごとに実施し，各補間手法に対応する適応後モデルを得る．
ファインチューニングのハイパーパラメータは，学習率，エポック数，バッチサイズを含め，すべての手法で共通の値を用いる．

\subsubsection{評価}
各分割において，評価用として割り当てられた1/5の検証用データを用いて，適応後モデルの予測精度を評価する．
評価指標には，予測NMSEを用いる．

評価対象は，ファインチューニングを行わないベースラインモデル，各補間手法を用いてファインチューニングした適応後モデル，および予測を行わない場合である．
予測なしとは直前フレームをそのまま次時刻の予測値として出力する手法であり，予測モデルの有効性を確認するためのベースラインとして用いる．

各分割で得られた予測NMSEを補間手法ごとに記録し，5分割すべての評価が完了した後に平均値を算出する．
ベースラインモデルから適応後モデルへの改善率を補間手法間で比較し，提案機構の有効性を検証する．

\subsubsection{交差検証の意義}
5分割交差検証を採用する理由は，評価結果の信頼性と汎化性を確保するためである．
単一のデータ分割のみで評価した場合，評価用データに含まれる軌跡の特性によって結果が変動する可能性がある．
例えば，評価用データに予測が容易な軌跡が偏って含まれれば，改善率は過大評価される．
逆に，予測が困難な軌跡が偏って含まれれば，改善率は過小評価される．

5分割交差検証では，すべてのデータが評価用として1度は使用されるため，特定の軌跡に依存した評価の偏りを抑制できる．
5回の評価結果を平均することで，データセット全体に対する平均的な性能を推定し，提案機構の有効性をより客観的に評価する．



\subsection{機械学習モデル}
はじめに本論文で用いる時系列CSI予測を実行するニューラルネットワークのアーキテクチャについて説明する.
本論文では多重パーセプトロン(MLP)と長短期記憶(LSTM)を用いた2種類のニューラルネットワークを用いる．  


本論文のCSI予測器は，全結合層からなる多層パーセプトロン（MLP）として実装する．
時刻方向に過去\(T_I\)フレーム分のCSIを用い，各フレームをベクトル化して結合した入力\(\bm{x}\in\mathbb{R}^{T_I\cdot F}\)から，次フレーム1枚分のCSIをベクトル化した出力\(\widehat{\bm{y}}\in\mathbb{R}^{F}\)を回帰する．
ここで，\(F\)は1フレームのCSI（行列）をフラット化した次元である．

MLPの層構成は以下のとおりである．中間層ではReLUにより非線形性を導入し，過学習を抑制するためにDropout（\(p=0.1\)）を適用する．

\begin{itemize}
  \item \(\mathrm{Linear}(\mathrm{in\_dim}\rightarrow 2048)\rightarrow \mathrm{ReLU}\rightarrow \mathrm{Dropout}(p=0.1)\)
  \item \(\mathrm{Linear}(2048\rightarrow 1024)\rightarrow \mathrm{ReLU}\rightarrow \mathrm{Dropout}(p=0.1)\)
  \item \(\mathrm{Linear}(1024\rightarrow 512)\rightarrow \mathrm{ReLU}\rightarrow \mathrm{Dropout}(p=0.1)\)
  \item \(\mathrm{Linear}(512\rightarrow \mathrm{out\_dim})\)
\end{itemize}

以上により，過去\(T_I\)フレームに含まれる時系列情報を，固定長ベクトル\(\bm{x}\)として受け取り，次フレームのCSIベクトル\(\widehat{\bm{y}}\)を予測する．

続いてLSTMのアーキテクチャについて説明する．
LSTMでは，過去\(T_I\)フレーム分のCSIを時系列として入力し，隠れ状態により時間方向の依存関係を保持しながら次フレームのCSIを回帰する．
入力はMLPと同様に，各フレームのCSIをベクトル化して結合した\(\bm{x}\in\mathbb{R}^{T_I\cdot F}\)である．本論文の設定では\(T_I=3\)，\(F=3072\)より\(\bm{x}\in\mathbb{R}^{9216}\)となる．
バッチサイズを\(B\)とすると入力形状は\([B,\,T_I\cdot F]=[B,\,9216]\)である．この入力を時系列へ再整形し，
\begin{equation}
  \bm{X}\in\mathbb{R}^{B\times T_I\times F}=\mathbb{R}^{B\times 3\times 3072}
\end{equation}
を得る．\(\bm{X}\)は3フレームからなる系列であり，各タイムステップは3072次元のCSIベクトルに対応する．

LSTMの層構成は以下のとおりである．本論文では2層のスタックLSTMを用いる．過学習を抑えるため，層間にDropout \(p=0.1\)を適用する．

\begin{itemize}
  \item 第1層LSTM: 入力\([B,3,3072]\)を受け取り，隠れ状態次元512の系列出力\([B,3,512]\)を出力する．
  \item 第2層LSTM: 第1層の出力\([B,3,512]\)を入力とし，\([B,3,512]\)を出力する．
  \item 特徴抽出: 第2層LSTMの最終タイムステップの隠れ状態\(\bm{h}_{T_I}\in\mathbb{R}^{B\times 512}\)を特徴量として用いる．\(\bm{h}_{T_I}\)は過去3フレームの情報を集約した固定長表現である．
  \item 全結合層: 抽出した特徴量\(\bm{h}_{T_I}\)を全結合層へ与え，次フレームのCSIベクトルを回帰する．全結合層は\(\mathrm{Linear}(512\rightarrow F)\)とし，出力形状は\([B,F]=[B,3072]\)である．
\end{itemize}

以上により，過去\(T_I\)フレームに含まれる時系列情報を，隠れ状態により保持しながら次フレームのCSIベクトル\(\widehat{\bm{y}}\)を予測する．





\subsubsection{機械学習モデルのハイパーパラメーター}

本論文で用いる予測モデルと補間モデル，および補間値を用いたファインチューニングの，学習率，エポック数，バッチサイズ設定値を以下に示す．
\begin{description}
  \item[ベースラインモデルのトレーニング] 学習率は\(1\times10^{-3}\)，エポック数は40，バッチサイズは128である．
  \item[補間モデルであるInterpolator NNのトレーニング] 学習率は\(1\times10^{-4}\)，エポック数は10，バッチサイズは128である．
  \item[ファインチューニング] 学習率は\(1\times10^{-4}\)，エポック数は20，バッチサイズは128である．
\end{description}

損失評価には，正規化平均二乗誤差 Normalized Mean Squared Error，NMSEを用いる．
NMSEは，推定値と予測値の二乗誤差を推定値の電力で正規化した量であり，サンプルごとに算出した後に平均し以下の式で表される


\paragraph{予測NMSE}
予測NMSEは，予測モデルが出力する予測値\(\widehat{\bm{H}}_t\)と真値\(\bm{H}_t\)の誤差を評価する．
\begin{equation}
  \mathrm{NMSE}_{\mathrm{pred}}
  =\frac{\left\lVert \widehat{\bm{H}}_t-\bm{H}_t\right\rVert_2^2}{\left\lVert \bm{H}_t\right\rVert_2^2}
  \label{eq:nmse_pred_def}
\end{equation}




\section{時系列補間型学習データを用いた無線チャネル予測機構評価}
\label{sec:evaluation_of_prediction_mechanism_using_time_series_interpolation_learning_data}

本節では，\autoref{sec:simulation}で述べたシミュレーション条件に基づき，時系列補間型学習データを用いたチャネル予測機構の評価を行う．


\subsection{新基地局設置時}
\label{sec:evaluation_of_prediction_mechanism_using_time_series_interpolation_learning_data_new_base_station_installation}
本節の実験では他セルで運用していたチャネル予測モデルを新規基地局へ展開する状況を想定している．
具体的には，池袋，渋谷，新宿の3地域で収集したCSI系列により事前学習したモデルを，錦糸町駅前の環境に適応させる．
新規基地局の設置直後は十分な学習データが蓄積されていないため，限られたサンプル数でモデルを適応させる手法が求められる．
提案する時系列補間型学習データを用いたファインチューニングが，この課題に対してどの程度有効であるかを検証する．

事前学習データには，\autoref{subsec:terrain_raytracing}で述べた渋谷駅前，新宿駅前，池袋駅前の3地域における地形データに対してレイトレーシングを実施し生成したCSI系列を用いる．
1サンプルは入力用の3時刻分のCSIと出力用の1時刻分のCSIで構成され，連続する4時刻のCSI系列を非重複で切り出して生成する．

事前学習データのサンプル数を\autoref{tab:pretraining_data_samples}に示す．
学習用データが204,390サンプル，検証用データが49,193サンプル，テスト用データが18,859サンプルであり，合計272,442サンプルで構成される．

\begin{table}[H]
  \centering
  \caption{事前学習データのサンプル数}
  \label{tab:pretraining_data_samples}
  \begin{tabular}{lr}
    \hline
    データ種別 & サンプル数 \\
    \hline
    学習用（Train） & 204,390 \\
    検証用（Val） & 49,193 \\
    テスト用（Test） & 18,859 \\
    \hline
    合計 & 272,442 \\
    \hline
  \end{tabular}
\end{table}

検証用データには，錦糸町駅前の地形データに対してレイトレーシングを実施し生成したCSI系列を用いる．
検証用データのサンプル数は約277,900である．
事前学習データと検証用データは互いに独立した地理的環境から取得しており，両者の間にデータの重複はない．

本評価では，既存セルで運用していたチャネル予測モデルを新規基地局へ展開する状況を想定する．
具体的には，池袋，渋谷，新宿の3地域で収集したCSI系列により事前学習したモデルを，錦糸町という未知の環境に適応させる．
新規基地局の設置直後は十分な学習データが蓄積されていないため，限られたサンプル数で効率的にモデルを適応させる手法が求められる．
提案する時系列補間型学習データを用いたファインチューニングが，この課題に対してどの程度有効であるかを検証する．

\subsubsection{ベースラインモデルの学習結果}
まず，事前学習データを用いたベースラインモデルの学習結果を示す．
\autoref{fig:baseline_learning_curves}にベースラインモデルの学習曲線を示す．
横軸はエポック数，縦軸はNMSEである．
エポックを重ねるごとに学習用データおよび検証用データの双方でNMSEが減少しており，モデルが適切に学習されていることが確認できる．

\begin{figure}[H]
  \centering
  \includegraphics[width=100mm]{../picture/4nd/441_real_town_learning_curves.pdf}
  \caption{ベースラインモデルの学習曲線}
  \label{fig:baseline_learning_curves}
\end{figure}

次に，ベースラインモデルの予測性能を評価するため，予測を行わない場合との比較を行う．
予測なしの手法として，入力3フレームの最終時刻$t=2$におけるCSI推定値をそのまま出力時刻$t=3$の推定値として使用する方法を定義する．
予測なしは直前の推定値をビームフォーミングに使用する場合に相当し，予測によりどの程度の改善が得られるかを評価する基準となる．

\autoref{tab:baseline_vs_copylast}に，錦糸町の検証用データにおけるベースラインモデルと予測なしのNMSE比較結果を示す．
5分割交差検証の各foldにおいて，ベースラインモデルのNMSEは予測なしと比較して大幅に小さい値を示している．
平均NMSEはベースラインモデルが0.136，予測なしが0.321であり，ベースラインモデルは予測なしの場合と比較してNMSEを約58\%削減している．
この結果から，事前学習により獲得したチャネル予測能力が，未知の環境である錦糸町においても一定の汎化性能を発揮していることがわかる．

\begin{table}[H]
  \centering
  \caption{ベースラインモデルと予測なしのNMSE比較}
  \label{tab:baseline_vs_copylast}
  \begin{tabular}{crr}
    \hline
    Fold & ベースラインモデル & 予測なし \\
    \hline
    0 & 0.144 & 0.493 \\
    1 & 0.141 & 0.326 \\
    2 & 0.127 & 0.205 \\
    3 & 0.143 & 0.348 \\
    4 & 0.128 & 0.232 \\
    \hline
    平均 & 0.136 & 0.321 \\
    \hline
  \end{tabular}
\end{table}

続いて，\autoref{sec:interpolation_methods}で述べた補間手法を用いて予測スロットのCSIを補間する．
補間手法の選定にあたっては，\autoref{tab:kinshicho_sssp_results}に示した錦糸町データセットにおける補間精度評価の結果を参考にする．
同評価では，錦糸町駅前の地形データに対してレイトレーシングにより生成したCSI系列を用いて各補間手法の精度を比較した．
その結果，スプライン補間および4次または5次の多項式近似がNMSE 0.006程度と最良の精度を達成することが判明している．

本実験では，上記の評価結果に基づき，スプライン補間および多項式近似を採用して予測スロットのCSIを補間する．
これらの補間手法は事前学習を必要としないため，新規基地局において即座に適用可能である点も利点となる．
補間により生成したCSIを用いてファインチューニング用の学習サンプルを構成し，ベースラインモデルの適応を試みる．

\subsubsection{学習サンプルの構成}
3入力1出力のチャネル予測モデルを運用する場合，$\bm{H}_t, \bm{H}_{t+1}, \bm{H}_{t+2}$から$\widehat{\bm{H}}_{t+3}$を得る．
参照信号を削減する予測スロットでは，時刻$t+3$の推定値$\bm{H}_{t+3}$を獲得できない．
基地局が利用できるCSI系列は$\bm{H}_t, \bm{H}_{t+1}, \bm{H}_{t+2}, -, \bm{H}_{t+4}, \bm{H}_{t+5}, \bm{H}_{t+6}, -, \ldots$のように推定値と欠損が周期的に現れる系列となる．
欠損時刻に対して補間を適用すると，補間値$\widetilde{\bm{H}}_{t+3}$が得られ，系列は$\bm{H}_t, \bm{H}_{t+1}, \bm{H}_{t+2}, \widetilde{\bm{H}}_{t+3}, \ldots$となる．

この補間後の系列から学習サンプルを構成する方法として，補間値$\widetilde{\bm{H}}$の配置位置に応じて4種類のパターンが考えられる．
\autoref{tab:sample_composition_441}に各パターンの構成を示す．
Labelは補間値を出力として用いる構成であり，First，Middle，Lastはそれぞれ補間値を入力の1番目，2番目，3番目に配置する構成である．

\begin{table}[H]
  \centering
  \caption{補間値の配置位置による学習サンプルの構成}
  \label{tab:sample_composition_441}
  \begin{tabular}{lcccc}
    \hline
    パターン & 入力1 & 入力2 & 入力3 & 出力 \\
    \hline
    Label & $\bm{H}_0$ & $\bm{H}_1$ & $\bm{H}_2$ & $\widetilde{\bm{H}}_3$ \\
    First & $\widetilde{\bm{H}}_3$ & $\bm{H}_4$ & $\bm{H}_5$ & $\bm{H}_6$ \\
    Middle & $\bm{H}_2$ & $\widetilde{\bm{H}}_3$ & $\bm{H}_4$ & $\bm{H}_5$ \\
    Last & $\bm{H}_1$ & $\bm{H}_2$ & $\widetilde{\bm{H}}_3$ & $\bm{H}_4$ \\
    \hline
  \end{tabular}
\end{table}

\subsubsection{ファインチューニング結果}
各サンプル構成を用いてベースラインモデルをファインチューニングし，予測精度の改善率を評価した．
補間手法としてはスプライン補間を採用した．
\autoref{tab:cubic_spline_441_results}にスプライン補間を用いた場合の結果を示す．
表中のファインチューニング後NMSEは5分割交差検証における平均値であり，ベースラインモデル比改善率はベースラインモデルのNMSEからの削減率を表す．

\begin{table}[H]
  \centering
  \caption{スプライン補間における配置位置ごとのファインチューニング結果}
  \label{tab:cubic_spline_441_results}
  \begin{tabular}{lcc}
    \hline
    配置位置 & ファインチューニング後NMSE & ベースラインモデル比改善率 \\
    \hline
    Label  & 0.0319 & 78.5\% \\
    \textbf{First}  & \textbf{0.0303} & \textbf{79.6\%} \\
    Middle & 0.0335 & 77.4\% \\
    Last   & 0.0310 & 79.1\% \\
    \hline
  \end{tabular}
\end{table}

Firstが最良の結果を示し，NMSEは0.030265，ベースラインモデル比改善率は79.56\%となった．
補間値を入力の1番目に配置する構成が最も効果的であることがわかる．
全ての配置位置において77\%以上の改善率が得られており，補間値を用いたファインチューニングが新規基地局への適応に有効であることが確認できる．


\subsubsection{補間手法ごとの予測精度改善率}
続いて，スプライン補間および多項式近似を用いて時系列補間型学習データを作成し，ファインチューニングによる予測精度改善率を評価した．
補間値の配置位置としては，前節の結果に基づきFirstパターンを採用した．

本実験では5分割交差検証を用いて評価を行った．
各分割において，ファインチューニング用データに対して各補間手法を適用し，Firstパターンの学習サンプルを構成してベースラインモデルを更新した．
更新後のモデルを評価用データで検証し，予測精度改善率を算出した．

\autoref{tab:interpolation_method_comparison}に補間手法ごとの予測精度改善率を示す．
表中の補間NMSEは各補間手法が出力する補間値$\widetilde{\bm{H}}$と真値$\bm{H}$との誤差を表す．
ファインチューニング前NMSEはベースラインモデルのNMSE，ファインチューニング後NMSEは更新後モデルのNMSEである．
改善率はファインチューニング前NMSEからの削減率を表し，5分割交差検証における平均値を示す．

\begin{equation}
  \mathrm{improve}
  =\frac{\mathrm{NMSE}_{\mathrm{base}}-\mathrm{NMSE}_{\mathrm{adapted}}}{\mathrm{NMSE}_{\mathrm{base}}}\times 100
  \label{eq:improve_rate}
\end{equation}




\begin{table}[H]
  \centering
  \caption{補間手法ごとの予測精度改善率}
  \label{tab:interpolation_method_comparison}
  \small
  \resizebox{\textwidth}{!}{
    \begin{tabular}{lcccccc}
      \hline
      補間手法 & 補間NMSE & 予測なし & ベースラインモデル & FT後NMSE & ベースラインモデルからの改善率 \\
      \hline
      スプライン補間 & 0.00610 & 0.321 & 0.136 & 0.028 & 79.4\% \\
      片側3点ずつの4次多項式近似 & 0.00590 & 0.321 & 0.136 & 0.028 & 79.4\% \\
      片側3点ずつの5次多項式近似 & 0.00590 & 0.321 & 0.136 & 0.028 & 79.4\% \\
      片側6点ずつの4次多項式近似 & 0.229 & 0.321 & 0.136 & 0.050 & 63.2\% \\
      \hline
    \end{tabular}
  }
\end{table}

スプライン補間，片側3点ずつの4次多項式近似，片側3点ずつの5次多項式近似の3手法は，補間NMSEが0.006程度と高精度であり，ファインチューニング後の改善率も79\%以上を達成した．
一方，片側6点ずつの4次多項式近似は補間NMSEが0.229と低精度であり，改善率は63.24\%にとどまった．

この結果から，補間手法自体の精度がファインチューニング後の予測精度改善率に影響を与えることがわかる．
\autoref{tab:kinshicho_sssp_results}に示したとおり，錦糸町データセットにおいてスプライン補間および片側3点ずつの4次または5次多項式近似が高精度であることが判明していた．
本実験においても，補間精度の高い手法ほど予測精度改善率が高くなる傾向が確認された．
補間NMSEが0.006程度の手法では79\%以上の改善率を達成した一方，補間NMSEが0.229の手法では改善率が63\%程度に低下した．

以上の結果から，時系列補間型学習データを用いたファインチューニングにおいて，補間手法の選定が予測精度に影響を与えることが示された．
高精度な補間手法を用いることで，新規基地局への適応においてより高い予測精度改善率を達成できる．

\subsubsection{学習サンプル数の影響評価}
学習サンプル数を段階的に増加させた場合の予測性能改善を評価する．
ファインチューニングに用いるサンプル数が予測精度に与える影響を明らかにすることで，実運用における必要データ量の指針を得る．

評価対象のベースラインとして，ファインチューニング前のベースラインモデルと予測なしを設定した．
ベースラインモデルのNMSEは0.1326，予測なしのNMSEは0.3621である．
\autoref{tab:sample_size_vs_nmse}に各サンプル数における予測NMSEを示す．
補間手法として，3次スプライン補間，片側3点ずつの4次多項式近似，片側3点ずつの5次多項式近似の3手法を用いた．

\begin{table}[H]
  \centering
  \caption{学習サンプル数と予測NMSEの関係}
  \label{tab:sample_size_vs_nmse}
  \small
  \resizebox{\textwidth}{!}{
    \begin{tabular}{rcccc}
      \hline
      サンプル数 & FT前NMSE & 3次スプライン & 片側3点ずつの4次多項式 & 片側3点ずつの5次多項式 \\
      \hline
      0 & 0.133 & 0.133 & 0.133 & 0.133 \\
      19,575 & 0.133 & 0.188 & 0.188 & 0.188 \\
      39,150 & 0.133 & 0.133 & 0.133 & 0.133 \\
      58,725 & 0.133 & 0.105 & 0.105 & 0.105 \\
      78,300 & 0.133 & 0.0894 & 0.0888 & 0.0892 \\
      97,874 & 0.133 & \textbf{0.0774} & \textbf{0.0770} & \textbf{0.0769} \\
      \hline
    \end{tabular}
  }
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.95\textwidth]{../picture/4nd/443_ft_sample_size_vs_nmse_no_nn_xtick_horizontal.png}
  \caption{学習サンプル数と予測NMSEの関係}
  \label{fig:sample_size_vs_nmse}
\end{figure}

\autoref{tab:sample_size_vs_nmse}および\autoref{fig:sample_size_vs_nmse}から，学習サンプル数の増加に伴いNMSEが減少する傾向が確認できる．
サンプル数0のときはファインチューニングが未実施であり，NMSEは0.1326である．
サンプル数19,575ではNMSEは0.188程度となり，ファインチューニング前と比較して一時的に悪化するが，サンプル数の増加に伴い改善する．
サンプル数39,150ではNMSE 0.133程度に達し，ベースラインモデルのNMSE 0.1326とほぼ同等の性能を示す．これ以上のサンプル数ではベースラインモデルを上回る性能を達成する．

サンプル数97,874では最良の結果が得られ，5次多項式近似でNMSE 0.0769を達成した．
ファインチューニング前と比較して約79\%の改善である．
3つの補間手法間のNMSE差は全てのサンプル数において0.002以内であり，手法間の性能差は小さい．

図中の水平破線はベースラインを示しており，上側の破線が予測なし，下側の破線がファインチューニング前のベースラインモデルである．
サンプル数の増加に伴い，ファインチューニング後のNMSEがベースラインモデルを下回り，十分なサンプル数があれば補間値を用いた学習が有効に機能することが確認できる．





\subsubsection{雑音に対する堅牢性評価}
提案手法の雑音環境下における性能を評価するため，評価用CSIに対して加法性白色ガウス雑音（AWGN）を付与し，各SNRにおける予測NMSEを測定した．

雑音の付与方法を以下に示す．
CSIテンソルを$\bm{H}\in\mathbb{C}^{T\times R_B\times T_x\times R_x}$とする．
SNR[dB]からノイズパワー比$\sigma$を
\begin{equation}
  \sigma=10^{-\frac{\mathrm{SNR}_{\mathrm{dB}}}{10}}
\end{equation}
として算出する．
標準複素ガウス雑音$z\sim\mathcal{CN}(0,1)$を生成し，CSIの平均電力を$P_s=\mathbb{E}\left[|\bm{H}|^2\right]$とする．
雑音を$n=\sqrt{\sigma P_s / 2}\,z$としてスケーリングし，雑音付加後のCSIを
\begin{equation}
  \bm{H}_{\mathrm{noisy}}=\bm{H}+n
\end{equation}
とする．
このとき，信号対雑音電力比は$\mathrm{SNR}=P_s/\mathbb{E}[|n|^2]=1/\sigma$を満たす．

評価対象のベースラインとして，ファインチューニング前の事前学習モデルであるベースラインモデルと，直前フレームをそのまま予測値とする予測なしの場合を設定した．
ベースラインモデルの予測NMSEは0.1439，予測なしのNMSEは0.1755である．
\autoref{tab:baseline_vs_copylast}に示した結果と値が異なるのは，データ分割のランダム性の違いによる．
本評価ではNMSEが比較的小さく算出される区間が評価用データに割り当てられたと考えられる．

評価対象のSNRは$-2$，$0$，$2$，$4$，$6$，$8$，$10$，$15$，$20$~dBとした．
\autoref{tab:noise_snr}に各SNRにおける予測NMSEを示す．
比較対象の補間手法として，3次スプライン補間，片側3点ずつの4次多項式近似，片側3点ずつの5次多項式近似の3手法を用いた．

\begin{table}[H]
  \centering
  \caption{各SNRにおける予測NMSE}
  \label{tab:noise_snr}
  \small
  \resizebox{\textwidth}{!}{
    \begin{tabular}{lccc}
      \hline
      SNR [dB] & 3次スプライン & 片側3点ずつの4次多項式 & 片側3点ずつの5次多項式 \\
      \hline
      クリーン & 0.0310 & 0.0310 & 0.0309 \\
      $-2$ & 0.0817 & 0.0813 & 0.0818 \\
      $0$ & 0.0614 & 0.0617 & 0.0615 \\
      $2$ & 0.0481 & 0.0486 & 0.0487 \\
      $4$ & 0.0411 & 0.0415 & 0.0414 \\
      $6$ & 0.0369 & 0.0371 & 0.0371 \\
      $8$ & 0.0348 & 0.0348 & 0.0343 \\
      $10$ & 0.0333 & 0.0332 & 0.0332 \\
      $15$ & 0.0316 & 0.0315 & 0.0316 \\
      $20$ & 0.0313 & 0.0311 & 0.0312 \\
      \hline
    \end{tabular}
  }
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=100mm]{../picture/4nd/441_snr_nmse_plot.png}
  \caption{各SNRにおける予測NMSE}
  \label{fig:snr_nmse_plot}
\end{figure}

\autoref{tab:noise_snr}および\autoref{fig:snr_nmse_plot}から，SNRが低いほど予測NMSEが大きくなり，SNRが高くなるほど予測NMSEが小さくなることが確認できる．
SNRが$-2$~dBのとき，3次スプライン補間では0.0817，片側3点ずつの4次多項式近似では0.0813，片側3点ずつの5次多項式近似では0.0818のNMSEを示す．
一方，SNRが$20$~dBのとき，各手法のNMSEは0.0313，0.0311，0.0312となり，クリーンな場合の0.0310前後に近づく．
この結果から，ノイズが大きい環境では予測精度が低下するが，SNRが高くなるにつれて予測精度が向上し，ノイズの影響が小さくなる環境ではクリーンな場合と同等の性能を維持できることが示される．

3つの補間手法を比較すると，各SNRにおけるNMSEの差は0.0001から0.0006程度であり，手法間の性能差は小さい．
特にSNRが$8$~dB以上の高SNR領域では，3手法のNMSEはほぼ一致しており，補間手法の選択による性能への影響は限定的である．
このことから，ノイズ環境における予測性能は，補間手法の違いよりもSNRの影響が支配的であると考えられる．





\subsubsection{セル内チャネル統計変動時（NLoSからLoSへの適応）}
\label{sec:evaluation_of_prediction_mechanism_using_time_series_interpolation_learning_data_channel_statistical_variation_within_cell}

本節では，同一セル内においてチャネル統計特性が変動した場合の予測性能を評価する．
前節では異なる地域間でのモデル適応を検証したが，実環境では同一セル内においても建物の建設や解体により電波伝搬環境が変化する場合がある．
本節の実験では，このような環境変化に対する予測モデルの適応性を検証する．

評価用データセットとして，東京駅八重洲口周辺の地形データを用いる．
当該エリアは現在大規模な再開発が進行しており，新たな高層ビルの建設によりセル内の電波伝搬環境が変化する状況を想定できる．
\autoref{fig:area_marunouchi}に示すように，本評価では同一エリアにおいてビル建設前後の2種類の地形データを用意した．
\autoref{fig:marunouchi_built}はビル建設後の状態を示しており，高層ビルにより見通しが遮られたNLoS環境を形成している．
一方，\autoref{fig:marunouchi_before_build}はビル建設前の状態であり，見通しが確保されたLoS環境となっている．

本実験では，NLoS環境で運用していたチャネル予測モデルを環境変化後のLoS環境に適応させる状況を想定する．
ビル建設後のNLoS環境で収集したCSI系列により事前学習を行い，その後ビル解体や都市再開発によりLoS環境へ変化した際に，限られたサンプル数でモデルを再適応させることを目指す．
セル内の環境変化は段階的に生じることが多く，変化直後は新環境に対応した学習データが不足するため，効率的なファインチューニング手法が求められる．

実験手順は前節と同様とする．
事前学習に用いるモデルアーキテクチャおよびハイパーパラメータ，補間手法，ファインチューニングの設定は\autoref{sec:evaluation_of_prediction_mechanism_using_time_series_interpolation_learning_data_new_base_station_installation}と同一である．
本節では事前学習データとして八重洲のビル建設後（NLoS環境，\autoref{fig:marunouchi_built}）の地形データを用い，評価用データセットにはビル建設前（LoS環境，\autoref{fig:marunouchi_before_build}）の地形データを用いる．

\subsubsection{ベースラインモデルの学習結果}
事前学習データを用いたベースラインモデルの学習結果を示す．
\autoref{fig:nlos_to_los_baseline_learning_curves}にベースラインモデルの学習曲線を示す．
横軸はエポック数，縦軸はNMSEである．

\begin{figure}[H]
  \centering
  \includegraphics[width=100mm]{../picture/4nd/443_nlos_to_los_learning_curves_nmse.png}
  \caption{ベースラインモデルの学習曲線（NLoSからLoSへの適応）}
  \label{fig:nlos_to_los_baseline_learning_curves}
\end{figure}

学習用データのNMSEはエポック数の増加に伴い単調に減少し，40エポック終了時点で約0.093に収束している．
検証用データのNMSEは初期エポックで急速に減少した後，約0.12前後で推移しており，15エポック以降はほぼ横ばいとなっている．
学習用データと検証用データのNMSEに約0.03の差が生じているが，検証用データのNMSEが発散していないことから，過学習の兆候は軽微であると判断できる．
学習曲線の挙動は前節の\autoref{fig:baseline_learning_curves}と類似しており，モデルが安定して収束していることが確認できる．

次に，ファインチューニングを行わない状態でのベースラインモデルの予測性能を評価する．
\autoref{tab:nlos_to_los_baseline_vs_copylast}に，八重洲のLoS環境における評価結果を示す．
予測なしとは前節と同様に，入力3フレームの最終時刻におけるCSI推定値をそのまま出力時刻の推定値として使用する手法である．

\begin{table}[H]
  \centering
  \caption{ベースラインモデルと予測なしのNMSE比較（NLoSからLoSへの適応）}
  \label{tab:nlos_to_los_baseline_vs_copylast}
  \begin{tabular}{crr}
    \hline
    Fold & ベースラインモデル（FT前） & 予測なし \\
    \hline
    0 & 0.328 & 0.201 \\
    1 & 0.438 & 0.179 \\
    2 & 0.303 & 0.092 \\
    3 & 0.310 & 0.095 \\
    4 & 0.410 & 0.140 \\
    \hline
    平均 & 0.358 & 0.141 \\
    \hline
  \end{tabular}
\end{table}

ベースラインモデル（ファインチューニング前）のNMSEは平均0.358であり，予測なしの平均0.141と比較して大きい値を示している．
この結果は，NLoS環境で学習したモデルがLoS環境に対して適切に汎化できていないことを示す．
前節の新基地局設置時の評価ではベースラインモデルが予測なしを上回る性能を示したが，本実験ではチャネル統計特性の変化により予測精度が大幅に低下している．
NLoS環境とLoS環境では電波伝搬特性が根本的に異なるため，事前学習で獲得したチャネル予測能力が新環境に適用できていない．
この結果から，セル内の環境変化に対応するためにはファインチューニングによるモデル適応が必要であることが示唆される．

\subsubsection{ファインチューニング結果}
ベースラインモデルに対してファインチューニングを実施し，予測精度の改善を評価する．
補間手法の選定にあたっては，\autoref{tab:marunouchi_sssp_results}に示した八重洲データセットにおける補間精度評価の結果を参考にする．
同評価では，スプライン補間および4次または5次の多項式近似がNMSE 0.05程度と最良の精度を達成することが確認されている．
本実験ではこれらの手法を採用し，補間値を用いたファインチューニングを実施する．

学習サンプルの構成については，前節の\autoref{tab:cubic_spline_441_results}において補間値を入力の1番目に配置するFirstパターンが最良の改善率を示したことから，本実験でもFirstパターンを採用する．

\autoref{tab:nlos_to_los_finetuning_results}に各補間手法を用いたファインチューニング結果を示す．
表中のFT後NMSEおよび改善率は5分割交差検証における平均$\pm$標準偏差であり，改善率は各foldにおけるベースラインモデル（FT前）のNMSEからの削減率を集計したものである．

\begin{table}[H]
  \centering
  \caption{補間手法ごとのファインチューニング結果（NLoSからLoSへの適応）}
  \label{tab:nlos_to_los_finetuning_results}
  \small
  \resizebox{\textwidth}{!}{
    \begin{tabular}{lccccc}
      \hline
      補間手法 & 補間NMSE & 予測なし & ベースラインモデル & FT後NMSE & ベースラインモデルからの改善率 \\
      \hline
      スプライン補間 & 0.0456 & 0.141 & 0.358 & 0.098$\pm$0.023 & 72.8$\pm$3.57\% \\
      片側3点ずつの4次多項式近似 & 0.0463 & 0.141 & 0.358 & \textbf{0.096$\pm$0.024} & \textbf{73.4$\pm$3.44\%} \\
      片側3点ずつの5次多項式近似 & 0.0463 & 0.141 & 0.358 & 0.098$\pm$0.023 & 72.9$\pm$3.55\% \\
      \hline
    \end{tabular}
  }
\end{table}

4次多項式近似が最良の結果を示し，NMSEは0.0960となった．
5次多項式近似およびスプライン補間も同程度の精度を達成しており，3手法間のNMSE差は0.002以内に収まっている．
ファインチューニング前のベースラインモデル（FT前）と比較すると，4次多項式近似では改善率がFold平均で\(73.35 \pm 3.44\)\%となった．
予測なしと比較しても，ファインチューニング後のモデルは全foldでNMSEが低く，環境変化に対して有効に適応できていることが確認できる．
この結果から，時系列補間型学習データを用いたファインチューニングにより，セル内の環境変化に対してもモデルを効果的に適応できることが確認された．

次に，ファインチューニングに用いる学習サンプル数と予測精度の関係を評価する．
実運用においては新環境でのデータ収集量が限られる場合があるため，少量のサンプルでどの程度の性能改善が得られるかを把握することは重要である．
\autoref{fig:nlos_to_los_incremental_finetune}に，学習サンプル数を変化させた場合のファインチューニング後NMSEを示す．

比較対象の補間手法として，スプライン補間，片側3点ずつの4次多項式近似，片側3点ずつの5次多項式近似に加え，ニューラルネットワーク補間（コンテキスト長3）を追加した．
ニューラルネットワーク補間は第\ref{sec:interpolation_methods}節で述べた手法であり，補間精度が低い場合にファインチューニング性能がどのように変化するかを検証するために比較対象として含めた．
第\ref{subsec:simulation_conditions}節の補間精度評価において，ニューラルネットワーク補間は多項式近似やスプライン補間と比較して補間NMSEが高い傾向にあることが確認されている．
したがって，ニューラルネットワーク補間を用いたファインチューニングでは，補間精度の劣化がどの程度予測性能に影響を与えるかを観察できる．

\begin{figure}[H]
  \centering
  \includegraphics[width=0.95\textwidth]{../picture/4nd/442_NLoS_to_Los_incremental_finetune_nmse_vs_samples.png}
  \caption{学習サンプル数とファインチューニング後NMSEの関係（NLoSからLoSへの適応）}
  \label{fig:nlos_to_los_incremental_finetune}
\end{figure}

\autoref{fig:nlos_to_los_incremental_finetune}から，全ての補間手法において学習サンプル数の増加に伴いNMSEが単調に減少する傾向が確認できる．
図中の上側の水平破線はファインチューニング前のベースラインモデル（NMSE約0.36），下側の水平破線は予測なし（NMSE約0.13）を示す．

スプライン補間，4次多項式近似，5次多項式近似の3手法は，全てのサンプル数において同程度のNMSEを示しており，曲線がほぼ重なっている．
これらの手法では，学習サンプル数が20,000の時点でNMSEが約0.19となり，ベースラインモデルに対して約47\%の改善を達成している．
学習サンプル数が40,000に達するとNMSEは約0.13となり，予測なしと同等の性能に到達する．
さらに学習サンプル数を増加させると，60,000サンプルでNMSEは約0.10，100,000サンプルでNMSEは約0.08となり，予測なしを大幅に上回る性能を達成している．

一方，ニューラルネットワーク補間（コンテキスト長3）は，他の3手法と比較してNMSEが一貫して高い値を示している．
学習サンプル数が20,000のときNMSEは約0.20であり，スプライン補間等の約0.19と比較して若干高い．
この差異は学習サンプル数の増加に伴い拡大し，100,000サンプルにおいてニューラルネットワーク補間のNMSEは約0.09であるのに対し，スプライン補間等は約0.08となっている．

この結果から，補間精度がファインチューニング後の予測精度に影響を与えることが確認された．
ニューラルネットワーク補間は補間NMSEが他手法より高いため，生成される学習サンプルの品質が相対的に低く，これがファインチューニング後の予測性能の低下につながっている．
ただし，ニューラルネットワーク補間を用いた場合でもベースラインモデルや予測なしを上回る性能を達成しており，補間精度が多少低い場合でも提案手法が有効に機能することが示された．

以上の結果から，補間手法の選択においては補間精度が高い手法を優先すべきであること，また学習サンプル数が限られる状況でも提案手法により一定の性能改善が得られることが確認された．




\subsubsection{雑音に対する堅牢性評価}
提案手法の雑音環境下における性能を評価するため，評価用CSIに対して加法性白色ガウス雑音を付与し，各SNRにおける予測NMSEを測定した．
雑音の付与方法は\autoref{sec:evaluation_of_prediction_mechanism_using_time_series_interpolation_learning_data_new_base_station_installation}と同様である．

評価対象のSNRは$-2$，$0$，$2$，$4$，$6$，$8$，$10$，$15$，$20$~dBとした．
比較対象の補間手法として，3次スプライン補間，片側3点ずつの4次多項式近似，片側3点ずつの5次多項式近似の3手法を用いた．
\autoref{tab:nlos_to_los_noise_snr}に各SNRにおける予測NMSEを示す．

\begin{table}[H]
  \centering
  \caption{各SNRにおける予測NMSE（NLoSからLoSへの適応）}
  \label{tab:nlos_to_los_noise_snr}
  \small
  \resizebox{\textwidth}{!}{
    \begin{tabular}{lccc}
      \hline
      SNR [dB] & 3次スプライン & 片側3点ずつの4次多項式 & 片側3点ずつの5次多項式 \\
      \hline
      クリーン & 0.0766 & 0.0768 & 0.0769 \\
      $20$ & 0.0766 & 0.0767 & 0.0768 \\
      $15$ & 0.0767 & 0.0770 & 0.0771 \\
      $10$ & 0.0782 & 0.0784 & 0.0785 \\
      $8$ & 0.0806 & 0.0807 & 0.0807 \\
      $6$ & 0.0850 & 0.0849 & 0.0849 \\
      $4$ & 0.0921 & 0.0916 & 0.0917 \\
      $2$ & 0.102 & 0.101 & 0.102 \\
      $0$ & 0.112 & 0.110 & 0.110 \\
      $-2$ & 0.132 & 0.131 & 0.131 \\
      \hline
    \end{tabular}
  }
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.95\textwidth]{../picture/4nd/443_input_snr_nmse_fullwidth_baselines.png}
  \caption{各SNRにおける予測NMSE（NLoSからLoSへの適応）}
  \label{fig:nlos_to_los_snr_nmse_plot}
\end{figure}

\autoref{tab:nlos_to_los_noise_snr}および\autoref{fig:nlos_to_los_snr_nmse_plot}から，SNRの低下に伴い予測NMSEが増加する傾向が確認できる．
SNRが$-2$~dBのとき，3次スプライン補間では0.1324，片側3点ずつの4次多項式近似では0.1307，片側3点ずつの5次多項式近似では0.1311のNMSEを示す．
一方，SNRが$20$~dB以上の高SNR領域では，各手法のNMSEは0.077程度となり，クリーンな場合とほぼ同等の性能を維持している．

図中の水平破線はベースラインを示しており，上側の破線がファインチューニング前のベースラインモデル，下側の破線が予測なしである．
ファインチューニング後のモデルは，SNRが$-2$~dBの低SNR環境においても予測なしと同程度のNMSEを達成しており，SNRが$0$~dB以上では予測なしを下回る性能を示している．
ファインチューニング前のベースラインモデルと比較すると，全てのSNR条件においてファインチューニング後のモデルが大幅に低いNMSEを達成している．

3つの補間手法を比較すると，各SNRにおけるNMSEの差は0.002以内であり，手法間の性能差は小さい．
特にSNRが$8$~dB以上の高SNR領域では，3手法のNMSEはほぼ一致している．
前節の新基地局設置時の評価と同様に，ノイズ環境における予測性能は補間手法の違いよりもSNRの影響が支配的である．

\subsection{セル内チャネル統計変動時}
\subsubsection{セル内チャネル統計変動時（LoSからNLoSへの適応）}
\label{sec:evaluation_of_prediction_mechanism_using_time_series_interpolation_learning_data_los_to_nlos}

前節ではNLoS環境からLoS環境への適応を検証したが，本節では逆方向の適応，すなわちLoS環境からNLoS環境への適応について評価する．
都市部においては新規ビルの建設により，従来見通しが確保されていたセルにおいて遮蔽物が出現しNLoS環境へ移行する状況が頻繁に生じる．
このような環境変化に対しても，提案する時系列補間型ファインチューニング手法が有効であるかを検証する．

本実験では，ビル建設以前のLoS環境で収集したCSI系列により事前学習を行い，その後ビル建設によりNLoS環境へ変化した際に，限られたサンプル数でモデルを再適応させることを想定する．
前節の評価ではNLoS環境で運用していたモデルをLoS環境に適応させたが，本節では逆にLoS環境で運用していたチャネル予測モデルをNLoS環境に適応させる．
LoS環境からNLoS環境への移行では，直接波が遮蔽されることでチャネルの変動特性が大きく変化するため，モデルの適応がより困難になることが予想される．

評価用データセットには，前節と同様に東京駅八重洲口周辺の地形データを用いる．
\autoref{fig:area_marunouchi}に示した2種類の地形データのうち，本節ではビル建設前のLoS環境（\autoref{fig:marunouchi_before_build}）を事前学習に用い，ビル建設後のNLoS環境（\autoref{fig:marunouchi_built}）を評価対象とする．
すなわち，前節とは事前学習環境と評価環境の役割を入れ替えた設定である．

実験手順は前節と同様とする．
事前学習に用いるモデルアーキテクチャおよびハイパーパラメータは\autoref{sec:evaluation_of_prediction_mechanism_using_time_series_interpolation_learning_data_new_base_station_installation}と同一である．
補間手法には，第\ref{subsec:simulation_conditions}節において有効性が確認されたスプライン補間，片側3点ずつの4次多項式近似，片側3点ずつの5次多項式近似の3手法を用いる．
ファインチューニングの設定は前節と同様に，補間値を入力の1番目に配置するFirstパターンを採用する．









\subsubsection{ベースラインモデルの学習結果}
LoS環境の事前学習データを用いたベースラインモデルの学習結果を示す．
\autoref{fig:los_to_nlos_baseline_learning_curves}にベースラインモデルの学習曲線を示す．
横軸はエポック数，縦軸はNMSEである．

\begin{figure}[H]
  \centering
  \includegraphics[width=100mm]{../picture/4nd/442_learning_curves_nmse_LoS_NLoS.png}
  \caption{ベースラインモデルの学習曲線（LoSからNLoSへの適応）}
  \label{fig:los_to_nlos_baseline_learning_curves}
\end{figure}

学習用データのNMSEはエポック数の増加に伴い減少し，40エポック終了時点で約0.08に収束している．
検証用データのNMSEは初期エポックで急速に減少した後，約0.12前後で推移している．
学習用データと検証用データのNMSEに約0.04の差が生じているが，検証用データのNMSEが発散していないことから，過学習の兆候は軽微であると判断できる．
前節のNLoS環境での事前学習（\autoref{fig:nlos_to_los_baseline_learning_curves}）と比較すると，LoS環境での学習は検証用NMSEが若干高い傾向にあるが，学習の収束挙動は同様である．

次に，ファインチューニングを行わない状態でのベースラインモデルの予測性能を評価する．
\autoref{tab:los_to_nlos_baseline_vs_copylast}に，八重洲のNLoS環境における評価結果を示す．
予測なしとは前節と同様に，入力3フレームの最終時刻におけるCSI推定値をそのまま出力時刻の推定値として使用する手法である．

\begin{table}[H]
  \centering
  \caption{ベースラインモデルと予測なしのNMSE比較（LoSからNLoSへの適応）}
  \label{tab:los_to_nlos_baseline_vs_copylast}
  \begin{tabular}{crr}
    \hline
    Fold & ベースラインモデル（FT前） & 予測なし \\
    \hline
    0 & 0.506 & 0.205 \\
    1 & 0.487 & 0.209 \\
    2 & 0.496 & 0.221 \\
    3 & 0.484 & 0.193 \\
    4 & 0.462 & 0.201 \\
    \hline
    平均 & 0.487 & 0.206 \\
    \hline
  \end{tabular}
\end{table}

ベースラインモデル（ファインチューニング前）のNMSEは平均0.487であり，予測なしの平均0.206と比較して約2.4倍大きい値を示している．
この結果は，LoS環境で学習したモデルがNLoS環境に対して適切に汎化できていないことを示す．
前節のNLoS→LoS適応（ベースラインNMSE 0.4096）と比較して，本節のLoS→NLoS適応ではベースラインNMSEがより高い値を示している．
LoS環境では直接波が支配的であり比較的単純なチャネル特性を学習するが，NLoS環境では多重反射による複雑な伝搬経路が存在するため，環境変化に伴う特性変動が大きく，モデルの汎化がより困難になっていると考えられる．
この結果から，LoS→NLoS適応においてもファインチューニングによるモデル適応が必要であることが示唆される．

\subsubsection{ファインチューニング結果}
ベースラインモデルに対してファインチューニングを実施し，予測精度の改善を評価する．
補間手法の選定にあたっては，第\ref{subsec:simulation_conditions}節において有効性が確認されたスプライン補間，片側3点ずつの4次多項式近似，片側3点ずつの5次多項式近似を採用する．
学習サンプルの構成については，前節と同様に補間値を入力の1番目に配置するFirstパターンを用いる．

\autoref{tab:los_to_nlos_finetuning_results}に各補間手法を用いたファインチューニング結果を示す．
表中のFT後NMSEおよび改善率は5分割交差検証における平均$\pm$標準偏差である．

\begin{table}[H]
  \centering
  \caption{補間手法ごとのファインチューニング結果（LoSからNLoSへの適応）}
  \label{tab:los_to_nlos_finetuning_results}
  \small
  \resizebox{\textwidth}{!}{
    \begin{tabular}{lccccc}
      \hline
      補間手法 & 補間NMSE & 予測なし & ベースラインモデル & FT後NMSE & ベースラインモデルからの改善率 \\
      \hline
      スプライン補間 & 0.0574 & 0.206 & 0.487 & 0.128$\pm$0.017 & 73.8$\pm$3.22\% \\
      片側3点ずつの4次多項式近似 & 0.0580 & 0.206 & 0.487 & 0.128$\pm$0.017 & 73.8$\pm$3.24\% \\
      \textbf{片側3点ずつの5次多項式近似} & 0.0580 & 0.206 & 0.487 & \textbf{0.127$\pm$0.017} & \textbf{73.8$\pm$3.25\%} \\
      \hline
    \end{tabular}
  }
\end{table}

5次多項式近似が最良の結果を示し，NMSEは0.127$\pm$0.017となった．
スプライン補間および4次多項式近似も同程度の精度を達成しており，3手法間のNMSE差は0.001以内に収まっている．
ファインチューニング前のベースラインモデルのNMSE 0.487と比較すると，5次多項式近似では改善率$73.83 \pm 3.25$\%を達成した．
予測なしのNMSE 0.206と比較しても，ファインチューニング後のモデルは約38\%低いNMSEを達成している．

前節のNLoS→LoS適応（FT後NMSE 0.096，改善率約73\%）と比較すると，本節のLoS→NLoS適応ではFT後NMSEがやや高く（0.127），改善率は同程度（約74\%）である．
これは，NLoS環境における複雑なチャネル特性が予測をより困難にしているためと考えられる．
しかしながら，提案手法により大幅な性能改善が得られており，セル内の環境変化に対してもモデルを効果的に適応できることが確認された．

次に，ファインチューニングに用いる学習サンプル数と予測精度の関係を評価する．
前節のNLoS→LoS適応と同様に，少量のサンプルでどの程度の性能改善が得られるかを把握することは実運用において重要である．
\autoref{fig:los_to_nlos_incremental_finetune}に，学習サンプル数を変化させた場合のファインチューニング後NMSEを示す．

比較対象の補間手法として，スプライン補間，片側3点ずつの4次多項式近似，片側3点ずつの5次多項式近似の3手法を用いた．

\begin{figure}[H]
  \centering
  \includegraphics[width=0.95\textwidth]{../picture/4nd/442_LoS_to_NLoS_incremental_finetune_nmse_vs_samples.png}
  \caption{学習サンプル数とファインチューニング後NMSEの関係（LoSからNLoSへの適応）}
  \label{fig:los_to_nlos_incremental_finetune}
\end{figure}

\autoref{fig:los_to_nlos_incremental_finetune}から，全ての補間手法において学習サンプル数の増加に伴いNMSEが単調に減少する傾向が確認できる．
図中の上側の水平破線はファインチューニング前のベースラインモデル（NMSE約0.49），下側の水平破線は予測なし（NMSE約0.19）を示す．

スプライン補間，4次多項式近似，5次多項式近似の3手法は，全てのサンプル数において同程度のNMSEを示しており，曲線がほぼ重なっている．
これらの手法では，学習サンプル数が25,000の時点でNMSEが約0.22となり，ベースラインモデルに対して約55\%の改善を達成している．
学習サンプル数が50,000に達するとNMSEは約0.175となり，予測なしを下回る性能に到達する．
さらに学習サンプル数を増加させると，70,000サンプルでNMSEは約0.15，90,000サンプルでNMSEは約0.135となり，120,000サンプルではNMSEは約0.125となって予測なしを大幅に上回る性能を達成している．

前節のNLoS→LoS適応（\autoref{fig:nlos_to_los_incremental_finetune}）と比較すると，本節のLoS→NLoS適応では予測なしを下回るために必要なサンプル数がより多い傾向にある．
NLoS→LoS適応では約40,000サンプルで予測なしと同等になるのに対し，LoS→NLoS適応では約50,000サンプルが必要である．
また，最終的なNMSEについても，NLoS→LoS適応では100,000サンプルで約0.08に達するのに対し，LoS→NLoS適応では120,000サンプルでも約0.125にとどまっている．
これらの差異は，NLoS環境におけるチャネル変動の複雑さが予測をより困難にしていることを反映している．

ただし，LoS→NLoS適応においても学習サンプル数の増加に伴う一貫した性能改善が確認されており，十分なサンプル数を確保することで高い予測精度を達成できることが示された．






\subsubsection{雑音に対する堅牢性評価}
提案手法の雑音環境下における性能を評価するため，評価用CSIに対して加法性白色ガウス雑音を付与し，各SNRにおける予測NMSEを測定した．
雑音の付与方法は\autoref{sec:evaluation_of_prediction_mechanism_using_time_series_interpolation_learning_data_new_base_station_installation}と同様である．

評価対象のSNRは$-2$，$0$，$2$，$4$，$6$，$8$，$10$，$15$，$20$~dBとした．
比較対象の補間手法として，3次スプライン補間，片側3点ずつの4次多項式近似，片側3点ずつの5次多項式近似の3手法を用いた．
\autoref{tab:los_to_nlos_noise_snr}に各SNRにおける予測NMSEを示す．

\begin{table}[H]
  \centering
  \caption{各SNRにおける予測NMSE（LoSからNLoSへの適応）}
  \label{tab:los_to_nlos_noise_snr}
  \small
  \resizebox{\textwidth}{!}{
    \begin{tabular}{lccc}
      \hline
      SNR [dB] & 3次スプライン & 片側3点ずつの4次多項式 & 片側3点ずつの5次多項式 \\
      \hline
      クリーン & 0.127 & 0.127 & \textbf{0.126} \\
      $20$ & 0.127 & 0.127 & \textbf{0.126} \\
      $15$ & 0.127 & 0.127 & \textbf{0.127} \\
      $10$ & 0.130 & 0.128 & \textbf{0.128} \\
      $8$ & 0.130 & 0.131 & \textbf{0.130} \\
      $6$ & 0.134 & \textbf{0.134} & 0.133 \\
      $4$ & 0.139 & 0.140 & \textbf{0.139} \\
      $2$ & 0.147 & 0.148 & \textbf{0.147} \\
      $0$ & 0.160 & \textbf{0.160} & 0.160 \\
      $-2$ & 0.181 & 0.181 & \textbf{0.181} \\
      \hline
    \end{tabular}
  }
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.95\textwidth]{../picture/4nd/442_snr_nmse_plot.png}
  \caption{各SNRにおける予測NMSE（LoSからNLoSへの適応）}
  \label{fig:los_to_nlos_snr_nmse_plot}
\end{figure}

\autoref{tab:los_to_nlos_noise_snr}および\autoref{fig:los_to_nlos_snr_nmse_plot}から，SNRの低下に伴い予測NMSEが増加する傾向が確認できる．
SNRが$-2$~dBのとき，3次スプライン補間では0.1806，片側3点ずつの4次多項式近似では0.1811，片側3点ずつの5次多項式近似では0.1805のNMSEを示す．
一方，SNRが$20$~dB以上の高SNR領域では，各手法のNMSEは0.127程度となり，クリーンな場合とほぼ同等の性能を維持している．

図中の水平破線はベースラインを示しており，上側の破線がファインチューニング前のベースラインモデル（NMSE 0.4921），下側の破線が予測なし（NMSE 0.1901）である．
ファインチューニング後のモデルは，SNRが$-2$~dBの低SNR環境においても予測なしを下回るNMSE（約0.18）を達成している．
SNRが$0$~dB以上では，ファインチューニング後のモデルは予測なしと比較して大幅に低いNMSEを示している．
ファインチューニング前のベースラインモデルと比較すると，全てのSNR条件においてファインチューニング後のモデルが大幅に低いNMSEを達成している．

3つの補間手法を比較すると，各SNRにおけるNMSEの差は0.001以内であり，手法間の性能差は極めて小さい．
特にSNRが$10$~dB以上の高SNR領域では，3手法のNMSEはほぼ一致している．
前節のNLoS→LoS適応と同様に，ノイズ環境における予測性能は補間手法の違いよりもSNRの影響が支配的である．

前節のNLoS→LoS適応（\autoref{tab:nlos_to_los_noise_snr}）と比較すると，本節のLoS→NLoS適応ではSNRが$-2$~dBのときのNMSEが0.18程度であり，前節の0.13程度よりも高い値を示している．
これは，NLoS環境における複雑なチャネル特性が雑音環境下においても予測を困難にしていることを示唆する．
しかしながら，いずれのSNR条件においてもファインチューニング後のモデルは予測なしおよびベースラインモデルを上回る性能を示しており，提案手法の有効性が確認された．

\subsubsection{セル内チャネル統計変動における双方向適応の比較考察}
\label{sec:bidirectional_adaptation_comparison}

本節では，セル内チャネル統計変動時における2つの適応方向，すなわちNLoS→LoS適応（\autoref{sec:evaluation_of_prediction_mechanism_using_time_series_interpolation_learning_data_channel_statistical_variation_within_cell}）とLoS→NLoS適応（\autoref{sec:evaluation_of_prediction_mechanism_using_time_series_interpolation_learning_data_los_to_nlos}）の実験結果を比較し，適応方向の違いが予測性能に与える影響について考察する．

\subsubsection{実験結果の比較}
\autoref{tab:bidirectional_comparison}に両方向の適応実験における主要な評価指標を整理する．

\begin{table}[H]
  \centering
  \caption{NLoS→LoS適応とLoS→NLoS適応の比較}
  \label{tab:bidirectional_comparison}
  \begin{tabular}{lcc}
    \hline
    評価指標 & NLoS→LoS & LoS→NLoS \\
    \hline
    予測なし NMSE & 0.140 & 0.206 \\
    ベースラインNMSE（FT前） & 0.410 & 0.487 \\
    FT後NMSE（最良） & 0.0960 & 0.128 \\
    改善率 & 約76\% & 約74\% \\
    最良補間手法 & 4次多項式近似 & 5次多項式近似 \\
    SNR $-2$~dB時NMSE & 0.13程度 & 0.18程度 \\
    \hline
  \end{tabular}
\end{table}

\autoref{tab:bidirectional_comparison}から，全ての評価指標においてNLoS→LoS適応がLoS→NLoS適応よりも優れた結果を示していることが確認できる．
以下では，この差異が生じる要因について物理的な観点から考察する．

\subsubsection{LoS環境とNLoS環境のチャネル特性の違い}
LoS環境とNLoS環境では，電波伝搬の物理的メカニズムが根本的に異なる．
LoS環境では送受信間に直接波が存在し，この直接波がチャネル応答の主成分となる．
直接波は伝搬距離に応じた位相回転と自由空間伝搬損失により特徴づけられ，ユーザの移動に伴うドップラー周波数シフトも比較的予測しやすい挙動を示す．
したがって，LoS環境のチャネル時系列は滑らかな変動パターンを持ち，時間的相関が強い傾向にある．

一方，NLoS環境では直接波が遮蔽物により遮断され，散乱波や反射波のみがチャネル応答を構成する．
複数の反射経路が干渉し合うことでマルチパスフェージングが生じ，チャネル応答は振幅と位相の両方において急激な変動を示す．
特に，各反射経路の遅延時間と到来角が異なるため，ユーザの微小な移動でも経路間の位相関係が大きく変化し，チャネル時系列は複雑で予測困難なパターンとなる．

\subsubsection{予測なし性能の差異に関する考察}
予測なし手法は直前のCSI推定値をそのまま将来時刻の推定値として使用するため，その性能はチャネルの時間的相関に強く依存する．
\autoref{tab:bidirectional_comparison}において，LoS環境での予測なし NMSE（0.1397）がNLoS環境（0.2056）より約32\%低い値を示している．
この差異は，LoS環境のチャネルがより強い時間的相関を持ち，時間変動が緩やかであることを反映している．

NLoS環境では，マルチパスフェージングによる急激なチャネル変動が生じるため，直前の観測値と現在の真値との乖離が大きくなる．
この結果として，予測なし手法の予測誤差が増大し，NLoS環境での予測なし NMSEが高い値を示している．

\subsubsection{ベースラインモデルの汎化性能に関する考察}
ファインチューニング前のベースラインモデルのNMSEは，NLoS→LoS適応で0.4096，LoS→NLoS適応で0.4869であり，LoS→NLoS適応の方が約19\%高い値を示している．
この差異は，事前学習環境と評価環境の特性差がモデルの汎化性能に与える影響を示唆している．

NLoS→LoS適応では，複雑なNLoS環境で事前学習したモデルを比較的単純なLoS環境に適用する．
NLoS環境での学習により，モデルは多様なチャネル変動パターンを学習しており，LoS環境における規則的な変動パターンに対しても一定程度の予測能力を発揮できると考えられる．
すなわち，複雑な環境での学習が単純な環境への汎化を部分的に可能にしている．

一方，LoS→NLoS適応では，比較的単純なLoS環境で事前学習したモデルを複雑なNLoS環境に適用する．
LoS環境では直接波が支配的であり，チャネル変動は主にドップラー効果による滑らかな位相回転として現れる．
このような限定的なパターンのみを学習したモデルは，NLoS環境における急激な振幅変動やマルチパスフェージングに対応できず，汎化性能が低下する．
この結果として，LoS→NLoS適応ではベースラインNMSEがより高い値を示している．

\subsubsection{ファインチューニング効果の差異に関する考察}
ファインチューニング後のNMSEは，NLoS→LoS適応で0.0960，LoS→NLoS適応で0.1275であり，約33\%の差が生じている．
改善率についても，NLoS→LoS適応が約76\%，LoS→NLoS適応が約74\%と，若干の差異が見られる．

この差異は，目標環境であるLoS環境とNLoS環境の本質的な予測困難度の違いに起因すると考えられる．
前述のように，LoS環境のチャネルは時間的相関が強く滑らかに変動するため，時系列予測モデルにとって学習・予測が容易である．
一方，NLoS環境のチャネルは急激な変動を示すため，同程度の学習データとモデル容量では，LoS環境と同等の予測精度を達成することが困難である．

ただし，両方向とも70\%以上の改善率を達成しており，提案する時系列補間型ファインチューニング手法は適応方向に関わらず有効に機能することが確認された．
LoS→NLoS適応においても予測なしと比較して約38\%のNMSE改善を達成しており，実用上十分な性能向上が得られている．

\subsubsection{雑音環境下における性能差に関する考察}
SNRが$-2$~dBの低SNR環境において，NLoS→LoS適応ではNMSEが0.13程度，LoS→NLoS適応では0.18程度を示しており，約38\%の差が生じている．
この差異は，クリーン環境での性能差（約33\%）よりも拡大している．

雑音環境では，CSI推定値に加法性雑音が重畳されるため，時系列データから真のチャネル変動パターンを抽出することがより困難になる．
NLoS環境では元来チャネル変動が複雑であるため，雑音の影響を受けた際に真のチャネル変動と雑音成分を分離することがより困難になる．
この結果として，LoS→NLoS適応では雑音環境における性能劣化がより顕著に現れている．

しかしながら，LoS→NLoS適応においてもSNRが$-2$~dBの条件で予測なし（NMSE 0.1901）を下回る性能を維持しており，提案手法は雑音環境においても有効に機能することが確認された．



\section{パイロット疎化拡大に伴う無線チャネル予測機構評価}
\label{sec:evaluation_of_prediction_mechanism_using_time_series_interpolation_learning_data_pilot_sparse_expansion}

前節までの評価では，3入力1出力の機械学習モデルを用いた．
パイロット信号の送信周期を5~msとすると，この設定は20~msあたり1回のパイロット送信を予測により削減できることを意味する．
すなわち，4スロット中3スロットで推定値を取得し，残り1スロットの参照信号送信を省略する運用に相当する．

本節では，パイロット信号の削減割合をさらに大きくした場合についても，提案したチャネル予測機構によりモデルの精度を改善しつつ運用が可能であるかを評価する．

入出力の時間間隔を変化させることで，同一の3入力1出力モデルを用いながらパイロット送信の削減割合を増加させることが可能である．
疎化パターンは，推定値$\bm{H}$が得られるスロットと予測値$\widehat{\bm{H}}$で代替するスロットの周期的な配置として定義する．
本研究では，周期4出力1パターン，周期3出力1パターン，周期2出力1パターンの3種類を検討する．

各パターンの時系列配置と予測モデルへの入出力対応を\autoref{tab:sparsity_patterns}に示す．

\begin{table}[H]
  \centering
  \caption{疎化パターンと入出力の対応}
  \label{tab:sparsity_patterns}
  \begin{tabular}{lccc}
    \hline
    パターン & 時系列配置 & 入力 & 出力 \\
    \hline
    周期4出力1 & $\bm{H}, \bm{H}, \bm{H}, \widehat{\bm{H}}, \cdots$ & $\bm{H}_{t-3}, \bm{H}_{t-2}, \bm{H}_{t-1}$ & $\widehat{\bm{H}}_t$ \\
    周期3出力1 & $\bm{H}, \bm{H}, \widehat{\bm{H}}, \cdots$ & $\bm{H}_{t-4}, \bm{H}_{t-2}, \bm{H}_{t-1}$ & $\widehat{\bm{H}}_t$ \\
    周期2出力1 & $\bm{H}, \widehat{\bm{H}}, \cdots$ & $\bm{H}_{t-5}, \bm{H}_{t-3}, \bm{H}_{t-1}$ & $\widehat{\bm{H}}_t$ \\
    \hline
  \end{tabular}
\end{table}

周期4出力1パターンでは4スロット中1スロットを予測で代替し，削減率は25\%である．
周期3出力1パターンでは3スロット中1スロットを予測で代替し，削減率は約33\%となる．
周期2出力1パターンでは2スロット中1スロットを予測で代替し，削減率は50\%に達する．

いずれのパターンでも，予測対象となる$\widehat{\bm{H}}$スロットの直前に存在する3つの$\bm{H}$スロットを入力として選択する．
周期4出力1パターンでは直前3スロットが連続して$\bm{H}$であるため，時刻$t-3, t-2, t-1$のCSIを入力とする．
周期3出力1パターンでは$t-3$が$\widehat{\bm{H}}$スロットとなるため，これを避けて$t-4, t-2, t-1$を選択する．
周期2出力1パターンでは1スロットおきに$\widehat{\bm{H}}$が配置されるため，$t-5, t-3, t-1$の3点を選択する．

このように入力の時間間隔を調整することで，モデルの入出力形式を3入力1出力に統一したまま，異なる削減率に対応した学習データを生成できる．

提案機構では，補間値を用いてファインチューニング用の学習サンプルを構成する．
各疎化パターンにおいて，サンプルの構成方法は複数存在する．
入力の3スロットと出力の1スロットに対して，推定値$\bm{H}$と補間値$\widetilde{\bm{H}}$をどのように配置するかによって異なる学習サンプルが得られる．
本研究では，パターンごとに2種類のサンプル構成を比較し，どの構成が予測精度の改善に有効であるかを検証した．

各疎化パターンにおけるファインチューニング用サンプルの構成を\autoref{tab:ft_sample_config}に示す．

\begin{table}[H]
  \centering
  \caption{ファインチューニング用サンプルの構成}
  \label{tab:ft_sample_config}
  \begin{tabular}{llcc}
    \hline
    パターン & 構成名 & 入力 & 出力 \\
    \hline
    周期3出力1 & $\widetilde{\bm{H}}\bm{H}\widetilde{\bm{H}}\rightarrow\bm{H}$ & $\widetilde{\bm{H}}, \bm{H}, \widetilde{\bm{H}}$ & $\bm{H}$ \\
    周期3出力1 & $\bm{H}\widetilde{\bm{H}}\bm{H}\rightarrow\bm{H}$ & $\bm{H}, \widetilde{\bm{H}}, \bm{H}$ & $\bm{H}$ \\
    \hline
    周期2出力1 & $\widetilde{\bm{H}}\widetilde{\bm{H}}\widetilde{\bm{H}}\rightarrow\bm{H}$ & $\widetilde{\bm{H}}, \widetilde{\bm{H}}, \widetilde{\bm{H}}$ & $\bm{H}$ \\
    周期2出力1 & $\bm{H}\bm{H}\bm{H}\rightarrow\widetilde{\bm{H}}$ & $\bm{H}, \bm{H}, \bm{H}$ & $\widetilde{\bm{H}}$ \\
    \hline
  \end{tabular}
\end{table}

周期3出力1パターンでは，時系列$\bm{H},\bm{H},\widetilde{\bm{H}},\bm{H},\bm{H},\widetilde{\bm{H}},\cdots$において，入力の3スロットに補間値$\widetilde{\bm{H}}$が1つまたは2つ含まれる構成となる．
$\widetilde{\bm{H}}\bm{H}\widetilde{\bm{H}}\rightarrow\bm{H}$は入力に補間値を2つ含み推定値を出力とする構成である．
$\bm{H}\widetilde{\bm{H}}\bm{H}\rightarrow\bm{H}$は入力に補間値を1つ含み推定値を出力とする構成である．

周期2出力1パターンでは，時系列$\bm{H},\widetilde{\bm{H}},\bm{H},\widetilde{\bm{H}},\cdots$において，入力と出力の構成が大きく異なる2種類となる．
$\widetilde{\bm{H}}\widetilde{\bm{H}}\widetilde{\bm{H}}\rightarrow\bm{H}$は入力がすべて補間値であり推定値を出力とする構成である．
$\bm{H}\bm{H}\bm{H}\rightarrow\widetilde{\bm{H}}$は入力がすべて推定値であり補間値を出力とする構成である．

% \subsection{MLPモデルにおける疎化拡大}
% \label{sec:evaluation_of_prediction_mechanism_using_time_series_interpolation_learning_data_pilot_sparse_expansion_mlp_model}





\subsection{LSTMモデルにおける疎化拡大}
\label{sec:evaluation_of_prediction_mechanism_using_time_series_interpolation_learning_data_pilot_sparse_expansion_lstm_model}

本節では，LSTMモデルを用いて疎化拡大の評価を行う．
用いるLSTMアーキテクチャは，\autoref{sec:simulation}で述べた2層スタックLSTMと同一である．

本節では，周期3出力1パターンおよび周期2出力1パターンを用いて評価する．
周期3出力1パターンは3スロット中1スロットを予測で代替し削減率33\%に相当する．
周期2出力1パターンは2スロット中1スロットを予測で代替し削減率50\%に相当する．

\subsubsection{ベースラインモデルの学習}
周期3出力1パターンおよび周期2出力1パターンのベースラインモデルについて，学習曲線を\autoref{fig:lstm_ssp_learning_curve}および\autoref{fig:lstm_sp_learning_curve}に示す．

\begin{figure}[H]
  \centering
  \includegraphics[width=0.95\textwidth]{../picture/4nd/45_ssp_learning_curves_nmse_ssp.png}
  \caption{周期3出力1パターンにおけるLSTMベースラインモデルの学習曲線}
  \label{fig:lstm_ssp_learning_curve}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.95\textwidth]{../picture/4nd/45_sp_learning_curves_nmse_sp.png}
  \caption{周期2出力1パターンにおけるLSTMベースラインモデルの学習曲線}
  \label{fig:lstm_sp_learning_curve}
\end{figure}

両パターンともに，検証NMSEは序盤の5から10エポック程度で急激に低下し，その後はほぼ横ばいとなる．
訓練NMSEは40エポックまで緩やかに改善を続けるが，検証NMSEの改善は限定的である．
この傾向から，ベースラインモデルは早期に収束する特性を持つことがわかる．

訓練NMSEと検証NMSEの間には一定の差が存在するものの，検証NMSEが後半で悪化し続ける挙動は見られない．
軽度の過学習が生じているが安定した状態を維持している．
この差は，事前学習データと検証データの間の分布差，すなわち学習に用いた都市と評価に用いた都市の環境差に起因すると考えられる．

周期3出力1パターンと周期2出力1パターンを比較すると，周期3出力1パターンのほうが検証NMSEが低い傾向にある．
同一のLSTMアーキテクチャであっても，入力の観測密度が高いパターンのほうが予測精度が高くなることを示している．
周期3出力1パターンでは入力間隔が狭く時間的に近接した観測値を利用できるため，予測対象との相関が強く保たれる．
一方，周期2出力1パターンでは入力間隔が広がり，時間的に離れた観測値を用いるため予測が困難になる．

\subsubsection{ベースラインモデルの評価}
予測なしとベースラインモデルについて，評価データに対する各分割のNMSEを\autoref{tab:lstm_ssp_baseline}および\autoref{tab:lstm_sp_baseline}に示す．

\begin{table}[H]
  \centering
  \caption{周期3出力1パターンにおけるベースライン比較}
  \label{tab:lstm_ssp_baseline}
  \begin{tabular}{lcc}
    \hline
    Fold & 予測なし NMSE & ベースライン NMSE \\
    \hline
    0 & 0.240 & 0.140 \\
    1 & 0.187 & 0.126 \\
    2 & 0.169 & 0.116 \\
    3 & 0.200 & 0.134 \\
    4 & 0.204 & 0.114 \\
    \hline
    平均 & 0.200 & 0.126 \\
    \hline
  \end{tabular}
\end{table}

\begin{table}[H]
  \centering
  \caption{周期2出力1パターンにおけるベースライン比較}
  \label{tab:lstm_sp_baseline}
  \begin{tabular}{lcc}
    \hline
    Fold & 予測なし NMSE & ベースライン NMSE \\
    \hline
    0 & 0.240 & 0.168 \\
    1 & 0.187 & 0.148 \\
    2 & 0.169 & 0.137 \\
    3 & 0.200 & 0.158 \\
    4 & 0.204 & 0.139 \\
    \hline
    平均 & 0.200 & 0.150 \\
    \hline
  \end{tabular}
\end{table}

周期3出力1パターンでは，ベースラインモデルが予測なしに対して平均37.03\%の改善を達成している．
周期2出力1パターンでは平均25.07\%の改善にとどまる．
疎化率が高くなるほど予測が困難になり，ベースラインモデルの性能優位性が縮小する傾向が確認できる．

\subsubsection{ファインチューニング後の性能}
提案機構によるファインチューニング後の性能を周期3出力1パターンについて\autoref{tab:lstm_ft_performance_period3}，周期2出力1パターンについて\autoref{tab:lstm_ft_performance_period2}に示す．
\autoref{tab:ft_sample_config}で示した2種類のサンプル構成それぞれについてファインチューニングを実施した．
補間手法として，3次スプライン補間，片側3点ずつの4次多項式近似，片側3点ずつの5次多項式近似の3手法を比較した．

\begin{table}[H]
  \centering
  \caption{ファインチューニング後の予測性能（周期3出力1パターン）}
  \label{tab:lstm_ft_performance_period3}
  \small
  \resizebox{\textwidth}{!}{
    \begin{tabular}{llcccc}
      \hline
      サンプル構成 & 補間手法 & 予測なし & ベースラインモデル & FT後NMSE & ベースラインモデルからの改善率 [\%] \\
      \hline
      $\widetilde{\bm{H}}\bm{H}\widetilde{\bm{H}}\rightarrow\bm{H}$ & 3次スプライン補間 & 0.200 & 0.126 & $0.0357 \pm 0.0049$ & $71.7 \pm 2.71$ \\
      $\widetilde{\bm{H}}\bm{H}\widetilde{\bm{H}}\rightarrow\bm{H}$ & 片側3点ずつの4次多項式近似 & 0.200 & 0.126 & $0.0369 \pm 0.0052$ & $70.8 \pm 2.53$ \\
      $\widetilde{\bm{H}}\bm{H}\widetilde{\bm{H}}\rightarrow\bm{H}$ & 片側3点ずつの5次多項式近似 & 0.200 & 0.126 & $0.0369 \pm 0.0052$ & $70.8 \pm 2.53$ \\
      $\bm{H}\widetilde{\bm{H}}\bm{H}\rightarrow\bm{H}$ & 3次スプライン補間 & 0.200 & 0.126 & $\bm{0.0350 \pm 0.0052}$ & $\bm{72.2 \pm 3.25}$ \\
      $\bm{H}\widetilde{\bm{H}}\bm{H}\rightarrow\bm{H}$ & 片側3点ずつの4次多項式近似 & 0.200 & 0.126 & $0.0351 \pm 0.0051$ & $72.1 \pm 3.24$ \\
      $\bm{H}\widetilde{\bm{H}}\bm{H}\rightarrow\bm{H}$ & 片側3点ずつの5次多項式近似 & 0.200 & 0.126 & $0.0351 \pm 0.0051$ & $72.1 \pm 3.24$ \\
      \hline
    \end{tabular}
  }
\end{table}

\begin{table}[H]
  \centering
  \caption{ファインチューニング後の予測性能（周期2出力1パターン）}
  \label{tab:lstm_ft_performance_period2}
  \small
  \resizebox{\textwidth}{!}{
    \begin{tabular}{llcccc}
      \hline
      サンプル構成 & 補間手法 & 予測なし & ベースラインモデル & FT後NMSE & ベースラインモデルからの改善率 [\%] \\
      \hline
      $\widetilde{\bm{H}}\widetilde{\bm{H}}\widetilde{\bm{H}}\rightarrow\bm{H}$ & 3次スプライン補間 & 0.200 & 0.150 & $0.0580 \pm 0.0092$ & $61.4 \pm 4.03$ \\
      $\widetilde{\bm{H}}\widetilde{\bm{H}}\widetilde{\bm{H}}\rightarrow\bm{H}$ & 片側3点ずつの4次多項式近似 & 0.200 & 0.150 & $0.0679 \pm 0.0124$ & $54.8 \pm 6.07$ \\
      $\widetilde{\bm{H}}\widetilde{\bm{H}}\widetilde{\bm{H}}\rightarrow\bm{H}$ & 片側3点ずつの5次多項式近似 & 0.200 & 0.150 & $0.0679 \pm 0.0124$ & $54.8 \pm 6.07$ \\
      $\bm{H}\bm{H}\bm{H}\rightarrow\widetilde{\bm{H}}$ & 3次スプライン補間 & 0.200 & 0.150 & $\bm{0.0477 \pm 0.0060}$ & $\bm{68.2 \pm 2.90}$ \\
      $\bm{H}\bm{H}\bm{H}\rightarrow\widetilde{\bm{H}}$ & 片側3点ずつの4次多項式近似 & 0.200 & 0.150 & $0.0507 \pm 0.0060$ & $66.2 \pm 2.68$ \\
      $\bm{H}\bm{H}\bm{H}\rightarrow\widetilde{\bm{H}}$ & 片側3点ずつの5次多項式近似 & 0.200 & 0.150 & $0.0507 \pm 0.0060$ & $66.2 \pm 2.68$ \\
      \hline
    \end{tabular}
  }
\end{table}

周期3出力1パターンでは，$\bm{H}\widetilde{\bm{H}}\bm{H}\rightarrow\bm{H}$と3次スプライン補間の組み合わせが最良の性能を示している．
ベースラインから72.19\%の改善を達成し，NMSEは0.0350まで低下した．
周期2出力1パターンでは，$\bm{H}\bm{H}\bm{H}\rightarrow\widetilde{\bm{H}}$と3次スプライン補間の組み合わせが最良であり，68.20\%の改善を達成してNMSEは0.0477となった．

サンプル構成間の比較では，入力に補間値を多く含む構成よりも，入力に推定値を多く含む構成のほうが高い改善率を示している．
周期3出力1パターンでは，$\widetilde{\bm{H}}\bm{H}\widetilde{\bm{H}}\rightarrow\bm{H}$が71.65\%であるのに対し，$\bm{H}\widetilde{\bm{H}}\bm{H}\rightarrow\bm{H}$は72.19\%と若干の差がある．
周期2出力1パターンでは差がより顕著であり，$\widetilde{\bm{H}}\widetilde{\bm{H}}\widetilde{\bm{H}}\rightarrow\bm{H}$が61.37\%であるのに対し，$\bm{H}\bm{H}\bm{H}\rightarrow\widetilde{\bm{H}}$は68.20\%と約7ポイントの差がある．
入力に補間値が多く含まれると補間誤差がモデルに伝播しやすく，性能が低下すると考えられる．

補間手法間の比較では，3次スプライン補間が片側多項式近似よりも優れた性能を示す傾向にある．
片側3点ずつの4次多項式近似と片側3点ずつの5次多項式近似は同一の性能を示しており，次数の違いによる差は見られない．

\subsubsection{パイロット削減と予測精度の両立}
以上の結果から，パイロット信号を削減した場合においても，提案機構によるファインチューニング後のNMSEが予測なしよりも低く抑えられていることが確認できる．

予測なしのNMSEは約0.200であるのに対し，周期3出力1パターンでは最良構成で0.035，周期2出力1パターンでは0.048を達成している．
周期2出力1パターンはパイロット送信を50\%削減する設定であるが，それでも予測なしの約4分の1のNMSEを実現している．

この結果は，提案したチャネル予測機構がパイロット信号の削減と予測精度の維持を両立できることを示している．
パイロット削減率を高めると予測が困難になりベースラインモデルの性能は低下するが，補間値を用いたファインチューニングにより新環境への適応が可能となり，実用的な予測精度を確保できる．

\subsection{多出力LSTMモデルによる疎化拡大}
\label{sec:multi_output_lstm}

前節までの評価では，予測モデルの出力を1フレームとしていた．
本節では，出力フレーム数を拡張し，複数フレームを同時に予測する多出力構成について評価する．
予測ホライズンを拡張することで，より多くの予測スロットを一度に生成でき，パイロット信号の削減効果をさらに高められる．

本実験では，周期3・2出力パターンと周期4・3出力パターンの2種類を検討する．
周期3・2出力パターンは周期3で2フレームを同時に予測する構成であり，周期4・3出力パターンは周期4で3フレームを同時に予測する構成である．
入力フレーム数は両パターンとも6フレームとする．

\subsubsection{多出力LSTMのアーキテクチャ}

多出力LSTMでは，過去\(T_I=6\)フレーム分のCSIを入力とし，将来\(T_O\)フレーム分のCSIを同時に回帰する．
周期3・2出力パターンでは\(T_O=2\)，周期4・3出力パターンでは\(T_O=3\)である．

\paragraph{入力層}
入力は各フレームのCSIをベクトル化して結合した\(\bm{x}\in\mathbb{R}^{T_I\cdot F}\)である．
本実験の設定では\(T_I=6\)，\(F=3072\)より\(\bm{x}\in\mathbb{R}^{18432}\)となる．
バッチサイズを\(B\)とすると入力形状は\([B,\,T_I\cdot F]=[B,\,18432]\)である．
この入力を時系列へ再整形し，
\begin{equation}
  \bm{X}\in\mathbb{R}^{B\times T_I\times F}=\mathbb{R}^{B\times 6\times 3072}
\end{equation}
を得る．\(\bm{X}\)は6フレームからなる系列であり，各タイムステップは3072次元のCSIベクトルに対応する．

\paragraph{LSTM層}
\autoref{sec:evaluation_of_prediction_mechanism_using_time_series_interpolation_learning_data_pilot_sparse_expansion_lstm_model}と同様に2層のスタックLSTMを用いる．
第1層は入力\([B,6,3072]\)を受け取り，隠れ状態次元512の系列出力\([B,6,512]\)を出力する．
第2層は第1層の出力を入力とし，\([B,6,512]\)を出力する．
層間にDropout \(p=0.1\)を適用する．

\paragraph{特徴抽出}
第2層LSTMの最終タイムステップの隠れ状態\(\bm{h}_{T_I}\in\mathbb{R}^{B\times 512}\)を特徴量として用いる．
\(\bm{h}_{T_I}\)は過去6フレームの情報を集約した固定長表現である．

\paragraph{全結合層}
抽出した特徴量\(\bm{h}_{T_I}\)を全結合層へ与え，複数フレームのCSIベクトルを同時に回帰する．
全結合層は以下の構成とする．
\begin{itemize}
  \item \(\mathrm{Linear}(512\rightarrow 512)\rightarrow \mathrm{ReLU}\rightarrow \mathrm{Dropout}(p=0.1)\)
  \item \(\mathrm{Linear}(512\rightarrow 256)\rightarrow \mathrm{ReLU}\rightarrow \mathrm{Dropout}(p=0.1)\)
  \item \(\mathrm{Linear}(256\rightarrow T_O\cdot F)\)
\end{itemize}
出力形状は\([B,\,T_O\cdot F]\)であり，周期3・2出力パターンでは\([B,\,6144]\)，周期4・3出力パターンでは\([B,\,9216]\)となる．

\subsubsection{入出力の時系列配置}

各パターンにおける入出力の時系列配置を説明する．
時刻\(t\)を最初の出力時刻とし，入力と出力を離散オフセットで定義する．

周期3・2出力パターンでは周期3で$\bm{H}$と$\widehat{\bm{H}}$が配置される．
入力オフセットは\([-16,-13,-10,-7,-4,-1]\)であり，出力オフセットは\([0,1]\)である．
入力の各時刻はSスロットに対応し，出力の2時刻はPスロットに対応する．
入力の最後の時刻\(t-1\)がSスロットとなるため，\(t\)はSの直後のPスロットである．

周期4・3出力パターンでは周期4で$\bm{H}$と$\widehat{\bm{H}}$が配置される．
入力オフセットは\([-21,-17,-13,-9,-5,-1]\)であり，出力オフセットは\([0,1,2]\)である．
入力の各時刻は$\bm{H}$スロットに対応し，出力の3時刻は$\widehat{\bm{H}}$スロットに対応する．
周期3・2出力パターンと同様に，入力の最後の時刻\(t-1\)が$\bm{H}$スロットとなる．

各サンプルの入出力は以下のように構成される．
\begin{align}
  \bm{X} &= [\bm{H}_{t+o_0}, \bm{H}_{t+o_1}, \ldots, \bm{H}_{t+o_5}] \in \mathbb{R}^{T_I\cdot F} \\
  \bm{Y} &= [\bm{H}_{t+u_0}, \bm{H}_{t+u_1}, \ldots] \in \mathbb{R}^{T_O\cdot F}
\end{align}
ここで，\(o_i\)は入力オフセット，\(u_i\)は出力オフセットである．

\subsubsection{予測なしベースライン}

予測を用いないベースラインとして，予測なしの場合を定義する．
予測なしとは入力系列の最終フレームを出力フレーム数だけ繰り返して出力する手法である．

評価データ\(\bm{X}\in\mathbb{R}^{N\times(T_I\cdot F)}\)，\(\bm{Y}\in\mathbb{R}^{N\times(T_O\cdot F)}\)に対して，予測なしの予測値は以下のように計算される．
\begin{align}
  \bm{x}_{\mathrm{last}} &= \bm{X}[:, (T_I-1)F : T_I\cdot F] \in \mathbb{R}^{N\times F} \\
  \widehat{\bm{Y}}_{\mathrm{copy}} &= \mathrm{repeat}(\bm{x}_{\mathrm{last}}, T_O) \in \mathbb{R}^{N\times(T_O\cdot F)}
\end{align}
周期3・2出力パターンでは同一フレームを2回，周期4・3出力パターンでは3回並べる．
この手法は予測ホライズン中のチャネルが変化しないと仮定するベースラインであり，予測モデルの有効性を検証する基準となる．

\subsubsection{学習条件}

ベースラインモデルの学習条件を以下に示す．
事前学習では40エポック，ファインチューニングでは20エポックの学習を実施する．
ファインチューニング時の学習率は\(1\times10^{-4}\)とする．
その他のハイパーパラメータは\autoref{sec:evaluation_of_prediction_mechanism_using_time_series_interpolation_learning_data_pilot_sparse_expansion_lstm_model}と同一である．

\subsubsection{補間手法}

本実験では，補間手法として5次多項式近似を採用する．
多項式近似の設定は片側3点ずつの近傍Sスロットを用いる構成とする．
\autoref{tab:kinshicho_sssp_results}に示したとおり，錦糸町データセットにおける補間精度評価において，5次多項式近似は片側3点ずつの設定でNMSE 0.0059を達成しており，スプライン補間と同等の高い補間精度を示した．
この結果に基づき，本実験では5次多項式近似を用いて予測スロットのCSIを補間する．

\subsubsection{ファインチューニング用サンプルの構成}

補間後のCSI系列からファインチューニング用の学習サンプルを構成する方法を説明する．
本実験では，入力に真値のみを用い，出力に補間値を用いる構成を採用する．

周期3・2出力パターンおよび周期4・3出力パターンにおける入出力の値の種別を\autoref{tab:spp_sppp_sample_composition}に示す．
入力の各オフセット位置は周期の倍数だけ離れた位置を指すため，全て$\bm{H}$スロットに対応する．
出力の各オフセット位置は$\widehat{\bm{H}}$スロットに対応し，補間値を用いる．

\begin{table}[H]
  \centering
  \caption{周期3・2出力および周期4・3出力パターンにおける入出力の値の種別}
  \label{tab:spp_sppp_sample_composition}
  \begin{tabular}{llll}
    \hline
    パターン & 位置 & オフセット & 値の種別 \\
    \hline
    周期3・2出力 & 入力 & $-16, -13, -10, -7, -4, -1$ & 全て真値 \\
    周期3・2出力 & 出力 & $0, 1$ & 全て補間値 \\
    \hline
    周期4・3出力 & 入力 & $-21, -17, -13, -9, -5, -1$ & 全て真値 \\
    周期4・3出力 & 出力 & $0, 1, 2$ & 全て補間値 \\
    \hline
  \end{tabular}
\end{table}

ファインチューニング用サンプルの生成では，出力時刻\(t\)が必ず$\widehat{\bm{H}}$スロットとなるよう設計している．
時刻\(t\)が$\widehat{\bm{H}}$スロットであるかどうかは，\(t \bmod \mathrm{period} \neq 0\)により判定する．
周期3・2出力パターンでは周期3，周期4・3出力パターンでは周期4である．
入力オフセットは周期の倍数だけ離れた位置を指すため，入力時刻は全て$\bm{H}$スロットとなり真値を用いる．
出力時刻は$\widehat{\bm{H}}$スロットであるため補間値を用いる．

この構成により，入力には補間誤差を含まない真値のみを与え，出力として補間値を予測するようモデルを学習させる．
前節までの評価では入力に補間値を含む構成も検討したが，入力に真値を多く含む構成のほうが高い改善率を示す傾向にあった．
本実験でも同様の傾向を踏まえ，入力を全て真値とする構成を採用した．

\subsubsection{予測なしベースラインの比較}
周期3・2出力パターンおよび周期4・3出力パターンにおいて，予測を行わなかった場合の結果（予測なしおよび事前学習のみのベースラインモデル）を\autoref{tab:spp_baseline}および\autoref{tab:sppp_baseline}に示す．

\begin{table}[H]
  \centering
  \caption{周期3・2出力パターンにおけるベースライン比較}
  \label{tab:spp_baseline}
  \begin{tabular}{rcc}
    \hline
    Fold & 予測なし & ベースライン \\
    \hline
    0 & 0.463 & 0.427 \\
    1 & 0.381 & 0.340 \\
    2 & 0.338 & 0.351 \\
    3 & 0.403 & 0.376 \\
    4 & 0.385 & 0.346 \\
    \hline
    平均 & 0.394 & 0.368 \\
    \hline
  \end{tabular}
\end{table}

\begin{table}[H]
  \centering
  \caption{周期4・3出力パターンにおけるベースライン比較}
  \label{tab:sppp_baseline}
  \begin{tabular}{rcc}
    \hline
    Fold & 予測なし & ベースライン \\
    \hline
    0 & 0.618 & 0.528 \\
    1 & 0.548 & 0.476 \\
    2 & 0.478 & 0.476 \\
    3 & 0.576 & 0.509 \\
    4 & 0.524 & 0.433 \\
    \hline
    平均 & 0.549 & 0.484 \\
    \hline
  \end{tabular}
\end{table}

\subsubsection{評価結果}

周期3・2出力パターンおよび周期4・3出力パターンにおける評価結果を示す．
5分割交差検証により各分割のNMSEを測定した．

\autoref{tab:spp_results}に周期3・2出力パターン，\autoref{tab:sppp_results}に周期4・3出力パターンのファインチューニング結果を示す．
表中のFT後NMSEおよび改善率は5分割交差検証における平均$\pm$標準偏差であり，改善率は各foldにおけるベースラインモデル（FT前）のNMSEからの削減率を集計したものである．

\begin{table}[H]
  \centering
  \caption{周期3・2出力パターンにおけるファインチューニング結果}
  \label{tab:spp_results}
  \small
  \resizebox{\textwidth}{!}{
    \begin{tabular}{lccccc}
      \hline
      補間手法 & 補間NMSE & 予測なし & ベースラインモデル & FT後NMSE & ベースラインモデルからの改善率 \\
      \hline
      片側3点ずつの5次多項式近似 & 0.153 & 0.394 & 0.368 & $0.183 \pm 0.024$ & $50.4 \pm 3.47$\% \\
      \hline
    \end{tabular}
  }
\end{table}

\begin{table}[H]
  \centering
  \caption{周期4・3出力パターンにおけるファインチューニング結果}
  \label{tab:sppp_results}
  \small
  \resizebox{\textwidth}{!}{
    \begin{tabular}{lccccc}
      \hline
      補間手法 & 補間NMSE & 予測なし & ベースラインモデル & FT後NMSE & ベースラインモデルからの改善率 \\
      \hline
      片側3点ずつの5次多項式近似 & 0.262 & 0.549 & 0.484 & $0.317 \pm 0.042$ & $34.5 \pm 7.40$\% \\
      \hline
    \end{tabular}
  }
\end{table}

周期3・2出力パターンでは，ファインチューニング後の平均NMSEは$0.183 \pm 0.024$であり，ベースラインモデルと比較して$50.40 \pm 3.47$\%の改善を達成した．
予測なしの平均NMSE 0.3941と比較すると約53.6\%の改善である．

周期4・3出力パターンでは，ファインチューニング後の平均NMSEは$0.317 \pm 0.042$であり，ベースラインモデルと比較して$34.54 \pm 7.40$\%の改善を達成した．
予測なしの平均NMSE 0.5487と比較すると約42.2\%の改善である．

両パターンともにファインチューニングにより予測精度が改善されている．
周期3・2出力パターンではベースラインからの改善率が約50\%，周期4・3出力パターンでは約35\%であり，出力フレーム数が増加するほど改善率は低下する傾向にある．
予測ホライズンが長くなるほど予測が困難になるため，この傾向は妥当である．




\section{おわりに}
本章では，参照信号削減下における時系列CSI予測モデルの更新手法として，時系列補間型学習データを用いたチャネル予測機構を提案した．
予測スロットでは参照信号を送信しないため正解ラベルが欠損するという問題に対し，後続スロットで得られる推定値から補間により欠損時刻のCSIを事後的に算出し，推定値と補間値で構成される学習サンプルを蓄積してモデルを更新する枠組みを示した．

提案機構の有効性を検証するため，レイトレーシングにより生成したCSI系列を用いて3種類の適応シナリオを評価した．
新基地局設置時の評価では，池袋，渋谷，新宿の3地域で事前学習したモデルを錦糸町環境に適応させた結果，スプライン補間および多項式近似を用いたファインチューニングにより約79\%の予測精度改善を達成した．
セル内チャネル統計変動時の評価では，NLoSからLoSへの適応で約73\%，LoSからNLoSへの適応で約74\%の改善率を達成した．
双方向の適応結果を比較すると，LoS環境はチャネルの時間的相関が強く予測が容易であるため，NLoSからLoSへの適応がより高い最終精度を達成する傾向にあることが確認された．

パイロット疎化拡大の評価では，削減率33\%の周期3出力1パターンで約72\%，削減率50\%の周期2出力1パターンで約68\%の改善率を達成した．
多出力LSTMを用いた予測ホライズン拡張では，2フレーム同時予測の周期3・2出力パターンで約50\%，3フレーム同時予測の周期4・3出力パターンで約35\%の改善率を達成した．
予測ホライズンが長くなるほど改善率は低下するが，いずれの条件においてもファインチューニング後のモデルは予測なしを上回る予測精度を示した．

雑音環境下における評価では，SNRの低下に伴い予測NMSEが増加する傾向が確認されたが，SNRが$-2$~dBの条件においてもファインチューニング後のモデルはベースラインを上回る性能を維持した．
補間手法間の性能差はSNRの影響と比較して小さく，スプライン補間と多項式近似はほぼ同等の結果を示した．

以上の結果から，提案した時系列補間型学習データを用いたチャネル予測機構は，参照信号削減を維持しながら環境変化に追従したモデル更新を実現できることが確認された．