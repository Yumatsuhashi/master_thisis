\chapter{時系列補間型学習データを用いた無線チャネル予測機構}{}
\label{chap:4th}

\section{はじめに}
本章では，前章までで述べた2章で指摘した既存のモデル更新手法における予測スロットが推定値にならないためモデルの重みを更新できないという問題に対して
補間を用いた新たなモデル重み更新機構を提案する．その際に用いる補間手法は第3章で比較検証した中で最も有効な手法を採用する.

% \section{関連研究と問題点}
% \label{sec:related_work_and_problems}
% 前章で述べた時系列CSI予測の環境適応に関する研究について，少量データでの適応を狙うメタ学習に基づく初期化学習\cite{kim2023_meta_denoising_mimo}，事前学習済みモデルとして大規模言語モデルを転用する研究\cite{liu2024_llm4cp}，運用中の分布変化に逐次追従する継続学習\cite{mohsin2025_continual_learning_channel_prediction}などがあった．

% 既存研究の多くは，新環境で得られる正解データを用いたモデル更新を前提としている．一方，CSI予測で参照信号を削減する場合，予測スロットでは参照信号を送らないため，予測対象時刻のCSI推定値が得られない．このとき，時系列CSI予測モデルの正解ラベルｆを獲得できないため，教師あり学習に基づく損失を計算できず，予測を継続しながら逐次的にモデルを更新することが難しい．

% 具体例として，時刻\(t\)のCSI推定値を\(\bm{H}_t\)，予測値を\(\widehat{\bm{H}}_t\)とする．3入力1出力の予測モデルを運用する場合，\(\bm{H}_t,\bm{H}_{t+1},\bm{H}_{t+2}\)から\(\widehat{\bm{H}}_{t+3}\)を得る．参照信号を削減する予測スロットでは，時刻\(t+3\)の推定値\(\bm{H}_{t+3}\)を獲得できない．その結果，\(\widehat{\bm{H}}_{t+3}\)に対する教師信号が欠落し，更新用の学習データを逐次獲得することができない．

% このとき，運用で基地局が利用できるCSI系列は，推定値と予測値が混在する系列となる．上の例では，時刻\(t\)から\(t+3\)にかけて\(\bm{H}_t,\bm{H}_{t+1},\bm{H}_{t+2},\widehat{\bm{H}}_{t+3}\)が得られる一方で，\(\bm{H}_{t+3}\)は欠落する．この混在系列を用いてモデルを更新する方法として，三つの方針が考えられる．

% 第1に，一時的に予測を停止し，参照信号を送信して全時刻の推定値を揃えた後に更新する方針である．しかし，参照信号削減という時系列CSI予測の目的に反するうえ，更新までの遅延も増大する．
% 加えて，運用中にモデルを停止する場合，停止と再開の手順，許容中断時間，それに伴う遅延を考慮した運用方針を設計する必要がある．しかし，これらに関する標準化は検討途上であり，具体的要件は十分に整理されていないため，実装上の困難が伴う．
% 移動通信システムの仕様を策定する国際標準化プロジェクトである3GPPでは無線機能に関する要件を扱う立場からAIと機械学習の適用に伴う要件を議論している\cite{3gpp_tr38843}．具体的には，AIモデルの配布，導入，有効化，無効化，切り替え，更新などの運用手順を含むライフサイクル管理と，これらの手順に伴う遅延と中断に関する要件である\cite{3gpp_tr38843}．商用展開に向けてモデル汎化，モデル切り替え，モデル更新の三つのアプローチが調査されているが，モデル有効化と無効化，切り替え時の遅延の扱いは議論中であり，具体的な規定は策定途上にある\cite{nokia_aiml_ran}．
% また，モデル切り替え時に推論をどのモデルが担うか，切り替え中の推論の中断をどの程度許容するか，切り替え判断の基準をどのように定めるかなど基本的事項が未解決であり，Release 19以降の検討に委ねられている\cite{arxiv_3gpp_standardization}．
% 3GPPでの標準化検討とは別に，産業界ではAI-RANとして，無線アクセスネットワークにAIモデルを組み込み，時系列CSI予測のような推論をRAN機能の近傍でリアルタイムに実行する次世代アーキテクチャが議論されている\cite{wia_challenges}．リアルタイム推論の実行には低遅延のエッジインフラや限られた計算資源で動作する軽量モデルに加え，AIモデルの障害時にRANが機能を維持するためのフォールバック機構が求められる\cite{wia_challenges}．一方で，フォールバック機構の設計指針は確立されておらず，推論を一時停止してレガシー手順へ切り替える際の中断時間やサービス品質への影響を制御する標準的な枠組みは存在しない．
% 以上より，予測停止に基づく第1の方針は参照信号削減の利点を損なうだけでなく，実運用における実現可能性にも課題を残す．

% 第2に，予測対象時刻を正解ラベルとみなし，\(\widehat{\bm{H}}_{t+3}\)に対して時刻\(t+3\)の正解を与えて更新する方針である．しかし，参照信号削減下では\(\bm{H}_{t+3}\)を獲得できないため，予測値との間の損失計算が成り立たず，教師あり学習ができない．
% 他分野では，観測や正解データが継続的に得られるため，データの到着に合わせて逐次更新する枠組みが一般的である．気象予測では観測値を取り込み，データ同化により状態推定と予報を反復する\cite{kalnay2003_atmospheric_modeling,evensen2003_enkf}．金融予測では市場価格やリターンが逐次観測され，オンライン学習により予測モデルを更新する\cite{cover1991_universal_portfolios}．データ分布が時間とともに変化する問題設定は概念ドリフトとして整理され，適応手法が議論されている\cite{gama2014_concept_drift_survey}．
% しかし，時系列CSI予測の分野では，予測スロットでは参照信号を送らないため，予測対象時刻のCSI推定値が得られない．


% 第3に，入力に予測値を含め，次に推定値が得られる時刻を正解ラベルとして更新する方針である．例えば\(\bm{H}_{t+1},\bm{H}_{t+2},\widehat{\bm{H}}_{t+3}\)から\(\bm{H}_{t+4}\)を学習する．
% ただし，入力に予測誤差が混入し，誤差蓄積による性能劣化を招く可能性が指摘されている\cite{jiang2022_transformer_mobility_negligible}．

% 以上より，参照信号削減を前提とする時系列CSI予測の運用では，推定値と予測値が混在するCSI系列から，予測を継続しながらモデルを更新する枠組みが必要となる．前節で述べた第1の方針は参照信号削減の目的と整合しないだけでなく，停止と再開に伴う運用手順や遅延と中断に関する要件が標準化検討途上である点からも，実装上の負担が大きい．そのため本研究では，第2および第3の方針が想定する状況，すなわち予測を継続したまま欠損する正解ラベルを扱いながら更新する問題を対象とする．




\section{時系列補間型学習データを用いたチャネル予測機構によるモデル重み更新}
本研究では，参照信号削減のため予測スロットでは参照信号を送信せず，当該スロットのCSI推定値が得られない状況を前提とする．このとき，予測スロットでは教師信号，すなわち正解ラベルが欠損するため，既存の重み更新手法をそのまま適用できない．そこで，予測を継続しながらも時系列CSI予測モデルを更新できる枠組みを提案する．
本枠組みの要点は，欠損した正解ラベルを直ちに用意して逐次更新するのではなく，後続スロットで観測されるCSI推定値に基づき予測スロットの補間値を事後的に算出し，推定値と補間値で構成されるCSI系列を一定量蓄積した後に，その系列から更新用の学習サンプル群を構成してモデルを更新する点にある．
提案機構の概要を図\ref{fig:explonation}に示す．

以下，時刻\(t\)をスロット時刻とし，参照信号から得るCSI推定値を\(\bm{H}_t\)，予測モデルが出力するCSI予測値を\(\widehat{\bm{H}}_t\)とする．
補間により得られる予測スロットの補間値を\(\widetilde{\bm{H}}_t\)とする．
説明のため，直近3スロットを入力として1スロット先を予測する3入力1出力の予測モデルを例にとる．このとき，学習済み予測モデル\(f_{\theta}\)により
\begin{equation}
  \widehat{\bm{H}}_{t+3}=f_{\theta}(\bm{H}_t,\bm{H}_{t+1},\bm{H}_{t+2})
\end{equation}
を得る．しかし，参照信号削減の運用では予測スロット\(t+3\)において参照信号を送信しないため，\(\bm{H}_{t+3}\)は観測できず，\(\widehat{\bm{H}}_{t+3}\)に対する教師信号が欠落する．

そこで本研究では，予測スロットより後に得られる推定値を用い，欠損した\(\bm{H}_{t+3}\)を事後的に推定する．
具体的には，次スロット以降で参照信号が送信されて\(\bm{H}_{t+4},\bm{H}_{t+5},\dots\)が得られたら，欠損時刻の前後に存在する推定値を用いて補間し，予測スロットに対応する補間値
\begin{equation}
  \widetilde{\bm{H}}_{t+3}
\end{equation}
を算出する．この\(\widetilde{\bm{H}}_{t+3}\)は，予測スロットで本来得られるべき\(\bm{H}_{t+3}\)の近似として扱うことで，教師あり学習に必要な正解ラベルを補間により近似する役割を担う．

補間値は後続スロットの推定値が得られてはじめて定まるため，欠損が生じるたびに即時に学習サンプルを確定させて逐次更新する運用とはならない．本研究では，推定値と補間値で構成されるCSI系列をバッファに蓄積し，所定の長さの時系列が揃った時点で，その系列から更新用の学習サンプル群を構成してモデルを微調整する．
例えば，3入力1出力の設定では，入力を\(\widetilde{\bm{H}}_{t+3},\bm{H}_{t+4},\bm{H}_{t+5}\)，出力を\(\bm{H}_{t+6}\)として学習サンプルを作成し，複数サンプルをまとめて更新に用いる．
ここで，3入力の並びは一例であり，入力の3時刻のうち予測スロットに対応する1点を\(\widetilde{\bm{H}}\)で置き換え，残りを後続スロットで得られる推定値で構成すればよい．
すなわち，
\begin{equation}
  \bm{H}_{t+6}\approx f_{\theta}(\widetilde{\bm{H}}_{t+3},\bm{H}_{t+4},\bm{H}_{t+5})
\end{equation}
となるように損失を計算し，勾配法によりモデルを微調整する．

以上の手順を繰り返すことで，参照信号削減下でも予測スロットにおける欠損ラベルを補間により補ったCSI系列を蓄積し，蓄積した系列から学習サンプル群を構成して更新を反復できる．
これにより，環境変化に伴う分布の変化に追従したモデル更新を実現する．




\begin{figure}[H]
  \centering
  \includegraphics[width=120mm]{../picture/4nd/explonation_pdf15.pdf}
  \caption{提案機構の概要}
  \label{fig:explonation}
\end{figure}




\section{シミュレーション}
\label{sec:simulation}

\subsection{シミュレーション条件}

本節では，提案機構の有効性を検証するためのシミュレーション条件について述べる．
本実験で用いるCSI系列は，\autoref{subsec:terrain_raytracing}で述べたとおり，Sionnaによるレイトレーシングで生成したものである．
以下，本実験で用いる学習データの構成および実験手順を説明する．

\subsubsection{ベースラインモデルおよび補間モデルの学習}
本実験では，事前学習用データセットとして事前学習データを用いる．
事前学習データは，池袋，渋谷，新宿の3地域から取得したCSI系列で構成される．
この事前学習データから，時系列CSI予測を担うベースラインモデルと，欠損時刻のCSIを推定する補間モデルの両方を学習する．

ベースラインモデルの学習では，事前学習データを学習用，検証用，テスト用の3つに分割する．
分割比率はTrain:Val:Test = 7:2:1とし，学習用データでモデルを訓練し，検証用データで過学習の監視および最良モデルの選択を行い，テスト用データで汎化性能を評価する．

補間モデルの学習も同一の事前学習データを用いる．
ニューラルネットワーク補間を用いる場合は，補間モデル専用のデータ分割を行う．
補間モデルの学習ではTrain:Val = 8:2の比率で分割し，学習用データで補間モデルを訓練し，検証用データで性能を監視する．
スプライン補間や多項式近似など事前学習を要しない補間手法では，このステップは不要である．

以上により，事前学習データからベースラインモデルと補間モデルの両方を得る．
ベースラインモデルは以降のファインチューニングにおける初期値として用い，補間モデルはファインチューニング用データセット生成時の補間値算出に用いる．

\subsubsection{検証用データの5分割}
検証用データは，錦糸町で取得したCSI系列で構成される．
この検証用データを用いて，ベースラインモデルを新環境に適応させるファインチューニングを実施する．

評価の信頼性を高めるため，検証用データを5分割し，交差検証により評価する．
具体的には，検証用データを5つの互いに重複しない部分集合に分割する．
各分割において，5つの部分集合のうち4つをファインチューニング用として用い，残りの1つを評価用として用いる．
すなわち，ファインチューニング用と評価用の比率は4:1である．

この分割を5回繰り返し，各回で異なる部分集合を評価用に割り当てることで，すべてのデータが1度は評価用として用いられる．
5分割交差検証により，特定のデータ分割に依存した偏りを排除し，データセットの難易度による評価結果の変動を均一化する．

\subsubsection{ファインチューニング用データセットの生成}
各分割において，ファインチューニング用として割り当てられた4/5の検証用データから，学習サンプルを生成する．
ファインチューニング用データセットの生成には，補間手法を用いる．

具体的には，連続するCSIフレームからスライディングウィンドウ方式でサンプルを抽出する．
抽出したウィンドウの中心時刻に対応するフレームを欠損フレームとみなし，周囲のフレームを用いて補間値を算出する．
補間値の算出には，3次スプライン補間，ニューラルネットワーク補間，多項式近似などの手法を適用する．
算出した補間値を入力系列に含め，後続時刻の真値を出力とする学習サンプルを構成する．

この手順により，欠損時刻を補間値で補完したファインチューニング用学習サンプル群が得られる．
補間手法ごとに異なるファインチューニング用データセットを生成し，手法間の性能比較に用いる．

\subsubsection{ファインチューニングの実施}
生成したファインチューニング用データセットを用いて，ベースラインモデルを更新する．
ベースラインモデルの重みを初期値として読み込み，ファインチューニング用データセットで追加学習を行う．
学習後のモデルを適応後モデルとして保存する．

この操作を補間手法ごとに実施し，各補間手法に対応する適応後モデルを得る．
ファインチューニングのハイパーパラメータは，学習率，エポック数，バッチサイズを含め，すべての手法で共通の値を用いる．

\subsubsection{評価}
各分割において，評価用として割り当てられた1/5の検証用データを用いて，適応後モデルの予測精度を評価する．
評価指標には，予測NMSEを用いる．

評価対象は，ファインチューニングを行わないベースラインモデル，各補間手法を用いてファインチューニングした適応後モデル，および予測を行わない単純戦略であるCopy-Lastである．
Copy-Lastは直前フレームをそのまま次時刻の予測値として出力する手法であり，予測モデルの有効性を確認するためのベースラインとして用いる．

各分割で得られた予測NMSEを補間手法ごとに記録し，5分割すべての評価が完了した後に平均値を算出する．
ベースラインモデルから適応後モデルへの改善率を補間手法間で比較し，提案機構の有効性を検証する．

\subsubsection{交差検証の意義}
5分割交差検証を採用する理由は，評価結果の信頼性と汎化性を確保するためである．
単一のデータ分割のみで評価した場合，評価用データに含まれる軌跡の特性によって結果が変動する可能性がある．
例えば，評価用データに予測が容易な軌跡が偏って含まれれば，改善率は過大評価される．
逆に，予測が困難な軌跡が偏って含まれれば，改善率は過小評価される．

5分割交差検証では，すべてのデータが評価用として1度は使用されるため，特定の軌跡に依存した評価の偏りを抑制できる．
5回の評価結果を平均することで，データセット全体に対する平均的な性能を推定し，提案機構の有効性をより客観的に評価する．



\subsection{機械学習モデル}
はじめに本論文で用いる時系列CSI予測を実行するニューラルネットワークのアーキテクチャについて説明する.
本論文では多重パーセプトロン(MLP)と長短期記憶(LSTM)を用いた2種類のニューラルネットワークを用いる．  


本論文のCSI予測器（CSI Predictor）は，全結合層からなる多層パーセプトロン（MLP）として実装する．
時刻方向に過去\(T_I\)フレーム分のCSIを用い，各フレームをベクトル化して結合した入力\(\bm{x}\in\mathbb{R}^{T_I\cdot F}\)から，次フレーム1枚分のCSIをベクトル化した出力\(\widehat{\bm{y}}\in\mathbb{R}^{F}\)を回帰する．
ここで，\(F\)は1フレームのCSI（行列）をフラット化した次元である．

MLPの層構成は以下のとおりである．中間層ではReLUにより非線形性を導入し，過学習を抑制するためにDropout（\(p=0.1\)）を適用する．

\begin{itemize}
  \item \(\mathrm{Linear}(\mathrm{in\_dim}\rightarrow 2048)\rightarrow \mathrm{ReLU}\rightarrow \mathrm{Dropout}(p=0.1)\)
  \item \(\mathrm{Linear}(2048\rightarrow 1024)\rightarrow \mathrm{ReLU}\rightarrow \mathrm{Dropout}(p=0.1)\)
  \item \(\mathrm{Linear}(1024\rightarrow 512)\rightarrow \mathrm{ReLU}\rightarrow \mathrm{Dropout}(p=0.1)\)
  \item \(\mathrm{Linear}(512\rightarrow \mathrm{out\_dim})\)
\end{itemize}

以上により，過去\(T_I\)フレームに含まれる時系列情報を，固定長ベクトル\(\bm{x}\)として受け取り，次フレームのCSIベクトル\(\widehat{\bm{y}}\)を予測する．

続いてLSTMのアーキテクチャについて紹介する．
LSTMでは，過去\(T_I\)フレーム分のCSIを時系列として入力し，隠れ状態により時間方向の依存関係を保持しながら次フレームのCSIを回帰する．

\paragraph{入力層}
入力はMLPと同様に，各フレームのCSIをベクトル化して結合した\(\bm{x}\in\mathbb{R}^{T_I\cdot F}\)である．本論文の設定では\(T_I=3\)，\(F=3072\)より\(\bm{x}\in\mathbb{R}^{9216}\)となる．
バッチサイズを\(B\)とすると入力形状は\([B,\,T_I\cdot F]=[B,\,9216]\)である．この入力を時系列へ再整形し，
\begin{equation}
  \bm{X}\in\mathbb{R}^{B\times T_I\times F}=\mathbb{R}^{B\times 3\times 3072}
\end{equation}
を得る．\(\bm{X}\)は3フレームからなる系列であり，各タイムステップは3072次元のCSIベクトルに対応する．

\paragraph{LSTM層}
本論文では2層のスタックLSTMを用いる．第1層は入力\([B,3,3072]\)を受け取り，隠れ状態次元512の系列出力\([B,3,512]\)を出力する．第2層は第1層の出力\([B,3,512]\)を入力とし，\([B,3,512]\)を出力する．過学習を抑えるため，層間にDropout \(p=0.1\)を適用する．

\paragraph{特徴抽出}
第2層LSTMの最終タイムステップの隠れ状態\(\bm{h}_{T_I}\in\mathbb{R}^{B\times 512}\)を特徴量として用いる．\(\bm{h}_{T_I}\)は過去3フレームの情報を集約した固定長表現である．

\paragraph{全結合層}
抽出した特徴量\(\bm{h}_{T_I}\)を全結合層へ与え，次フレームのCSIベクトルを回帰する．全結合層は
\begin{equation}
  \mathrm{Linear}(512\rightarrow F)
\end{equation}
とし，出力形状は\([B,F]=[B,3072]\)である．





\subsubsection{機械学習モデルのハイパーパラメーター}

本論文で用いる予測モデルと補間モデル，および補間値を用いたファインチューニングの，学習率，エポック数，バッチサイズ設定値を以下に示す．
\begin{description}
  \item[ベースラインモデルのトレーニング] 学習率は\(1\times10^{-3}\)，エポック数は40，バッチサイズは128である．
  \item[補間モデルであるInterpolator NNのトレーニング] 学習率は\(1\times10^{-4}\)，エポック数は10，バッチサイズは128である．
  \item[ファインチューニング] 学習率は\(1\times10^{-4}\)，エポック数は20，バッチサイズは128である．
\end{description}

損失評価には，正規化平均二乗誤差 Normalized Mean Squared Error，NMSEを用いる．
NMSEは，推定値と予測値値の二乗誤差を推定値の電力で正規化した量であり，サンプルごとに算出した後に平均し以下の式で表される


\paragraph{予測NMSE}
予測NMSEは，予測モデルが出力する予測値\(\widehat{\bm{H}}_t\)と真値\(\bm{H}_t\)の誤差を評価する．
\begin{equation}
  \mathrm{NMSE}_{\mathrm{pred}}
  =\frac{\left\lVert \widehat{\bm{H}}_t-\bm{H}_t\right\rVert_2^2}{\left\lVert \bm{H}_t\right\rVert_2^2}
  \label{eq:nmse_pred_def}
\end{equation}




\section{時系列補間型学習データを用いた無線チャネル予測機構評価}
\label{sec:evaluation_of_prediction_mechanism_using_time_series_interpolation_learning_data}

本節では，\autoref{sec:simulation}で述べたシミュレーション条件に基づき，時系列補間型学習データを用いたチャネル予測機構の評価を行う．


\subsection{新基地局設置時}
\label{sec:evaluation_of_prediction_mechanism_using_time_series_interpolation_learning_data_new_base_station_installation}
本節の実験では他セルで運用していたチャネル予測モデルを新規基地局へ展開する状況を想定している．
具体的には，池袋，渋谷，新宿の3地域で収集したCSI系列により事前学習したモデルを，錦糸町駅前の環境に適応させる．
新規基地局の設置直後は十分な学習データが蓄積されていないため，限られたサンプル数でモデルを適応させる手法が求められる．
提案する時系列補間型学習データを用いたファインチューニングが，この課題に対して程度有効であるかを検証する．

事前学習データには，\autoref{subsec:terrain_raytracing}で述べた渋谷駅前，新宿駅前，池袋駅前の3地域における地形データに対してレイトレーシングを実施し生成したCSI系列を用いる．
1サンプルは入力用の3時刻分のCSIと出力用の1時刻分のCSIで構成され，連続する4時刻のCSI系列を非重複で切り出して生成する．

事前学習データのサンプル数を\autoref{tab:pretraining_data_samples}に示す．
学習用データが204,390サンプル，検証用データが49,193サンプル，テスト用データが18,859サンプルであり，合計272,442サンプルで構成される．

\begin{table}[H]
  \centering
  \caption{事前学習データのサンプル数}
  \label{tab:pretraining_data_samples}
  \begin{tabular}{lr}
    \hline
    データ種別 & サンプル数 \\
    \hline
    学習用（Train） & 204,390 \\
    検証用（Val） & 49,193 \\
    テスト用（Test） & 18,859 \\
    \hline
    合計 & 272,442 \\
    \hline
  \end{tabular}
\end{table}

検証用データには，錦糸町駅前の地形データに対してレイトレーシングを実施し生成したCSI系列を用いる．
検証用データのサンプル数は約277,900である．
事前学習データと検証用データは互いに独立した地理的環境から取得しており，両者の間にデータの重複はない．

本評価では，既存セルで運用していたチャネル予測モデルを新規基地局へ展開する状況を想定する．
具体的には，池袋，渋谷，新宿の3地域で収集したCSI系列により事前学習したモデルを，錦糸町という未知の環境に適応させる．
新規基地局の設置直後は十分な学習データが蓄積されていないため，限られたサンプル数で効率的にモデルを適応させる手法が求められる．
提案する時系列補間型学習データを用いたファインチューニングが，この課題に対してどの程度有効であるかを検証する．

\subsubsection{ベースラインモデルの学習結果}
まず，事前学習データを用いたベースラインモデルの学習結果を示す．
\autoref{fig:baseline_learning_curves}にベースラインモデルの学習曲線を示す．
横軸はエポック数，縦軸はNMSEである．
エポックを重ねるごとに学習用データおよび検証用データの双方でNMSEが減少しており，モデルが適切に学習されていることが確認できる．

\begin{figure}[H]
  \centering
  \includegraphics[width=100mm]{../picture/4nd/441_real_town_learning_curves.pdf}
  \caption{ベースラインモデルの学習曲線}
  \label{fig:baseline_learning_curves}
\end{figure}

次に，ベースラインモデルの予測性能を評価するため，予測を行わない場合との比較を行う．
予測なしの手法として，入力3フレームの最終時刻$t=2$におけるCSI推定値をそのまま出力時刻$t=3$の推定値として使用するCopy-Lastを定義する．
Copy-Lastは，直前の推定値をビームフォーミングに使用する場合に相当し，予測によりどの程度の改善が得られるかを評価する基準となる．

\autoref{tab:baseline_vs_copylast}に，錦糸町の検証用データにおけるベースラインモデルとCopy-LastのNMSE比較結果を示す．
5分割交差検証の各foldにおいて，ベースラインモデルのNMSEはCopy-Lastと比較して大幅に小さい値を示している．
平均NMSEはベースラインモデルが0.136，Copy-Lastが0.321であり，ベースラインモデルは予測なしの場合と比較してNMSEを約58\%削減している．
この結果から，事前学習により獲得したチャネル予測能力が，未知の環境である錦糸町においても一定の汎化性能を発揮していることがわかる．

\begin{table}[H]
  \centering
  \caption{ベースラインモデルとCopy-LastのNMSE比較}
  \label{tab:baseline_vs_copylast}
  \begin{tabular}{crr}
    \hline
    Fold & ベースラインモデル & Copy-Last \\
    \hline
    0 & 0.144 & 0.493 \\
    1 & 0.141 & 0.326 \\
    2 & 0.127 & 0.205 \\
    3 & 0.143 & 0.348 \\
    4 & 0.128 & 0.232 \\
    \hline
    平均 & 0.136 & 0.321 \\
    \hline
  \end{tabular}
\end{table}

続いて，\autoref{sec:interpolation_methods}で述べた補間手法を用いて予測スロットのCSIを補間する．
補間手法の選定にあたっては，\autoref{tab:kinshicho_sssp_results}に示した錦糸町データセットにおける補間精度評価の結果を参考にする．
同評価では，錦糸町駅前の地形データに対してレイトレーシングにより生成したCSI系列を用いて各補間手法の精度を比較した．
その結果，スプライン補間および4次または5次の多項式近似がNMSE 0.03程度と最良の精度を達成することが判明している．

本実験では，上記の評価結果に基づき，スプライン補間および多項式近似を採用して予測スロットのCSIを補間する．
これらの補間手法は事前学習を必要としないため，新規基地局において即座に適用可能である点も利点となる．
補間により生成したCSIを用いてファインチューニング用の学習サンプルを構成し，ベースラインモデルの適応を試みる．

\subsubsection{学習サンプルの構成}
3入力1出力のチャネル予測モデルを運用する場合，$\bm{H}_t, \bm{H}_{t+1}, \bm{H}_{t+2}$から$\widehat{\bm{H}}_{t+3}$を得る．
参照信号を削減する予測スロットでは，時刻$t+3$の推定値$\bm{H}_{t+3}$を獲得できない．
基地局が利用できるCSI系列は$\bm{H}_t, \bm{H}_{t+1}, \bm{H}_{t+2}, -, \bm{H}_{t+4}, \bm{H}_{t+5}, \bm{H}_{t+6}, -, \ldots$のように推定値と欠損が周期的に現れる系列となる．
欠損時刻に対して補間を適用すると，補間値$\widetilde{\bm{H}}_{t+3}$が得られ，系列は$\bm{H}_t, \bm{H}_{t+1}, \bm{H}_{t+2}, \widetilde{\bm{H}}_{t+3}, \ldots$となる．

この補間後の系列から学習サンプルを構成する方法として，補間値$\widetilde{\bm{H}}$の配置位置に応じて4種類のパターンが考えられる．
\autoref{tab:sample_composition_441}に各パターンの構成を示す．
Labelは補間値を出力として用いる構成であり，First，Middle，Lastはそれぞれ補間値を入力の1番目，2番目，3番目に配置する構成である．

\begin{table}[H]
  \centering
  \caption{補間値の配置位置による学習サンプルの構成}
  \label{tab:sample_composition_441}
  \begin{tabular}{lcccc}
    \hline
    パターン & 入力1 & 入力2 & 入力3 & 出力 \\
    \hline
    Label & $\bm{H}_0$ & $\bm{H}_1$ & $\bm{H}_2$ & $\widetilde{\bm{H}}_3$ \\
    First & $\widetilde{\bm{H}}_3$ & $\bm{H}_4$ & $\bm{H}_5$ & $\bm{H}_6$ \\
    Middle & $\bm{H}_2$ & $\widetilde{\bm{H}}_3$ & $\bm{H}_4$ & $\bm{H}_5$ \\
    Last & $\bm{H}_1$ & $\bm{H}_2$ & $\widetilde{\bm{H}}_3$ & $\bm{H}_4$ \\
    \hline
  \end{tabular}
\end{table}

\subsubsection{ファインチューニング結果}
各サンプル構成を用いてベースラインモデルをファインチューニングし，予測精度の改善率を評価した．
補間手法としてはスプライン補間を採用した．
\autoref{tab:cubic_spline_441_results}にCubic Spline補間を用いた場合の結果を示す．
表中のファインチューニング後NMSEは5分割交差検証における平均値であり，ベースラインモデル比改善率はベースラインモデルのNMSEからの削減率を表す．

\begin{table}[H]
  \centering
  \caption{Cubic Spline補間における配置位置ごとのファインチューニング結果}
  \label{tab:cubic_spline_441_results}
  \begin{tabular}{lcc}
    \hline
    配置位置 & ファインチューニング後NMSE & ベースラインモデル比改善率 \\
    \hline
    Label  & 0.031919 & 78.45\% \\
    \textbf{First}  & \textbf{0.030265} & \textbf{79.56\%} \\
    Middle & 0.033456 & 77.41\% \\
    Last   & 0.030964 & 79.09\% \\
    \hline
  \end{tabular}
\end{table}

Firstが最良の結果を示し，NMSEは0.030265，ベースラインモデル比改善率は79.56\%となった．
補間値を入力の1番目に配置する構成が最も効果的であることがわかる．
全ての配置位置において77\%以上の改善率が得られており，補間値を用いたファインチューニングが新規基地局への適応に有効であることが確認できる．


\subsubsection{補間手法ごとの予測精度改善率}
続いて，スプライン補間および多項式近似を用いて時系列補間型学習データを作成し，ファインチューニングによる予測精度改善率を評価した．
補間値の配置位置としては，前節の結果に基づきFirstパターンを採用した．

検証用データは8:2の比率で分割し，80\%を補間およびファインチューニング用データ，20\%を評価用データとして用いた．
ファインチューニング用データに対して各補間手法を適用し，Firstパターンの学習サンプルを構成してベースラインモデルを更新した．
更新後のモデルを評価用データで検証し，予測精度改善率を算出した．

\autoref{tab:interpolation_method_comparison}に補間手法ごとの予測精度改善率を示す．
表中の補間NMSEは各補間手法が出力する補間値$\widetilde{\bm{H}}$と真値$\bm{H}$との誤差を表す．
ファインチューニング前NMSEはベースラインモデルのNMSE，ファインチューニング後NMSEは更新後モデルのNMSEである．
改善率はファインチューニング前NMSEからの削減率を表し，5分割交差検証における平均値を示す．

\begin{equation}
  \mathrm{improve}
  =\frac{\mathrm{NMSE}_{\mathrm{base}}-\mathrm{NMSE}_{\mathrm{adapted}}}{\mathrm{NMSE}_{\mathrm{base}}}\times 100
  \label{eq:improve_rate}
\end{equation}




\begin{table}[H]
  \centering
  \caption{補間手法ごとの予測精度改善率}
  \label{tab:interpolation_method_comparison}
  \begin{tabular}{lccccc}
    \hline
    補間手法 & 補間NMSE & FT前NMSE & FT後NMSE & 改善率 \\
    \hline
    スプライン補間 & 0.0061 & 0.136 & 0.028 & 79.37\% \\
    4次多項式近似（$K=3$） & 0.0059 & 0.136 & 0.028 & 79.35\% \\
    5次多項式近似（$K=3$） & 0.0059 & 0.136 & 0.028 & 79.36\% \\
    5次多項式近似（$K=6$） & 0.2291 & 0.136 & 0.050 & 63.24\% \\
    \hline
  \end{tabular}
\end{table}

スプライン補間，4次多項式近似（$K=3$），5次多項式近似（$K=3$）の3手法は，補間NMSEが0.006程度と高精度であり，ファインチューニング後の改善率も79\%以上を達成した．
一方，5次多項式近似（$K=6$）は補間NMSEが0.229と低精度であり，改善率は63.24\%にとどまった．

この結果から，補間手法自体の精度がファインチューニング後の予測精度改善率に影響を与えることがわかる．
\autoref{tab:kinshicho_sssp_results}に示したとおり，錦糸町データセットにおいてスプライン補間および4次または5次の多項式近似（$K=6$）が高精度であることが判明していた．
本実験においても，補間精度の高い手法ほど予測精度改善率が高くなる傾向が確認された．
補間NMSEが0.006程度の手法では79\%以上の改善率を達成した一方，補間NMSEが0.229の手法では改善率が63\%程度に低下した．

以上の結果から，時系列補間型学習データを用いたファインチューニングにおいて，補間手法の選定が予測精度に影響を与えることが示された．
高精度な補間手法を用いることで，新規基地局への適応においてより高い予測精度改善率を達成できる．

\subsubsection{学習サンプル数の影響評価}
学習サンプル数を段階的に増加させた場合の予測性能改善を評価する．
ファインチューニングに用いるサンプル数が予測精度に与える影響を明らかにすることで，実運用における必要データ量の指針を得る．

評価対象のベースラインとして，ファインチューニング前のベースラインモデルとCopy-Lastを設定した．
ベースラインモデルのNMSEは0.3621，Copy-LastのNMSEは0.1326である．
\autoref{tab:sample_size_vs_nmse}に各サンプル数における予測NMSEを示す．
補間手法として，3次スプライン補間，片側3点4次多項式近似，片側3点5次多項式近似の3手法を用いた．

\begin{table}[H]
  \centering
  \caption{学習サンプル数と予測NMSEの関係}
  \label{tab:sample_size_vs_nmse}
  \begin{tabular}{rcccc}
    \hline
    サンプル数 & FT前NMSE & 3次スプライン & 片側3点4次多項式 & 片側3点5次多項式 \\
    \hline
    0 & 0.3621 & 0.3621 & 0.3621 & 0.3621 \\
    19,575 & 0.3621 & 0.1882 & 0.1881 & 0.1882 \\
    39,150 & 0.3621 & 0.1330 & 0.1331 & 0.1328 \\
    58,725 & 0.3621 & 0.1045 & 0.1051 & 0.1045 \\
    78,300 & 0.3621 & 0.0894 & 0.0888 & 0.0892 \\
    97,874 & 0.3621 & \textbf{0.0774} & \textbf{0.0770} & \textbf{0.0769} \\
    \hline
  \end{tabular}
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=140mm]{../picture/4nd/443_ft_sample_size_vs_nmse_no_nn_xtick_horizontal.png}
  \caption{学習サンプル数と予測NMSEの関係}
  \label{fig:sample_size_vs_nmse}
\end{figure}

\autoref{tab:sample_size_vs_nmse}および\autoref{fig:sample_size_vs_nmse}から，学習サンプル数の増加に伴いNMSEが単調に減少する傾向が確認できる．
サンプル数0のときはファインチューニングが未実施であり，NMSEは0.3621である．
サンプル数19,575では約48\%の改善が得られ，NMSEは0.188程度まで低下する．
サンプル数39,150ではCopy-LastのNMSE 0.1326とほぼ同等の0.133程度に達し，これ以上のサンプル数ではCopy-Lastを下回る性能を示す．

サンプル数97,874では最良の結果が得られ，5次多項式近似でNMSE 0.0769を達成した．
ファインチューニング前と比較して約79\%の改善である．
3つの補間手法間のNMSE差は全てのサンプル数において0.002以内であり，手法間の性能差は小さい．

図中の水平破線はベースラインを示しており，上側の破線がファインチューニング前のベースラインモデル，下側の破線がCopy-Lastである．
サンプル数の増加に伴い，ファインチューニング後のNMSEがCopy-Lastを下回り，十分なサンプル数があれば予測モデルが有効に機能することが確認できる．





\subsubsection{雑音に対する堅牢性評価}
提案手法の雑音環境下における性能を評価するため，評価用CSIに対して加法性白色ガウス雑音（AWGN）を付与し，各SNRにおける予測NMSEを測定した．

雑音の付与方法を以下に示す．
CSIテンソルを$\bm{H}\in\mathbb{C}^{T\times R_B\times T_x\times R_x}$とする．
SNR[dB]からノイズパワー比$\sigma$を
\begin{equation}
  \sigma=10^{-\frac{\mathrm{SNR}_{\mathrm{dB}}}{10}}
\end{equation}
として算出する．
標準複素ガウス雑音$z\sim\mathcal{CN}(0,1)$を生成し，CSIの平均電力を$P_s=\mathbb{E}\left[|\bm{H}|^2\right]$とする．
雑音を$n=\sqrt{\sigma P_s / 2}\,z$としてスケーリングし，雑音付加後のCSIを
\begin{equation}
  \bm{H}_{\mathrm{noisy}}=\bm{H}+n
\end{equation}
とする．
このとき，信号対雑音電力比は$\mathrm{SNR}=P_s/\mathbb{E}[|n|^2]=1/\sigma$を満たす．

評価対象のベースラインとして，ファインチューニング前の事前学習モデルであるベースラインモデルと，直前フレームをそのまま予測値とするCopy-Lastを設定した．
ベースラインモデルの予測NMSEは0.1439，Copy-LastのNMSEは0.1755である．
\autoref{tab:baseline_comparison_fold}に示した結果と値が異なるのは，データ分割のランダム性の違いによる．
本評価ではNMSEが比較的小さく算出される区間が評価用データに割り当てられたと考えられる．

評価対象のSNRは$-2$，$0$，$2$，$4$，$6$，$8$，$10$，$15$，$20$~dBとした．
\autoref{tab:noise_snr}に各SNRにおける予測NMSEを示す．
比較対象の補間手法として，3次スプライン補間，片側3点4次多項式近似，片側3点5次多項式近似の3手法を用いた．

\begin{table}[H]
  \centering
  \caption{各SNRにおける予測NMSE}
  \label{tab:noise_snr}
  \small
  \resizebox{\textwidth}{!}{
    \begin{tabular}{lccc}
      \hline
      SNR [dB] & 3次スプライン & 片側3点4次多項式 & 片側3点5次多項式 \\
      \hline
      クリーン & 0.0310 & 0.0310 & 0.0309 \\
      $-2$ & 0.0817 & 0.0813 & 0.0818 \\
      $0$ & 0.0614 & 0.0617 & 0.0615 \\
      $2$ & 0.0481 & 0.0486 & 0.0487 \\
      $4$ & 0.0411 & 0.0415 & 0.0414 \\
      $6$ & 0.0369 & 0.0371 & 0.0371 \\
      $8$ & 0.0348 & 0.0348 & 0.0343 \\
      $10$ & 0.0333 & 0.0332 & 0.0332 \\
      $15$ & 0.0316 & 0.0315 & 0.0316 \\
      $20$ & 0.0313 & 0.0311 & 0.0312 \\
      \hline
    \end{tabular}
  }
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=100mm]{../picture/4nd/441_snr_nmse_plot.png}
  \caption{各SNRにおける予測NMSE}
  \label{fig:snr_nmse_plot}
\end{figure}

\autoref{tab:noise_snr}および\autoref{fig:snr_nmse_plot}から，SNRが低いほど予測NMSEが大きくなり，SNRが高くなるほど予測NMSEが小さくなることが確認できる．
SNRが$-2$~dBのとき，3次スプライン補間では0.0817，片側3点4次多項式近似では0.0813，片側3点5次多項式近似では0.0818のNMSEを示す．
一方，SNRが$20$~dBのとき，各手法のNMSEは0.0313，0.0311，0.0312となり，クリーンな場合の0.0310前後に近づく．
この結果から，ノイズが大きい環境では予測精度が低下するが，SNRが高くなるにつれて予測精度が向上し，ノイズの影響が小さくなる環境ではクリーンな場合と同等の性能を維持できることが示される．

3つの補間手法を比較すると，各SNRにおけるNMSEの差は0.0001から0.0006程度であり，手法間の性能差は小さい．
特にSNRが$8$~dB以上の高SNR領域では，3手法のNMSEはほぼ一致しており，補間手法の選択による性能への影響は限定的である．
このことから，ノイズ環境における予測性能は，補間手法の違いよりもSNRの影響が支配的であると考えられる．





\subsection{セル内チャネル統計変動時}
\label{sec:evaluation_of_prediction_mechanism_using_time_series_interpolation_learning_data_channel_statistical_variation_within_cell}

本節では，同一セル内においてチャネル統計特性が変動した場合の予測性能を評価する．
前節では異なる地域間でのモデル適応を検証したが，実環境では同一セル内においても建物の建設や解体により電波伝搬環境が変化する場合がある．
本節の実験では，このような環境変化に対する予測モデルの適応性を検証する．

評価用データセットとして，東京駅八重洲口周辺の地形データを用いる．
当該エリアは現在大規模な再開発が進行しており，新たな高層ビルの建設によりセル内の電波伝搬環境が変化する状況を想定できる．
\autoref{fig:area_marunouchi}に示すように，本評価では同一エリアにおいてビル建設前後の2種類の地形データを用意した．
\autoref{fig:marunouchi_built}はビル建設後の状態を示しており，高層ビルにより見通しが遮られたNLoS環境を形成している．
一方，\autoref{fig:marunouchi_before_build}はビル建設前の状態であり，見通しが確保されたLoS環境となっている．

本実験では，NLoS環境で運用していたチャネル予測モデルを環境変化後のLoS環境に適応させる状況を想定する．
ビル建設後のNLoS環境で収集したCSI系列により事前学習を行い，その後ビル解体や都市再開発によりLoS環境へ変化した際に，限られたサンプル数でモデルを再適応させることを目指す．
セル内の環境変化は段階的に生じることが多く，変化直後は新環境に対応した学習データが不足するため，効率的なファインチューニング手法が求められる．

実験手順は前節と同様とする．
事前学習に用いるモデルアーキテクチャおよびハイパーパラメータ，補間手法，ファインチューニングの設定は\autoref{sec:evaluation_of_prediction_mechanism_using_time_series_interpolation_learning_data_new_base_station_installation}と同一である．
本節では画像生成および評価用データセットのみを八重洲の地形データに置き換え，事前学習データには前節と同様に池袋，渋谷，新宿の3地域で生成したCSI系列を用いる．

\subsubsection{ベースラインモデルの学習結果}
事前学習データを用いたベースラインモデルの学習結果を示す．
\autoref{fig:nlos_to_los_baseline_learning_curves}にベースラインモデルの学習曲線を示す．
横軸はエポック数，縦軸はNMSEである．

\begin{figure}[H]
  \centering
  \includegraphics[width=100mm]{../picture/4nd/443_nlos_to_los_learning_curves_nmse.png}
  \caption{ベースラインモデルの学習曲線（NLoSからLoSへの適応）}
  \label{fig:nlos_to_los_baseline_learning_curves}
\end{figure}

学習用データのNMSEはエポック数の増加に伴い単調に減少し，40エポック終了時点で約0.093に収束している．
検証用データのNMSEは初期エポックで急速に減少した後，約0.12前後で推移しており，15エポック以降はほぼ横ばいとなっている．
学習用データと検証用データのNMSEに約0.03の差が生じているが，検証用データのNMSEが発散していないことから，過学習の兆候は軽微であると判断できる．
学習曲線の挙動は前節の\autoref{fig:baseline_learning_curves}と類似しており，モデルが安定して収束していることが確認できる．

次に，ファインチューニングを行わない状態でのベースラインモデルの予測性能を評価する．
\autoref{tab:nlos_to_los_baseline_vs_copylast}に，八重洲のLoS環境における評価結果を示す．
Copy-Lastは前節と同様に，入力3フレームの最終時刻におけるCSI推定値をそのまま出力時刻の推定値として使用する手法である．

\begin{table}[H]
  \centering
  \caption{ベースラインモデルとCopy-LastのNMSE比較（NLoSからLoSへの適応）}
  \label{tab:nlos_to_los_baseline_vs_copylast}
  \begin{tabular}{lr}
    \hline
    手法 & NMSE \\
    \hline
    Copy-Last & 0.1397 \\
    ベースラインモデル（ファインチューニング前） & 0.4096 \\
    \hline
  \end{tabular}
\end{table}

ベースラインモデルのNMSEは0.4096であり，Copy-Lastの0.1397と比較して約2.9倍大きい値を示している．
この結果は，NLoS環境で学習したモデルがLoS環境に対して適切に汎化できていないことを示す．
前節の新基地局設置時の評価ではベースラインモデルがCopy-Lastを上回る性能を示したが，本実験ではチャネル統計特性の変化により予測精度が大幅に低下している．
NLoS環境とLoS環境では電波伝搬特性が根本的に異なるため，事前学習で獲得したチャネル予測能力が新環境に適用できていない．
この結果から，セル内の環境変化に対応するためにはファインチューニングによるモデル適応が必要であることが示唆される．

\subsubsection{ファインチューニング結果}
ベースラインモデルに対してファインチューニングを実施し，予測精度の改善を評価する．
補間手法の選定にあたっては，\autoref{tab:marunouchi_sssp_results}に示した八重洲データセットにおける補間精度評価の結果を参考にする．
同評価では，スプライン補間および4次または5次の多項式近似がNMSE 0.05程度と最良の精度を達成することが確認されている．
本実験ではこれらの手法を採用し，補間値を用いたファインチューニングを実施する．

学習サンプルの構成については，前節の\autoref{tab:cubic_spline_441_results}において補間値を入力の1番目に配置するFirstパターンが最良の改善率を示したことから，本実験でもFirstパターンを採用する．

\autoref{tab:nlos_to_los_finetuning_results}に各補間手法を用いたファインチューニング結果を示す．
表中のNMSEおよび標準偏差は5分割交差検証における値である．

\begin{table}[H]
  \centering
  \caption{補間手法ごとのファインチューニング結果（NLoSからLoSへの適応）}
  \label{tab:nlos_to_los_finetuning_results}
  \begin{tabular}{lcccc}
    \hline
    補間手法 & FT前NMSE & FT後NMSE & 標準偏差 & 改善率 \\
    \hline
    \textbf{4次多項式近似（$K=3$）} & 0.328--0.409 & \textbf{0.0960} & 0.0239 & \textbf{約76\%} \\
    5次多項式近似（$K=3$） & 0.328--0.409 & 0.0976 & 0.0231 & 約76\% \\
    スプライン補間 & 0.328--0.409 & 0.0978 & 0.0235 & 約76\% \\
    \hline
  \end{tabular}
\end{table}

4次多項式近似が最良の結果を示し，NMSEは0.0960となった．
5次多項式近似およびスプライン補間も同程度の精度を達成しており，3手法間のNMSE差は0.002以内に収まっている．
ファインチューニング前のベースラインモデルのNMSE 0.4096と比較すると，4次多項式近似では約76.6\%の改善が得られた．
Copy-LastのNMSE 0.1397と比較しても，ファインチューニング後のモデルは約31.3\%低いNMSEを達成している．
この結果から，時系列補間型学習データを用いたファインチューニングにより，セル内の環境変化に対してもモデルを効果的に適応できることが確認された．

次に，ファインチューニングに用いる学習サンプル数と予測精度の関係を評価する．
実運用においては新環境でのデータ収集量が限られる場合があるため，少量のサンプルでどの程度の性能改善が得られるかを把握することは重要である．
\autoref{fig:nlos_to_los_incremental_finetune}に，学習サンプル数を変化させた場合のファインチューニング後NMSEを示す．

比較対象の補間手法として，スプライン補間，4次多項式近似（$K=3$），5次多項式近似（$K=3$）に加え，ニューラルネットワーク補間（コンテキスト長3）を追加した．
ニューラルネットワーク補間は第\ref{sec:interpolation_methods}節で述べた手法であり，補間精度が低い場合にファインチューニング性能がどのように変化するかを検証するために比較対象として含めた．
第\ref{subsec:simulation_conditions}節の補間精度評価において，ニューラルネットワーク補間は多項式近似やスプライン補間と比較して補間NMSEが高い傾向にあることが確認されている．
したがって，ニューラルネットワーク補間を用いたファインチューニングでは，補間精度の劣化がどの程度予測性能に影響を与えるかを観察できる．

\begin{figure}[H]
  \centering
  \includegraphics[width=140mm]{../picture/4nd/442_NLoS_to_Los_incremental_finetune_nmse_vs_samples.png}
  \caption{学習サンプル数とファインチューニング後NMSEの関係（NLoSからLoSへの適応）}
  \label{fig:nlos_to_los_incremental_finetune}
\end{figure}

\autoref{fig:nlos_to_los_incremental_finetune}から，全ての補間手法において学習サンプル数の増加に伴いNMSEが単調に減少する傾向が確認できる．
図中の上側の水平破線はファインチューニング前のベースラインモデル（NMSE約0.36），下側の水平破線はCopy-Last（NMSE約0.13）を示す．

スプライン補間，4次多項式近似，5次多項式近似の3手法は，全てのサンプル数において同程度のNMSEを示しており，曲線がほぼ重なっている．
これらの手法では，学習サンプル数が20,000の時点でNMSEが約0.19となり，ベースラインモデルに対して約47\%の改善を達成している．
学習サンプル数が40,000に達するとNMSEは約0.13となり，Copy-Lastと同等の性能に到達する．
さらに学習サンプル数を増加させると，60,000サンプルでNMSEは約0.10，100,000サンプルでNMSEは約0.08となり，Copy-Lastを大幅に上回る性能を達成している．

一方，ニューラルネットワーク補間（コンテキスト長3）は，他の3手法と比較してNMSEが一貫して高い値を示している．
学習サンプル数が20,000のときNMSEは約0.20であり，スプライン補間等の約0.19と比較して若干高い．
この差異は学習サンプル数の増加に伴い拡大し，100,000サンプルにおいてニューラルネットワーク補間のNMSEは約0.09であるのに対し，スプライン補間等は約0.08となっている．

この結果から，補間精度がファインチューニング後の予測精度に影響を与えることが確認された．
ニューラルネットワーク補間は補間NMSEが他手法より高いため，生成される学習サンプルの品質が相対的に低く，これがファインチューニング後の予測性能の低下につながっている．
ただし，ニューラルネットワーク補間を用いた場合でもベースラインモデルやCopy-Lastを上回る性能を達成しており，補間精度が多少低い場合でも提案手法が有効に機能することが示された．

以上の結果から，補間手法の選択においては補間精度が高い手法を優先すべきであること，また学習サンプル数が限られる状況でも提案手法により一定の性能改善が得られることが確認された．




\subsubsection{雑音に対する堅牢性評価}
提案手法の雑音環境下における性能を評価するため，評価用CSIに対して加法性白色ガウス雑音を付与し，各SNRにおける予測NMSEを測定した．
雑音の付与方法は\autoref{sec:evaluation_of_prediction_mechanism_using_time_series_interpolation_learning_data_new_base_station_installation}と同様である．

評価対象のSNRは$-2$，$0$，$2$，$4$，$6$，$8$，$10$，$15$，$20$~dBとした．
比較対象の補間手法として，3次スプライン補間，片側3点4次多項式近似，片側3点5次多項式近似の3手法を用いた．
\autoref{tab:nlos_to_los_noise_snr}に各SNRにおける予測NMSEを示す．

\begin{table}[H]
  \centering
  \caption{各SNRにおける予測NMSE（NLoSからLoSへの適応）}
  \label{tab:nlos_to_los_noise_snr}
  \small
  \resizebox{\textwidth}{!}{
    \begin{tabular}{lccc}
      \hline
      SNR [dB] & 3次スプライン & 片側3点4次多項式 & 片側3点5次多項式 \\
      \hline
      クリーン & 0.0766 & 0.0768 & 0.0769 \\
      $20$ & 0.0766 & 0.0767 & 0.0768 \\
      $15$ & 0.0767 & 0.0770 & 0.0771 \\
      $10$ & 0.0782 & 0.0784 & 0.0785 \\
      $8$ & 0.0806 & 0.0807 & 0.0807 \\
      $6$ & 0.0850 & 0.0849 & 0.0849 \\
      $4$ & 0.0921 & 0.0916 & 0.0917 \\
      $2$ & 0.1023 & 0.1012 & 0.1015 \\
      $0$ & 0.1118 & 0.1097 & 0.1100 \\
      $-2$ & 0.1324 & 0.1307 & 0.1311 \\
      \hline
    \end{tabular}
  }
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=140mm]{../picture/4nd/443_input_snr_nmse_fullwidth_baselines.png}
  \caption{各SNRにおける予測NMSE（NLoSからLoSへの適応）}
  \label{fig:nlos_to_los_snr_nmse_plot}
\end{figure}

\autoref{tab:nlos_to_los_noise_snr}および\autoref{fig:nlos_to_los_snr_nmse_plot}から，SNRの低下に伴い予測NMSEが増加する傾向が確認できる．
SNRが$-2$~dBのとき，3次スプライン補間では0.1324，片側3点4次多項式近似では0.1307，片側3点5次多項式近似では0.1311のNMSEを示す．
一方，SNRが$20$~dB以上の高SNR領域では，各手法のNMSEは0.077程度となり，クリーンな場合とほぼ同等の性能を維持している．

図中の水平破線はベースラインを示しており，上側の破線がファインチューニング前のベースラインモデル，下側の破線がCopy-Lastである．
ファインチューニング後のモデルは，SNRが$-2$~dBの低SNR環境においてもCopy-Lastと同程度のNMSEを達成しており，SNRが$0$~dB以上ではCopy-Lastを下回る性能を示している．
ファインチューニング前のベースラインモデルと比較すると，全てのSNR条件においてファインチューニング後のモデルが大幅に低いNMSEを達成している．

3つの補間手法を比較すると，各SNRにおけるNMSEの差は0.002以内であり，手法間の性能差は小さい．
特にSNRが$8$~dB以上の高SNR領域では，3手法のNMSEはほぼ一致している．
前節の新基地局設置時の評価と同様に，ノイズ環境における予測性能は補間手法の違いよりもSNRの影響が支配的である．

\subsection{セル内チャネル統計変動時（LoSからNLoSへの適応）}
\label{sec:evaluation_of_prediction_mechanism_using_time_series_interpolation_learning_data_los_to_nlos}

前節ではNLoS環境からLoS環境への適応を検証したが，本節では逆方向の適応，すなわちLoS環境からNLoS環境への適応について評価する．
都市部においては新規ビルの建設により，従来見通しが確保されていたセルにおいて遮蔽物が出現しNLoS環境へ移行する状況が頻繁に生じる．
このような環境変化に対しても，提案する時系列補間型ファインチューニング手法が有効であるかを検証する．

本実験では，ビル建設以前のLoS環境で収集したCSI系列により事前学習を行い，その後ビル建設によりNLoS環境へ変化した際に，限られたサンプル数でモデルを再適応させることを想定する．
前節の評価ではNLoS環境で運用していたモデルをLoS環境に適応させたが，本節では逆にLoS環境で運用していたチャネル予測モデルをNLoS環境に適応させる．
LoS環境からNLoS環境への移行では，直接波が遮蔽されることでチャネルの変動特性が大きく変化するため，モデルの適応がより困難になることが予想される．

評価用データセットには，前節と同様に東京駅八重洲口周辺の地形データを用いる．
\autoref{fig:area_marunouchi}に示した2種類の地形データのうち，本節ではビル建設前のLoS環境（\autoref{fig:marunouchi_before_build}）を事前学習に用い，ビル建設後のNLoS環境（\autoref{fig:marunouchi_built}）を評価対象とする．
すなわち，前節とは事前学習環境と評価環境の役割を入れ替えた設定である．

実験手順は前節と同様とする．
事前学習に用いるモデルアーキテクチャおよびハイパーパラメータは\autoref{sec:evaluation_of_prediction_mechanism_using_time_series_interpolation_learning_data_new_base_station_installation}と同一である．
補間手法には，第\ref{subsec:simulation_conditions}節において有効性が確認されたスプライン補間，4次多項式近似（$K=3$），5次多項式近似（$K=3$）の3手法を用いる．
ファインチューニングの設定は前節と同様に，補間値を入力の1番目に配置するFirstパターンを採用する．









\subsubsection{ベースラインモデルの学習結果}
LoS環境の事前学習データを用いたベースラインモデルの学習結果を示す．
\autoref{fig:los_to_nlos_baseline_learning_curves}にベースラインモデルの学習曲線を示す．
横軸はエポック数，縦軸はNMSEである．

\begin{figure}[H]
  \centering
  \includegraphics[width=100mm]{../picture/4nd/442_learning_curves_nmse_LoS_NLoS.png}
  \caption{ベースラインモデルの学習曲線（LoSからNLoSへの適応）}
  \label{fig:los_to_nlos_baseline_learning_curves}
\end{figure}

学習用データのNMSEはエポック数の増加に伴い減少し，40エポック終了時点で約0.08に収束している．
検証用データのNMSEは初期エポックで急速に減少した後，約0.12前後で推移している．
学習用データと検証用データのNMSEに約0.04の差が生じているが，検証用データのNMSEが発散していないことから，過学習の兆候は軽微であると判断できる．
前節のNLoS環境での事前学習（\autoref{fig:nlos_to_los_baseline_learning_curves}）と比較すると，LoS環境での学習は検証用NMSEが若干高い傾向にあるが，学習の収束挙動は同様である．

次に，ファインチューニングを行わない状態でのベースラインモデルの予測性能を評価する．
\autoref{tab:los_to_nlos_baseline_vs_copylast}に，八重洲のNLoS環境における評価結果を示す．
Copy-Lastは前節と同様に，入力3フレームの最終時刻におけるCSI推定値をそのまま出力時刻の推定値として使用する手法である．

\begin{table}[H]
  \centering
  \caption{ベースラインモデルとCopy-LastのNMSE比較（LoSからNLoSへの適応）}
  \label{tab:los_to_nlos_baseline_vs_copylast}
  \begin{tabular}{lr}
    \hline
    手法 & NMSE \\
    \hline
    Copy-Last & 0.2056 \\
    ベースラインモデル（ファインチューニング前） & 0.4869 \\
    \hline
  \end{tabular}
\end{table}

ベースラインモデルのNMSEは0.4869であり，Copy-Lastの0.2056と比較して約2.4倍大きい値を示している．
この結果は，LoS環境で学習したモデルがNLoS環境に対して適切に汎化できていないことを示す．
前節のNLoS→LoS適応（ベースラインNMSE 0.4096）と比較して，本節のLoS→NLoS適応ではベースラインNMSEがより高い値を示している．
LoS環境では直接波が支配的であり比較的単純なチャネル特性を学習するが，NLoS環境では多重反射による複雑な伝搬経路が存在するため，環境変化に伴う特性変動が大きく，モデルの汎化がより困難になっていると考えられる．
この結果から，LoS→NLoS適応においてもファインチューニングによるモデル適応が必要であることが示唆される．

\subsubsection{ファインチューニング結果}
ベースラインモデルに対してファインチューニングを実施し，予測精度の改善を評価する．
補間手法の選定にあたっては，第\ref{subsec:simulation_conditions}節において有効性が確認されたスプライン補間，4次多項式近似（$K=3$），5次多項式近似（$K=3$）を採用する．
学習サンプルの構成については，前節と同様に補間値を入力の1番目に配置するFirstパターンを用いる．

\autoref{tab:los_to_nlos_finetuning_results}に各補間手法を用いたファインチューニング結果を示す．
表中のNMSEおよび標準偏差は5分割交差検証における値である．

\begin{table}[H]
  \centering
  \caption{補間手法ごとのファインチューニング結果（LoSからNLoSへの適応）}
  \label{tab:los_to_nlos_finetuning_results}
  \begin{tabular}{lcccc}
    \hline
    補間手法 & FT前NMSE & FT後NMSE & 標準偏差 & 改善率 \\
    \hline
    スプライン補間 & 0.462--0.506 & 0.1275 & 0.0168 & 約74\% \\
    4次多項式近似（$K=3$） & 0.462--0.506 & 0.1277 & 0.0171 & 約74\% \\
    \textbf{5次多項式近似（$K=3$）} & 0.462--0.506 & \textbf{0.1275} & 0.0171 & \textbf{約74\%} \\
    \hline
  \end{tabular}
\end{table}

5次多項式近似が最良の結果を示し，NMSEは0.1275となった．
スプライン補間および4次多項式近似も同程度の精度を達成しており，3手法間のNMSE差は0.0002以内に収まっている．
ファインチューニング前のベースラインモデルのNMSE 0.4869と比較すると，5次多項式近似では約73.8\%の改善が得られた．
Copy-LastのNMSE 0.2056と比較しても，ファインチューニング後のモデルは約38.0\%低いNMSEを達成している．

前節のNLoS→LoS適応（FT後NMSE 0.0960，改善率76\%）と比較すると，本節のLoS→NLoS適応ではFT後NMSEがやや高く（0.1275），改善率もやや低い（74\%）．
これは，NLoS環境における複雑なチャネル特性が予測をより困難にしているためと考えられる．
しかしながら，提案手法により大幅な性能改善が得られており，セル内の環境変化に対してもモデルを効果的に適応できることが確認された．

次に，ファインチューニングに用いる学習サンプル数と予測精度の関係を評価する．
前節のNLoS→LoS適応と同様に，少量のサンプルでどの程度の性能改善が得られるかを把握することは実運用において重要である．
\autoref{fig:los_to_nlos_incremental_finetune}に，学習サンプル数を変化させた場合のファインチューニング後NMSEを示す．

比較対象の補間手法として，スプライン補間，4次多項式近似（$K=3$），5次多項式近似（$K=3$）の3手法を用いた．

\begin{figure}[H]
  \centering
  \includegraphics[width=140mm]{../picture/4nd/442_LoS_to_NLoS_incremental_finetune_nmse_vs_samples.png}
  \caption{学習サンプル数とファインチューニング後NMSEの関係（LoSからNLoSへの適応）}
  \label{fig:los_to_nlos_incremental_finetune}
\end{figure}

\autoref{fig:los_to_nlos_incremental_finetune}から，全ての補間手法において学習サンプル数の増加に伴いNMSEが単調に減少する傾向が確認できる．
図中の上側の水平破線はファインチューニング前のベースラインモデル（NMSE約0.49），下側の水平破線はCopy-Last（NMSE約0.19）を示す．

スプライン補間，4次多項式近似，5次多項式近似の3手法は，全てのサンプル数において同程度のNMSEを示しており，曲線がほぼ重なっている．
これらの手法では，学習サンプル数が25,000の時点でNMSEが約0.22となり，ベースラインモデルに対して約55\%の改善を達成している．
学習サンプル数が50,000に達するとNMSEは約0.175となり，Copy-Lastを下回る性能に到達する．
さらに学習サンプル数を増加させると，70,000サンプルでNMSEは約0.15，90,000サンプルでNMSEは約0.135となり，120,000サンプルではNMSEは約0.125となってCopy-Lastを大幅に上回る性能を達成している．

前節のNLoS→LoS適応（\autoref{fig:nlos_to_los_incremental_finetune}）と比較すると，本節のLoS→NLoS適応ではCopy-Lastを下回るために必要なサンプル数がより多い傾向にある．
NLoS→LoS適応では約40,000サンプルでCopy-Lastと同等になるのに対し，LoS→NLoS適応では約50,000サンプルが必要である．
また，最終的なNMSEについても，NLoS→LoS適応では100,000サンプルで約0.08に達するのに対し，LoS→NLoS適応では120,000サンプルでも約0.125にとどまっている．
これらの差異は，NLoS環境におけるチャネル変動の複雑さが予測をより困難にしていることを反映している．

ただし，LoS→NLoS適応においても学習サンプル数の増加に伴う一貫した性能改善が確認されており，十分なサンプル数を確保することで高い予測精度を達成できることが示された．






\subsubsection{雑音に対する堅牢性評価}
提案手法の雑音環境下における性能を評価するため，評価用CSIに対して加法性白色ガウス雑音を付与し，各SNRにおける予測NMSEを測定した．
雑音の付与方法は\autoref{sec:evaluation_of_prediction_mechanism_using_time_series_interpolation_learning_data_new_base_station_installation}と同様である．

評価対象のSNRは$-2$，$0$，$2$，$4$，$6$，$8$，$10$，$15$，$20$~dBとした．
比較対象の補間手法として，3次スプライン補間，片側3点4次多項式近似，片側3点5次多項式近似の3手法を用いた．
\autoref{tab:los_to_nlos_noise_snr}に各SNRにおける予測NMSEを示す．

\begin{table}[H]
  \centering
  \caption{各SNRにおける予測NMSE（LoSからNLoSへの適応）}
  \label{tab:los_to_nlos_noise_snr}
  \small
  \resizebox{\textwidth}{!}{
    \begin{tabular}{lccc}
      \hline
      SNR [dB] & 3次スプライン & 片側3点4次多項式 & 片側3点5次多項式 \\
      \hline
      クリーン & 0.1265 & 0.1267 & \textbf{0.1261} \\
      $20$ & 0.1268 & 0.1265 & \textbf{0.1263} \\
      $15$ & 0.1266 & 0.1268 & \textbf{0.1265} \\
      $10$ & 0.1299 & 0.1281 & \textbf{0.1283} \\
      $8$ & 0.1304 & 0.1305 & \textbf{0.1303} \\
      $6$ & 0.1337 & \textbf{0.1335} & 0.1334 \\
      $4$ & 0.1393 & 0.1395 & \textbf{0.1394} \\
      $2$ & 0.1469 & 0.1476 & \textbf{0.1472} \\
      $0$ & 0.1602 & \textbf{0.1601} & 0.1601 \\
      $-2$ & 0.1806 & 0.1811 & \textbf{0.1805} \\
      \hline
    \end{tabular}
  }
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=140mm]{../picture/4nd/442_snr_nmse_plot.png}
  \caption{各SNRにおける予測NMSE（LoSからNLoSへの適応）}
  \label{fig:los_to_nlos_snr_nmse_plot}
\end{figure}

\autoref{tab:los_to_nlos_noise_snr}および\autoref{fig:los_to_nlos_snr_nmse_plot}から，SNRの低下に伴い予測NMSEが増加する傾向が確認できる．
SNRが$-2$~dBのとき，3次スプライン補間では0.1806，片側3点4次多項式近似では0.1811，片側3点5次多項式近似では0.1805のNMSEを示す．
一方，SNRが$20$~dB以上の高SNR領域では，各手法のNMSEは0.127程度となり，クリーンな場合とほぼ同等の性能を維持している．

図中の水平破線はベースラインを示しており，上側の破線がファインチューニング前のベースラインモデル（NMSE 0.4921），下側の破線がCopy-Last（NMSE 0.1901）である．
ファインチューニング後のモデルは，SNRが$-2$~dBの低SNR環境においてもCopy-Lastを下回るNMSE（約0.18）を達成している．
SNRが$0$~dB以上では，ファインチューニング後のモデルはCopy-Lastと比較して大幅に低いNMSEを示している．
ファインチューニング前のベースラインモデルと比較すると，全てのSNR条件においてファインチューニング後のモデルが大幅に低いNMSEを達成している．

3つの補間手法を比較すると，各SNRにおけるNMSEの差は0.001以内であり，手法間の性能差は極めて小さい．
特にSNRが$10$~dB以上の高SNR領域では，3手法のNMSEはほぼ一致している．
前節のNLoS→LoS適応と同様に，ノイズ環境における予測性能は補間手法の違いよりもSNRの影響が支配的である．

前節のNLoS→LoS適応（\autoref{tab:nlos_to_los_noise_snr}）と比較すると，本節のLoS→NLoS適応ではSNRが$-2$~dBのときのNMSEが0.18程度であり，前節の0.13程度よりも高い値を示している．
これは，NLoS環境における複雑なチャネル特性が雑音環境下においても予測を困難にしていることを示唆する．
しかしながら，いずれのSNR条件においてもファインチューニング後のモデルはCopy-Lastおよびベースラインモデルを上回る性能を示しており，提案手法の有効性が確認された．

\subsection{セル内チャネル統計変動における双方向適応の比較考察}
\label{sec:bidirectional_adaptation_comparison}

本節では，セル内チャネル統計変動時における2つの適応方向，すなわちNLoS→LoS適応（\autoref{sec:evaluation_of_prediction_mechanism_using_time_series_interpolation_learning_data_channel_statistical_variation_within_cell}）とLoS→NLoS適応（\autoref{sec:evaluation_of_prediction_mechanism_using_time_series_interpolation_learning_data_los_to_nlos}）の実験結果を比較し，適応方向の違いが予測性能に与える影響について考察する．

\subsubsection{実験結果の比較}
\autoref{tab:bidirectional_comparison}に両方向の適応実験における主要な評価指標を整理する．

\begin{table}[H]
  \centering
  \caption{NLoS→LoS適応とLoS→NLoS適応の比較}
  \label{tab:bidirectional_comparison}
  \begin{tabular}{lcc}
    \hline
    評価指標 & NLoS→LoS & LoS→NLoS \\
    \hline
    Copy-Last NMSE & 0.1397 & 0.2056 \\
    ベースラインNMSE（FT前） & 0.4096 & 0.4869 \\
    FT後NMSE（最良） & 0.0960 & 0.1275 \\
    改善率 & 約76\% & 約74\% \\
    最良補間手法 & 4次多項式近似 & 5次多項式近似 \\
    SNR $-2$~dB時NMSE & 0.13程度 & 0.18程度 \\
    \hline
  \end{tabular}
\end{table}

\autoref{tab:bidirectional_comparison}から，全ての評価指標においてNLoS→LoS適応がLoS→NLoS適応よりも優れた結果を示していることが確認できる．
以下では，この差異が生じる要因について物理的な観点から考察する．

\subsubsection{LoS環境とNLoS環境のチャネル特性の違い}
LoS環境とNLoS環境では，電波伝搬の物理的メカニズムが根本的に異なる．
LoS環境では送受信間に直接波が存在し，この直接波がチャネル応答の主成分となる．
直接波は伝搬距離に応じた位相回転と自由空間伝搬損失により特徴づけられ，ユーザの移動に伴うドップラー周波数シフトも比較的予測しやすい挙動を示す．
したがって，LoS環境のチャネル時系列は滑らかな変動パターンを持ち，時間的相関が強い傾向にある．

一方，NLoS環境では直接波が遮蔽物により遮断され，散乱波や反射波のみがチャネル応答を構成する．
複数の反射経路が干渉し合うことでマルチパスフェージングが生じ，チャネル応答は振幅と位相の両方において急激な変動を示す．
特に，各反射経路の遅延時間と到来角が異なるため，ユーザの微小な移動でも経路間の位相関係が大きく変化し，チャネル時系列は複雑で予測困難なパターンとなる．

\subsubsection{Copy-Last性能の差異に関する考察}
Copy-Last手法は直前のCSI推定値をそのまま将来時刻の推定値として使用するため，その性能はチャネルの時間的相関に強く依存する．
\autoref{tab:bidirectional_comparison}において，LoS環境でのCopy-Last NMSE（0.1397）がNLoS環境（0.2056）より約32\%低い値を示している．
この差異は，LoS環境のチャネルがより強い時間的相関を持ち，時間変動が緩やかであることを反映している．

NLoS環境では，マルチパスフェージングによる急激なチャネル変動が生じるため，直前の観測値と現在の真値との乖離が大きくなる．
この結果として，Copy-Last手法の予測誤差が増大し，NLoS環境でのCopy-Last NMSEが高い値を示している．

\subsubsection{ベースラインモデルの汎化性能に関する考察}
ファインチューニング前のベースラインモデルのNMSEは，NLoS→LoS適応で0.4096，LoS→NLoS適応で0.4869であり，LoS→NLoS適応の方が約19\%高い値を示している．
この差異は，事前学習環境と評価環境の特性差がモデルの汎化性能に与える影響を示唆している．

NLoS→LoS適応では，複雑なNLoS環境で事前学習したモデルを比較的単純なLoS環境に適用する．
NLoS環境での学習により，モデルは多様なチャネル変動パターンを学習しており，LoS環境における規則的な変動パターンに対しても一定程度の予測能力を発揮できると考えられる．
すなわち，複雑な環境での学習が単純な環境への汎化を部分的に可能にしている．

一方，LoS→NLoS適応では，比較的単純なLoS環境で事前学習したモデルを複雑なNLoS環境に適用する．
LoS環境では直接波が支配的であり，チャネル変動は主にドップラー効果による滑らかな位相回転として現れる．
このような限定的なパターンのみを学習したモデルは，NLoS環境における急激な振幅変動やマルチパスフェージングに対応できず，汎化性能が低下する．
この結果として，LoS→NLoS適応ではベースラインNMSEがより高い値を示している．

\subsubsection{ファインチューニング効果の差異に関する考察}
ファインチューニング後のNMSEは，NLoS→LoS適応で0.0960，LoS→NLoS適応で0.1275であり，約33\%の差が生じている．
改善率についても，NLoS→LoS適応が約76\%，LoS→NLoS適応が約74\%と，若干の差異が見られる．

この差異は，目標環境であるLoS環境とNLoS環境の本質的な予測困難度の違いに起因すると考えられる．
前述のように，LoS環境のチャネルは時間的相関が強く滑らかに変動するため，時系列予測モデルにとって学習・予測が容易である．
一方，NLoS環境のチャネルは急激な変動を示すため，同程度の学習データとモデル容量では，LoS環境と同等の予測精度を達成することが困難である．

ただし，両方向とも70\%以上の改善率を達成しており，提案する時系列補間型ファインチューニング手法は適応方向に関わらず有効に機能することが確認された．
LoS→NLoS適応においてもCopy-Lastと比較して約38\%のNMSE改善を達成しており，実用上十分な性能向上が得られている．

\subsubsection{雑音環境下における性能差に関する考察}
SNRが$-2$~dBの低SNR環境において，NLoS→LoS適応ではNMSEが0.13程度，LoS→NLoS適応では0.18程度を示しており，約38\%の差が生じている．
この差異は，クリーン環境での性能差（約33\%）よりも拡大している．

雑音環境では，CSI推定値に加法性雑音が重畳されるため，時系列データから真のチャネル変動パターンを抽出することがより困難になる．
NLoS環境では元来チャネル変動が複雑であるため，雑音の影響を受けた際に真のチャネル変動と雑音成分を分離することがより困難になる．
この結果として，LoS→NLoS適応では雑音環境における性能劣化がより顕著に現れている．

しかしながら，LoS→NLoS適応においてもSNRが$-2$~dBの条件でCopy-Last（NMSE 0.1901）を下回る性能を維持しており，提案手法は雑音環境においても有効に機能することが確認された．



\section{パイロット疎化拡大に伴う無線チャネル予測機構評価}
\label{sec:evaluation_of_prediction_mechanism_using_time_series_interpolation_learning_data_pilot_sparse_expansion}

前節までの評価では，3入力1出力の機械学習モデルを用いた．
パイロット信号の送信周期を5~msとすると，この設定は20~msあたり1回のパイロット送信を予測により削減できることを意味する．
すなわち，4スロット中3スロットで推定値を取得し，残り1スロットの参照信号送信を省略する運用に相当する．

本節では，パイロット信号の削減割合をさらに大きくした場合についても，提案したチャネル予測機構によりモデルの精度を改善しつつ運用が可能であるかを評価する．

入出力の時間間隔を変化させることで，同一の3入力1出力モデルを用いながらパイロット送信の削減割合を増加させることが可能である．
ここでSはパイロット信号を送信するスロット，Pは予測により代替するスロットを表す．
本研究では，SSSP，SSP，SPの3種類の疎化パターンを検討する．

各パターンの時系列配置と予測モデルへの入出力対応を\autoref{tab:sparsity_patterns}に示す．

\begin{table}[H]
  \centering
  \caption{疎化パターンと入出力の対応}
  \label{tab:sparsity_patterns}
  \begin{tabular}{lccc}
    \hline
    パターン & 時系列配置 & 入力 & 出力 \\
    \hline
    SSSP & S, S, S, P, S, S, S, P, $\cdots$ & $h_{t-3}, h_{t-2}, h_{t-1}$ & $h_t$ \\
    SSP  & S, S, P, S, S, P, $\cdots$ & $h_{t-4}, h_{t-2}, h_{t-1}$ & $h_t$ \\
    SP   & S, P, S, P, $\cdots$ & $h_{t-5}, h_{t-3}, h_{t-1}$ & $h_t$ \\
    \hline
  \end{tabular}
\end{table}

SSSPパターンでは4スロット中1スロットを予測で代替し，削減率は25\%である．
SSPパターンでは3スロット中1スロットを予測で代替し，削減率は約33\%となる．
SPパターンでは2スロット中1スロットを予測で代替し，削減率は50\%に達する．

いずれのパターンでも，予測対象となるPスロットの直前に存在する3つのSスロットを入力として選択する．
SSSPでは直前3スロットが連続してSであるため，時刻$t-3, t-2, t-1$のCSIを入力とする．
SSPでは$t-3$がPスロットとなるため，これを避けて$t-4, t-2, t-1$を選択する．
SPでは1スロットおきにPが配置されるため，$t-5, t-3, t-1$の3点を選択する．

このように入力の時間間隔を調整することで，モデルの入出力形式を3入力1出力に統一したまま，異なる削減率に対応した学習データを生成できる．

提案機構では，補間値を用いてファインチューニング用の学習サンプルを構成する．
各疎化パターンにおいて，サンプルの構成方法は複数存在する．
入力の3スロットと出力の1スロットに対して，推定値Sと補間値Iをどのように配置するかによって異なる学習サンプルが得られる．
本研究では，パターンごとに2種類のサンプル構成を比較し，どの構成が予測精度の改善に有効であるかを検証した．

各疎化パターンにおけるファインチューニング用サンプルの構成を\autoref{tab:ft_sample_config}に示す．

\begin{table}[H]
  \centering
  \caption{ファインチューニング用サンプルの構成}
  \label{tab:ft_sample_config}
  \begin{tabular}{llcc}
    \hline
    パターン & 構成名 & 入力 & 出力 \\
    \hline
    周期3 & I,S,I$\rightarrow$S & 補間, 推定, 補間 & 推定 \\
    周期3 & S,I,S$\rightarrow$S & 推定, 補間, 推定 & 推定 \\
    \hline
    周期2 & I,I,I$\rightarrow$S & 補間, 補間, 補間 & 推定 \\
    周期2 & S,S,S$\rightarrow$I & 推定, 推定, 推定 & 補間 \\
    \hline
  \end{tabular}
\end{table}

周期3パターンでは，時系列S,S,I,S,S,I,$\cdots$において，入力の3スロットに補間値Iが1つまたは2つ含まれる構成となる．
I,S,I$\rightarrow$Sは入力に補間値を2つ含み推定値を出力とする構成である．
S,I,S$\rightarrow$Sは入力に補間値を1つ含み推定値を出力とする構成である．

周期2パターンでは，時系列S,I,S,I,$\cdots$において，入力と出力の構成が大きく異なる2種類となる．
I,I,I$\rightarrow$Sは入力がすべて補間値であり推定値を出力とする構成である．
S,S,S$\rightarrow$Iは入力がすべて推定値であり補間値を出力とする構成である．

\subsection{MLPモデルにおける疎化拡大}
\label{sec:evaluation_of_prediction_mechanism_using_time_series_interpolation_learning_data_pilot_sparse_expansion_mlp_model}





\subsection{LSTMモデルにおける疎化拡大}
\label{sec:evaluation_of_prediction_mechanism_using_time_series_interpolation_learning_data_pilot_sparse_expansion_lstm_model}

本節では，LSTMモデルを用いて疎化拡大の評価を行う．
用いるLSTMアーキテクチャは，\autoref{sec:simulation}で述べた2層スタックLSTMと同一である．

以降，SSPパターンを周期3パターン，SPパターンを周期2パターンと呼称する．
周期3パターンは3スロット中1スロットを予測で代替し削減率33\%に相当する．
周期2パターンは2スロット中1スロットを予測で代替し削減率50\%に相当する．

\subsubsection{ベースラインモデルの学習}
周期3パターンおよび周期2パターンのベースラインモデルについて，学習曲線を\autoref{fig:lstm_ssp_learning_curve}および\autoref{fig:lstm_sp_learning_curve}に示す．

\begin{figure}[H]
  \centering
  \includegraphics[width=140mm]{../picture/4nd/45_ssp_learning_curves_nmse_ssp.png}
  \caption{周期3パターンにおけるLSTMベースラインモデルの学習曲線}
  \label{fig:lstm_ssp_learning_curve}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=140mm]{../picture/4nd/45_sp_learning_curves_nmse_sp.png}
  \caption{周期2パターンにおけるLSTMベースラインモデルの学習曲線}
  \label{fig:lstm_sp_learning_curve}
\end{figure}

両パターンともに，検証NMSEは序盤の5から10エポック程度で急激に低下し，その後はほぼ横ばいとなる．
訓練NMSEは40エポックまで緩やかに改善を続けるが，検証NMSEの改善は限定的である．
この傾向から，ベースラインモデルは早期に収束する特性を持つことがわかる．

訓練NMSEと検証NMSEの間には一定の差が存在するものの，検証NMSEが後半で悪化し続ける挙動は見られない．
軽度の過学習が生じているが安定した状態を維持している．
この差は，事前学習データと検証データの間の分布差，すなわち学習に用いた都市と評価に用いた都市の環境差に起因すると考えられる．

周期3パターンと周期2パターンを比較すると，周期3パターンのほうが検証NMSEが低い傾向にある．
同一のLSTMアーキテクチャであっても，入力の観測密度が高いパターンのほうが予測精度が高くなることを示している．
周期3パターンでは入力間隔が狭く時間的に近接した観測値を利用できるため，予測対象との相関が強く保たれる．
一方，周期2パターンでは入力間隔が広がり，時間的に離れた観測値を用いるため予測が困難になる．

\subsubsection{ベースラインモデルの評価}
予測を用いないCopy-Lastとベースラインモデルについて，評価データに対する各分割のNMSEを\autoref{tab:lstm_ssp_baseline}および\autoref{tab:lstm_sp_baseline}に示す．

\begin{table}[H]
  \centering
  \caption{周期3パターンにおけるベースライン比較}
  \label{tab:lstm_ssp_baseline}
  \begin{tabular}{lccc}
    \hline
    Fold & Copy-Last NMSE & ベースライン NMSE & 改善率 [\%] \\
    \hline
    0 & 0.2401 & 0.1400 & 41.68 \\
    1 & 0.1867 & 0.1261 & 32.44 \\
    2 & 0.1687 & 0.1162 & 31.11 \\
    3 & 0.1999 & 0.1335 & 33.20 \\
    4 & 0.2044 & 0.1137 & 44.36 \\
    \hline
    平均 & 0.1999 & 0.1259 & 37.03 \\
    \hline
  \end{tabular}
\end{table}

\begin{table}[H]
  \centering
  \caption{周期2パターンにおけるベースライン比較}
  \label{tab:lstm_sp_baseline}
  \begin{tabular}{lccc}
    \hline
    Fold & Copy-Last NMSE & ベースライン NMSE & 改善率 [\%] \\
    \hline
    0 & 0.2401 & 0.1677 & 30.13 \\
    1 & 0.1867 & 0.1478 & 20.84 \\
    2 & 0.1687 & 0.1374 & 18.58 \\
    3 & 0.1999 & 0.1576 & 21.17 \\
    4 & 0.2044 & 0.1387 & 32.13 \\
    \hline
    平均 & 0.1999 & 0.1498 & 25.07 \\
    \hline
  \end{tabular}
\end{table}

周期3パターンでは，ベースラインモデルがCopy-Lastに対して平均37.03\%の改善を達成している．
周期2パターンでは平均25.07\%の改善にとどまる．
疎化率が高くなるほど予測が困難になり，ベースラインモデルの性能優位性が縮小する傾向が確認できる．

\subsubsection{ファインチューニング後の性能}
提案機構によるファインチューニング後の性能を\autoref{tab:lstm_ft_performance}に示す．
\autoref{tab:ft_sample_config}で示した2種類のサンプル構成それぞれについてファインチューニングを実施した．
補間手法として，3次スプライン補間，片側3点4次多項式近似，片側3点5次多項式近似の3手法を比較した．

\begin{table}[H]
  \centering
  \caption{ファインチューニング後の予測性能}
  \label{tab:lstm_ft_performance}
  \small
  \resizebox{\textwidth}{!}{
    \begin{tabular}{llllc}
      \hline
      パターン & サンプル構成 & 補間手法 & NMSE & ベースラインからの改善率 [\%] \\
      \hline
      周期3 & I,S,I$\rightarrow$S & 3次スプライン補間 & $0.0357 \pm 0.0049$ & $71.65 \pm 2.71$ \\
      周期3 & I,S,I$\rightarrow$S & 片側3点4次多項式近似 & $0.0369 \pm 0.0052$ & $70.79 \pm 2.53$ \\
      周期3 & I,S,I$\rightarrow$S & 片側3点5次多項式近似 & $0.0369 \pm 0.0052$ & $70.79 \pm 2.53$ \\
      周期3 & S,I,S$\rightarrow$S & 3次スプライン補間 & $\bm{0.0350 \pm 0.0052}$ & $\bm{72.19 \pm 3.25}$ \\
      周期3 & S,I,S$\rightarrow$S & 片側3点4次多項式近似 & $0.0351 \pm 0.0051$ & $72.09 \pm 3.24$ \\
      周期3 & S,I,S$\rightarrow$S & 片側3点5次多項式近似 & $0.0351 \pm 0.0051$ & $72.09 \pm 3.24$ \\
      \hline
      周期2 & I,I,I$\rightarrow$S & 3次スプライン補間 & $0.0580 \pm 0.0092$ & $61.37 \pm 4.03$ \\
      周期2 & I,I,I$\rightarrow$S & 片側3点4次多項式近似 & $0.0679 \pm 0.0124$ & $54.78 \pm 6.07$ \\
      周期2 & I,I,I$\rightarrow$S & 片側3点5次多項式近似 & $0.0679 \pm 0.0124$ & $54.78 \pm 6.07$ \\
      周期2 & S,S,S$\rightarrow$I & 3次スプライン補間 & $\bm{0.0477 \pm 0.0060}$ & $\bm{68.20 \pm 2.90}$ \\
      周期2 & S,S,S$\rightarrow$I & 片側3点4次多項式近似 & $0.0507 \pm 0.0060$ & $66.16 \pm 2.68$ \\
      周期2 & S,S,S$\rightarrow$I & 片側3点5次多項式近似 & $0.0507 \pm 0.0060$ & $66.16 \pm 2.68$ \\
      \hline
    \end{tabular}
  }
\end{table}

周期3パターンでは，S,I,S$\rightarrow$Sと3次スプライン補間の組み合わせが最良の性能を示している．
ベースラインから72.19\%の改善を達成し，NMSEは0.0350まで低下した．
周期2パターンでは，S,S,S$\rightarrow$Iと3次スプライン補間の組み合わせが最良であり，68.20\%の改善を達成してNMSEは0.0477となった．

サンプル構成間の比較では，入力に補間値を多く含む構成よりも，入力に推定値を多く含む構成のほうが高い改善率を示している．
周期3パターンでは，I,S,I$\rightarrow$Sが71.65\%であるのに対し，S,I,S$\rightarrow$Sは72.19\%と若干の差がある．
周期2パターンでは差がより顕著であり，I,I,I$\rightarrow$Sが61.37\%であるのに対し，S,S,S$\rightarrow$Iは68.20\%と約7ポイントの差がある．
入力に補間値が多く含まれると補間誤差がモデルに伝播しやすく，性能が低下すると考えられる．

補間手法間の比較では，3次スプライン補間が片側多項式近似よりも優れた性能を示す傾向にある．
片側3点4次多項式近似と片側3点5次多項式近似は同一の性能を示しており，次数の違いによる差は見られない．

\subsubsection{パイロット削減と予測精度の両立}
以上の結果から，パイロット信号を削減した場合においても，提案機構によるファインチューニング後のNMSEが予測を用いないCopy-Lastよりも低く抑えられていることが確認できる．

Copy-LastのNMSEは約0.200であるのに対し，周期3パターンでは最良構成で0.035，周期2パターンでは0.048を達成している．
周期2パターンはパイロット送信を50\%削減する設定であるが，それでもCopy-Lastの約4分の1のNMSEを実現している．

この結果は，提案したチャネル予測機構がパイロット信号の削減と予測精度の維持を両立できることを示している．
パイロット削減率を高めると予測が困難になりベースラインモデルの性能は低下するが，補間値を用いたファインチューニングにより新環境への適応が可能となり，実用的な予測精度を確保できる．

% %----------------------------------------------------------------------------
% %----------------------------------------------------------------------------

% %----------------------------------------------------------------------------
% %----------------------------------------------------------------------------
% \subsection{補間値の入力位置によるモデル精度改善率の比較}
% \label{interpolation_input_position}

% \autoref{sec:related_work_and_problems}で述べたとおり，入力中または出力位置に補間値を持ってくる場合を考える．
% 本実験では3入力1出力の機械学習モデルにおいて，入力中に補間値を持ってくる場合の3パターンと出力位置に補間値を持ってくる場合の合計4パターンを比較する．
% それぞれのファインチューニング用サンプルの作り方の違いによって予測精度の改善率がどう異なるかを比較する．


% 本実験は5つのステップで構成される．
% 事前学習データで事前学習したベースラインモデルを起点として，補間値を用いたファインチューニングにより検証用データへの適応を試みる．

% \subsubsection{実験結果}
% まず，ベースライン性能のNMSEを表\ref{tab:baseline_nmse_interpolation_position}に示す．

% \begin{table}[H]
%   \centering
%   \caption{ベースライン性能 NMSE}
%   \label{tab:baseline_nmse_interpolation_position}
%   \begin{tabular}{lc}
%     \hline
%     指標 & NMSE \\
%     \hline
%     Copy-last Baseline & 0.175486 \\
%     ベースラインモデル & 0.148085 \\
%     \hline
%   \end{tabular}
% \end{table}

% 次に，Cubic Spline補間を用いた場合の，補間値の配置位置ごとのファインチューニング後NMSEとベースラインモデル比改善率を表\ref{tab:cubic_spline_position_results}に示す．
% 最良はFirstであり，NMSEは\(0.030265\)，ベースラインモデル比改善率は\(79.56\%\)となった．

% \begin{table}[H]
%   \centering
%     \caption{Cubic Spline補間 配置位置ごとの精度 ファインチューニング後NMSE}
%     \label{tab:cubic_spline_position_results}
%     \begin{tabular}{lcc}
%       \hline
%       配置位置 & ファインチューニング後NMSE & ベースラインモデル比改善率 \\
%     \hline
%     Label  & 0.031919 & 78.45\% \\
%     \textbf{First}  & \textbf{0.030265} & \textbf{79.56\%} \\
%     Middle & 0.033456 & 77.41\% \\
%     Last   & 0.030964 & 79.09\% \\
%     \hline
%   \end{tabular}
% \end{table}

% さらに，NN補間を用いた場合の結果を表\ref{tab:nn_interp_position_results}に示す．NN補間においても最良はFirstであり，NMSEは\(0.035399\)，ベースラインモデル比改善率は\(76.10\%\)となった．

% \begin{table}[H]
%   \centering
%     \caption{NN補間 配置位置ごとの精度 ファインチューニング後NMSE}
%     \label{tab:nn_interp_position_results}
%     \begin{tabular}{lcc}
%       \hline
%       配置位置 & ファインチューニング後NMSE & ベースラインモデル比改善率 \\
%     \hline
%     Label  & 0.072354 & 51.14\% \\
%     \textbf{First}  & \textbf{0.035399} & \textbf{76.10\%} \\
%     Middle & 0.058685 & 60.37\% \\
%     Last   & 0.102788 & 30.59\% \\
%     \hline
%   \end{tabular}
% \end{table}

% 補間手法別に最良条件同士を比較した結果を表\ref{tab:best_nmse_by_method}に示す．本実験条件では，Cubic Spline補間のFirstがNN補間のFirstよりも低NMSEを達成した．

% \begin{table}[H]
%   \centering
%     \caption{補間手法別の最良NMSE 最良配置位置}
%     \label{tab:best_nmse_by_method}
%     \begin{tabular}{lccc}
%       \hline
%       補間手法 & 最良配置位置 & NMSE & ベースラインモデル比改善率 \\
%     \hline
%     Cubic Spline & First & 0.030265 & 79.56\% \\
%     NN補間 & First & 0.035399 & 76.10\% \\
%     \hline
%   \end{tabular}
% \end{table}

% \subsubsection{考察}
% 本実験では，Cubic Spline補間およびNN補間のいずれにおいてもFirstが最良となった．これは，補間値に含まれる誤差が，出力に近いほど予測誤差へ直接寄与しやすいためである．Lastでは出力の直前時刻が補間値となるため，モデルは誤差を含むフレームに強く依存しやすく，ファインチューニング後の誤差が増大しやすい．一方，Firstでは出力に近いフレームが真値で観測されるため，モデルは観測値を主要な手掛かりとして予測でき，補間誤差の影響が抑制される．

% Labelは補間値を出力とするため，補間誤差が教師信号のノイズとして学習に混入する．スプライン補間では補間誤差が小さく，擬似ラベルのノイズが抑制されるため性能が維持された．NN補間では擬似ラベル誤差が相対的に大きくなりやすく，改善が限定的となった．






% 補間NMSEは式(\ref{eq:nmse_interp_def})，予測NMSEは式(\ref{eq:nmse_pred_def})で定義したとおりである．
% ベースラインモデルの予測NMSEを\(\mathrm{NMSE}_{\mathrm{base}}\)，適応後モデルの予測NMSEを\(\mathrm{NMSE}_{\mathrm{adapted}}\)と表す．
% 改善率はファインチューニング前NMSEからの削減率を表し，式(\ref{eq:improve_rate})で定義する．

% \subsubsection{各補間手法の詳細}
% 本実験で用いる補間手法を表\ref{tab:interp_methods_detail}に示す．各手法の詳細は\autoref{sec:interpolation_methods}で述べたとおりである．

% \begin{table}[H]
%   \centering
%   \caption{本実験で用いる補間手法}
%   \label{tab:interp_methods_detail}
%   \begin{tabular}{ll}
%     \hline
%     補間手法 & 設定 \\
%     \hline
%     3次スプライン補間 & 近傍6点 \\
%     ニューラルネットワーク補間 & 近傍6点 \\
%     2次多項式近似 & 近傍6点 \\
%     3次多項式近似 & 近傍6点 \\
%     4次多項式近似 & 近傍6点 \\
%     4次多項式近似 & 近傍片側3点 \\
%     4次多項式近似 & 近傍片側6点 \\
%     4次多項式近似 & 近傍片側9点 \\
%     5次多項式近似 & 近傍片側3点 \\
%     5次多項式近似 & 近傍片側6点 \\
%     5次多項式近似 & 近傍片側9点 \\
%     6次多項式近似 & 近傍片側3点 \\
%     6次多項式近似 & 近傍片側6点 \\
%     6次多項式近似 & 近傍片側9点 \\
%     \hline
%   \end{tabular}
% \end{table}

% 3次スプライン補間は，補間対象時刻の前後6点を用いて時間方向に平滑な曲線を構成し，補間値を算出する．
% ニューラルネットワーク補間は，事前学習データで学習した補間モデルを用いて，近傍6点から中心時刻のCSIを推定する．
% 多項式近似は，時間方向に低次多項式を当てはめて補間値を算出する．次数\(d\)と近傍点数\(k\)を変化させ，補間精度への影響を比較する．

% \subsubsection{実験結果}

% \paragraph{ベースラインモデルの有効性}
% まず，ベースラインモデルが予測を行わない場合と比較して有効であることを確認する．予測を行わない場合のベースラインとして，Copy-Lastを定義する．Copy-Lastは，入力として与えられた3フレームのうち最後のフレーム\(\bm{H}_t\)をそのまま次時刻の予測値として出力する手法である．すなわち，
% \begin{equation}
%   \widehat{\bm{H}}_{t+1}=\bm{H}_t
% \end{equation}
% とする．CSIの時間変動が小さい場合，この手法でも低い予測誤差が得られるが，時間変動が大きい環境では誤差が増大する．

% 表\ref{tab:baseline_comparison_fold}に各foldにおけるベースラインモデルとCopy-LastのNMSEを示す．

% \begin{table}[H]
%   \centering
%   \caption{ベースラインモデルとCopy-Lastの比較}
%   \label{tab:baseline_comparison_fold}
%   \begin{tabular}{ccc}
%     \hline
%     fold & ベースラインモデル NMSE & Copy-Last NMSE \\
%     \hline
%     0 & 0.1438 & 0.4933 \\
%     1 & 0.1407 & 0.3258 \\
%     2 & 0.1269 & 0.2050 \\
%     3 & 0.1432 & 0.3483 \\
%     4 & 0.1278 & 0.2325 \\
%     \hline
%     平均 & 0.1365 & 0.3210 \\
%     \hline
%   \end{tabular}
% \end{table}

% 全foldにおいてベースラインモデルのNMSEがCopy-Lastを下回っており，ベースラインモデルによる予測が有効であることが確認できた．平均NMSEはベースラインモデルが0.1365，Copy-Lastが0.3210であり，ベースラインモデルはCopy-Lastと比較して約57\%の誤差削減を達成している．

% \paragraph{補間手法別の性能比較}
% \label{subsec:interpolation_methods_comparison}
% 5分割交差検証の結果を表\ref{tab:kfold_results_other_cell}に示す．各値は5 foldの平均である．

% \begin{table}[H]
%   \centering
%   \caption{5分割交差検証による補間手法別の性能比較}
%   \label{tab:kfold_results_other_cell}
%   \begin{tabular}{lcccc}
%     \hline
%     補間手法 & 補間NMSE & ベースラインモデル NMSE & 適応後モデル NMSE & 改善率 \\
%     \hline
%     3次スプライン補間 & 0.0061 & 0.1365 & 0.0282 & 79.37\% \\
%     ニューラルネットワーク補間 & 0.0200 & 0.1365 & 0.0292 & 78.64\% \\
%     2次多項式近似 & 0.0518 & 0.1365 & 0.0351 & 74.29\% \\
%     3次多項式近似 & 0.0518 & 0.1365 & 0.0352 & 74.21\% \\
%     4次多項式近似（片側3点） & 0.0059 & 0.1365 & 0.0283 & 79.35\% \\
%     4次多項式近似（片側6点） & 0.2291 & 0.1365 & 0.0502 & 63.28\% \\
%     4次多項式近似（片側9点） & 0.2585 & 0.1365 & 0.0614 & 54.95\% \\
%     5次多項式近似（片側3点） & 0.0059 & 0.1365 & 0.0282 & 79.36\% \\
%     5次多項式近似（片側6点） & 0.2291 & 0.1365 & 0.0502 & 63.24\% \\
%     5次多項式近似（片側9点） & 0.2585 & 0.1365 & 0.0616 & 54.78\% \\
%     6次多項式近似（片側3点） & 0.1432 & 0.1365 & 0.0878 & 35.62\% \\
%     6次多項式近似（片側6点） & 0.0571 & 0.1365 & 0.0334 & 75.54\% \\
%     6次多項式近似（片側9点） & 0.2359 & 0.1365 & 0.0516 & 62.16\% \\
%     \hline
%   \end{tabular}
% \end{table}

% ベースラインモデルのNMSEは全手法で共通の0.1365である．最良の改善率を達成したのは3次スプライン補間であり，適応後モデルのNMSEは0.0282，改善率は79.37\%となった．4次多項式近似およびニューラルネットワーク補間も同程度の改善率を達成した．

% 多項式近似では，次数と近傍点数の組み合わせにより性能が大きく異なる．片側3点を用いる4次および5次多項式近似はスプライン補間と同等の改善率を達成したが，片側6点以上では補間NMSEが増大し，改善率が低下した．6次多項式近似は片側3点で改善率が35.62\%と最も低く，過適合により補間精度が劣化したと考えられる．

% 本実験の結果から，補間手法の選択について以下の知見が得られた．

% 最もモデルの改善率が高かった手法は3次スプライン補間である．補間NMSEが0.0061と低く，改善率も79.37\%で最良となった．4次多項式近似および5次多項式近似を片側3点で用いた場合も，3次スプライン補間とほぼ同等の性能を達成した．
% ニューラルネットワーク補間は補間NMSEが0.0200と3次スプライン補間より高いものの，改善率は78.64\%であり実用上は同等の性能といえる．

% 一方，片側6点以上を用いる多項式近似は補間NMSEが増大し，改善率が低下した．6次多項式近似を片側3点で用いた場合は改善率が35.62\%と著しく低下しており，この組み合わせは不適である．

% 補間NMSEと改善率の関係を分析すると，補間NMSEが低いほど改善率が高くなる傾向がある．補間値はファインチューニング時の学習サンプルを構成するため，補間誤差が小さいほど学習信号の品質が高くなる．
% 学習データの誤差が抑えられることで，モデルは検証用データの環境への適応を効率的に進められる．
% 3次スプライン補間や片側3点の多項式近似が高い改善率を達成したのは，補間NMSEが低く学習サンプルの品質が保たれたためである．

% \subsection{雑音に対する堅牢性}
% \label{subsec:noise_robustness}
% 本実験では，雑音環境下における補間手法の堅牢性を評価する．

% 事前学習のデータセットは第\ref{subsec:thickness}節と同様に，池袋，渋谷，新宿の3地域の地形データに対してレイトレーシングにより得られたCSI系列を用いる．
% テストデータセットも第\ref{subsec:thickness}節と同様に，錦糸町駅の地形データに対してレイトレーシングにより得られたCSI系列を用いる．
% 学習用サンプルは70万サンプル，テストデータセットは12.8万サンプルである．

% 比較する補間手法は，第\ref{subsec:interpolation_methods_comparison}節で高い性能を示した3次スプライン補間，3点コンテキストを用いたニューラルネットワーク補間，片側3点の4次多項式近似，片側3点の5次多項式近似の4手法である

% % | ディレクトリ | ファイル数（使用） | 説明 |
% % |-------------|------------------|------|
% % | `/data/ikebukuro` | 40/50 | 池袋エリアのCSI軌跡データ |
% % | `/data/shibuya` | 40/53 | 渋谷エリアのCSI軌跡データ |
% % | `/data/shinjuku` | 40/49 | 新宿エリアのCSI軌跡データ |
% % | **合計** | **120ファイル** | 3都市マルチシティ学習 |




% \paragraph{評価対象のSNR}
% 評価用CSIに対して，SNRを0~dBから50~dBまで5~dB刻みで変化させながら加法性白色ガウス雑音を付与し，各SNRにおける予測NMSEを測定した．

% \paragraph{雑音の付与方法}
% CSIテンソルを\(\bm{H}\in\mathbb{C}^{T\times R_B\times T_x\times R_x}\)とする．実装上は実部と虚部を分離した\(\widetilde{\bm{H}}\in\mathbb{R}^{T\times R_B\times T_x\times R_x\times 2}\)として保存されており，最後の次元が実部と虚部に対応する．

% まず，実部と虚部を結合して複素表現を構成する．
% \begin{equation}
%   \bm{H}_{\mathrm{c}}=\bm{H}_{\mathrm{re}}+j\bm{H}_{\mathrm{im}}
% \end{equation}
% 次に，SNR[dB]からノイズパワー比\(\sigma\)を算出する．
% \begin{equation}
%   \sigma=10^{-\frac{\mathrm{SNR}_{\mathrm{dB}}}{10}}
% \end{equation}
% 標準複素ガウス雑音\(z\sim\mathcal{CN}(0,1)\)を生成する．各成分は実部と虚部がそれぞれ\(\mathcal{N}(0,\tfrac{1}{2})\)に従う．CSIの平均電力を
% \begin{equation}
%   P_s=\mathbb{E}\left[|\bm{H}_{\mathrm{c}}|^2\right]
% \end{equation}
% とし，雑音を
% \begin{equation}
%   n=\sqrt{\frac{\sigma}{2}}\,z\sqrt{P_s}
% \end{equation}
% としてスケーリングする．雑音付加後のCSIは
% \begin{equation}
%   \bm{H}_{\mathrm{noisy}}=\bm{H}_{\mathrm{c}}+n
% \end{equation}
% となる．このとき，雑音の平均電力は\(\mathbb{E}[|n|^2]=\sigma P_s\)であり，信号対雑音電力比は
% \begin{equation}
%   \mathrm{SNR}=\frac{P_s}{\mathbb{E}[|n|^2]}=\frac{1}{\sigma}
% \end{equation}
% を満たす．

% \paragraph{実験結果}
% 評価対象のベースラインとして，ファインチューニングを行わない事前学習モデルであるベースラインモデルと，直前フレームをコピーする単純戦略であるCopy-Lastを設定した．
% ベースラインモデルの予測NMSEは0.1439，Copy-Lastの予測NMSEは0.1755である．

% まず，ノイズなしのクリーン条件における各補間手法の性能を評価した．
% 表\ref{tab:noise_clean}に結果を示す．
% 片側3点の5次多項式近似が予測NMSE 0.0309と最も低く，ベースラインモデルに対して78.5\%の改善率を示した．
% 片側3点の4次多項式近似と3次スプライン補間は予測NMSE 0.0310で，改善率は78.4\%とほぼ同等の性能を示した．
% 3点コンテキストを用いたニューラルネットワーク補間は予測NMSE 0.0345で，改善率は76.0\%であった．

% \begin{table}[H]
%   \centering
%     \caption{クリーン条件における各補間手法の性能}
%     \label{tab:noise_clean}
%     \begin{tabular}{lcc}
%       \hline
%       手法 & 予測NMSE & ベースラインモデル比改善率 \\
%     \hline
%     片側3点の5次多項式近似 & 0.0309 & 78.5\% \\
%     片側3点の4次多項式近似 & 0.0310 & 78.4\% \\
%     3次スプライン補間 & 0.0310 & 78.4\% \\
%     3点コンテキストニューラルネットワーク補間 & 0.0345 & 76.0\% \\
%     \hline
%   \end{tabular}
% \end{table}

% 次に，各SNRレベルにおける予測NMSEを測定した．

% 評価対象のSNRは-2，0，2，4，6，8，10，15，20~dBである．
% 表\ref{tab:noise_snr}に各SNRにおける予測NMSEを示す．

% \begin{table}[H]
%   \centering
%   \caption{各SNRレベルにおける予測NMSE}
%   \label{tab:noise_snr_level}
%   \small % フォントサイズを少し小さく
%   \resizebox{\textwidth}{!}{ % 横幅に収める
%     \begin{tabular}{lcccc}
%       \hline
%       SNR (dB) & 3次スプライン & 3点コンテキストNN & 片側3点4次多項式 & 片側3点5次多項式 \\
%       \hline
%       クリーン & 0.0310 & 0.0345 & 0.0310 & 0.0309 \\
%       -2 & 0.0817 & 0.0603 & 0.0813 & 0.0818 \\
%       0 & 0.0614 & 0.0540 & 0.0617 & 0.0615 \\
%       2 & 0.0481 & 0.0476 & 0.0486 & 0.0487 \\
%       4 & 0.0411 & 0.0439 & 0.0415 & 0.0414 \\
%       6 & 0.0369 & 0.0417 & 0.0371 & 0.0371 \\
%       8 & 0.0348 & 0.0392 & 0.0348 & 0.0343 \\
%       10 & 0.0333 & 0.0383 & 0.0332 & 0.0332 \\
%       15 & 0.0316 & 0.0365 & 0.0315 & 0.0316 \\
%       20 & 0.0313 & 0.0359 & 0.0311 & 0.0312 \\
%       \hline
%     \end{tabular}
%   }
% \end{table}

% \begin{figure}[H]
%   \centering
%   % trim=左 下 右 上 の順で余白を削る（単位はピクセル相当）
%   \includegraphics[width=0.9\textwidth,bb=400 300 3200 1800,clip]{../picture/4nd/result_multi_town_snr.png}
%   \caption{各SNRレベルにおける予測NMSE}
%   \label{fig:noise_snr}
% \end{figure}

% SNRが低い領域（-2~dBから2~dB）では，3点コンテキストを用いたニューラルネットワーク補間が最も低い予測NMSEを示した．
% SNR -2~dBでは予測NMSE 0.0603，SNR 0~dBでは0.0540，SNR 2~dBでは0.0476と，他の手法と比較して優れた堅牢性を示した．

% SNRが4~dB以上では，3次スプライン補間，片側3点の4次多項式近似，片側3点の5次多項式近似がほぼ同等の性能を示し，3点コンテキストを用いたニューラルネットワーク補間より低い予測NMSEを達成した．
% SNR 20~dBでは，片側3点の4次多項式近似が予測NMSE 0.0311と最も低く，クリーン条件に近い性能を示した．

% これらの結果から，低SNR環境ではニューラルネットワーク補間が最も堅牢であり，高SNR環境では多項式近似やスプライン補間が優れた性能を示すことが確認された．




% ------------------------------------------------------------
% %----------------------------------------------------------------------------
% \subsection{同一セル内での環境適応}
% \label{subsec:rx_position}
% テスト。


% %----------------------------------------------------------------------------
% %----------------------------------------------------------------------------
% \subsection{実験4}
% \label{subsec:simo}
% テスト。


% %----------------------------------------------------------------------------
% %----------------------------------------------------------------------------
% \section{考察}
% テスト。



\section{おわりに}
テスト。
